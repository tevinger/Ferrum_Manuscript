---
title: "Ferrum_Temporal Analysis"
output: html_document
date: "2025-03-14"
editor_options: 
  chunk_output_type: console
---

# Load Packages
```{r}
#install.packages("dataRetrieval")
library(dataRetrieval)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(lubridate)
library(emmeans)
library(lme4)
library(ggeasy)
library(lattice)
library(rstatix)
library(ggsignif)
library(outliers)
library(ggpmisc)
library(ggpubr)
library(r2symbols)
library(stargazer)
library(ggbreak)
library(writexl)
library(ggrepel)
library(stringr)
library(ggthemes)
library(reshape)
library(RColorBrewer)
library(readxl)
library(dplyr)
library(gridExtra)
library(scales)
library(dbscan)
library(mclust)
library(devtools)
library(factoextra)
library(corrplot)
library(ggbiplot)
library(ggcorrplot)
library(GGally)
library(Hmisc)
library(ggbiplot)
library(ggfortify)
library(emmeans)
library(lme4)
library(lmerTest)
library(multcomp)
library(readxl)
library(learnr)
library(scatterplot3d)
library(vegan)
library(ggtern)
library(plotrix)
library(smwrBase)
library(smwrData)
library(smwrGraphs)
library(colorBlindness)
library(flextable)
library(officer)
library(dunn.test)
library(multcompView)
library(patchwork)
library(ggpattern)
```

# Download Discharge Data
```{r}
# Set site numbers for the 4 water stations we want to pull data for
site_numbers <- c("15564879", "15743850", "15744500", "15747000")

# IKALUKROK C AB RED DOG C NR KIVALINA AK Site Number = 15746980
# site_numbers <- c("15564879", "15743850", "15744500", "15747000", "15746980")

sites <- whatNWISsites(sites = site_numbers)

view(sites)

# write_xlsx(sites, "C:/Users/tayta/Downloads/USGS water stations.xlsx")

# Define the time period
start_date <- "2015-01-01"
end_date <- "2024-12-31"

# Retrieve daily discharge data for all sites
discharge_data_raw <- readNWISdv(
  siteNumbers = site_numbers, 
  parameterCd = "00060", 
  startDate = start_date, 
  endDate = end_date
)

# add site names to site numbers
site_names <- sites %>% 
  dplyr::select(site_no, station_nm)

discharge_data_mod <- left_join(discharge_data_raw, site_names, by = join_by(site_no))
```

```{r}
# modifications to use for plots
discharge_data <- discharge_data_mod %>%
  mutate(Year = year(Date)) %>%
  mutate(Month = month(as.Date(Date), label = TRUE, abbr = FALSE)) %>%
  mutate(
    Season = case_when(
      Month %in% c("May", "June") ~ "early",
      Month %in% c("August", "September") ~ "late",
      TRUE ~ NA_character_
    )
  ) %>%
  mutate(Year_Season = paste(Year,
                             Season,
                             sep = "_")) %>%
  # add pre and post onset descriptions
  mutate(Onset_timing = case_when(
    Year_Season %in% c("2015_early", "2016_early", "2017_early", "2018_early", "2015_late", "2016_late", "2017_late", "2018_late", "2019_early", "2015_NA", "2016_NA", "2017_NA", "2018_NA") ~ "pre",
    Year_Season %in% c("2019_late", "2020_early", "2021_early", "2022_early", "2023_early", "2024_early", "2020_late", "2021_late", "2022_late", "2023_late", "2024_late", "2020_NA", "2021_NA", "2022_NA", "2023_NA", "2024_NA") ~ "post",
    TRUE ~ NA_character_
  )) %>%
  mutate(Year_onset_timing = paste(Year,
                                   Onset_timing,
                                   sep = "_")
  ) %>%
  dplyr::rename(discharge_cfs = X_00060_00003) %>% # remane discharge measurements column
  mutate(discharge_cms = discharge_cfs * 0.0283168) # convert cfs to cms
```

```{r}
yearly_discharge <- discharge_data %>%
  group_by(station_nm, Year) %>%
  summarise(
    total_discharge_cms = sum(discharge_cms, na.rm = TRUE),
    average_discharge_cms = mean(discharge_cms, na.rm = TRUE),
    total_discharge_cfs = sum(discharge_cfs, na.rm = TRUE),
    average_discharge_cfs = mean(discharge_cfs, na.rm = TRUE),
    .groups = "drop"
  )

yearly_onset_discharge <- discharge_data %>%
  filter(!Year_onset_timing == "2019_NA") %>%
  group_by(station_nm, Year_onset_timing) %>%
  summarise(
    total_discharge_cms = sum(discharge_cms, na.rm = TRUE),
    average_discharge_cms = mean(discharge_cms, na.rm = TRUE),
    total_discharge_cfs = sum(discharge_cfs, na.rm = TRUE),
    average_discharge_cfs = mean(discharge_cfs, na.rm = TRUE),
    .groups = "drop"
  ) %>% 
  mutate(
    onset_timing = case_when(
      str_detect(Year_onset_timing, "pre")  ~ "pre",
      str_detect(Year_onset_timing, "post") ~ "post",
      TRUE ~ NA_character_
    )
  )

monthly_average <- discharge_data %>%
  group_by(station_nm, Year, Month) %>%
  summarise(
    total_discharge_cms = sum(discharge_cms, na.rm = TRUE),
    average_discharge_cms = mean(discharge_cms, na.rm = TRUE),
    total_discharge_cfs = sum(discharge_cfs, na.rm = TRUE),
    average_discharge_cfs = mean(discharge_cfs, na.rm = TRUE),
    .groups = "drop"
  )

seasonal_average <- discharge_data %>%
  group_by(station_nm, Year, Season) %>%
  summarise(
    total_discharge_cms = sum(discharge_cms, na.rm = TRUE),
    average_discharge_cms = mean(discharge_cms, na.rm = TRUE),
    total_discharge_cfs = sum(discharge_cfs, na.rm = TRUE),
    average_discharge_cfs = mean(discharge_cfs, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(!is.na(Season))

onset_discharge <- discharge_data %>%
  filter(!is.na(Onset_timing)) %>%
  group_by(station_nm, Onset_timing) %>%
  summarise(
    total_discharge_cms = sum(discharge_cms, na.rm = TRUE),
    average_discharge_cms = mean(discharge_cms, na.rm = TRUE),
    total_discharge_cfs = sum(discharge_cfs, na.rm = TRUE),
    average_discharge_cfs = mean(discharge_cfs, na.rm = TRUE),
    .groups = "drop"
  )

discharge_onset_data <- discharge_data %>%
  filter(!is.na(Onset_timing))
```

```{r}
library(writexl)

discharge_data_list <- list(discharge_data, yearly_discharge, monthly_average, seasonal_average, onset_average)

write_xlsx(discharge_data_list,
  "C:/Users/tevinger/Downloads/discharge data.xlsx"
)

```


```{r}
# plot the Q data
library(ggplot2)

q.p <- ggplot(discharge_data, aes(x = Date, y = discharge_cfs, color = station_nm)) +
  geom_line() +
  facet_wrap(station_nm~., scales = "free", ncol = 2)+
  labs(x = "Date",
       y = "Discharge (cfs)") +
  theme_minimal() +
  theme(
    legend.position = "none"
  ) +
  DA_theme

q.p
```

```{r}
yearly_discharge <- yearly_discharge %>%
  arrange(station_nm, Year)

q.p_2 <- ggplot(yearly_discharge, 
                aes(x = as.factor(Year), y = total_discharge_cms, color = station_nm)) +
  geom_point(size = 2.8) +
  geom_line(aes(group = 1), linewidth = 1) +   # ✅ THIS restores the line
  facet_wrap(station_nm~., scales = "free", ncol = 2) +
  scale_y_continuous(labels = scales::comma) +
  labs(x = NULL, 
       #y = "Discharge (cfs)"
       y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 12, color = "black", face = "bold"),
    axis.text.x = element_text(size = 12, color = "black", face = "bold", 
                               angle = 45, hjust = 1, vjust = 1),
    axis.ticks.y = element_line(linewidth = 0.9, color = "black"),
    axis.ticks.length.y = unit(0.1, "cm"),
    axis.ticks.x = element_line(linewidth = 0.9, color = "black"),
    axis.ticks.length.x = unit(0.15, "cm"),
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold", color = "black"),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.border = element_rect(fill = NA, color = "black", size = 1.25),
    panel.background = element_rect(fill = "transparent"),
    plot.background = element_rect(fill = "transparent", color = NA),
    legend.position = "none",
    strip.text = element_blank(),
    panel.spacing.x = unit(1.5, "lines"),
    panel.spacing.y = unit(2.75, "lines")
  )

q.p_2

ggsave("C:/Users/tevinger/Downloads/Total Discharge_cms.png", q.p_2, width = 11, height = 7)

# ggsave(q.p, filename = "02_Hydrographs_Available_Data_2015to2025.png",
#        width = 11, height = 7)
```

```{r}
discharge_data_onset <- yearly_onset_discharge %>%
  filter(onset_timing %in% c("pre", "post")) %>%
  mutate(onset_timing = factor(onset_timing, levels = c("pre", "post")))

discharge_bps <- discharge_data_onset %>%
  ggplot(aes(x = onset_timing, y = total_discharge_cms, fill = station_nm)) +
  geom_boxplot() +
  facet_wrap(station_nm~., scales = "free", ncol = 4) +
  labs(x = NULL, y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 12, color = "black", face = "bold"),
    axis.text.x = element_text(size = 12, color = "black", face = "bold", 
                               angle = 45, hjust = 0.5, vjust = 0.8),
    axis.ticks.y = element_line(linewidth = 0.9, color = "black"),
    axis.ticks.length.y = unit(0.1, "cm"),
    axis.ticks.x = element_line(linewidth = 0.9, color = "black"),
    axis.ticks.length.x = unit(0.15, "cm"),
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold", color = "black"),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.border = element_rect(fill = NA, color = "black", size = 1.25),
    panel.background = element_rect(fill = "transparent"),
    plot.background = element_rect(fill = "transparent", color = NA),
    legend.position = "none",
    strip.text = element_blank(),
    panel.spacing.x = unit(1.5, "lines"),
    panel.spacing.y = unit(1.75, "lines")
  )

discharge_bps

ggsave("C:/Users/tevinger/Downloads/Onset timing Total Discharge cms.png", discharge_bps, width = 10, height = 5)
```

```{r}
discharge_data_onset <- yearly_onset_discharge %>%
  filter(onset_timing %in% c("pre", "post")) %>%
  mutate(onset_timing = factor(onset_timing, levels = c("pre", "post")))

discharge_bps <- discharge_data_onset %>%
  filter(!is.na(onset_timing)) %>%
  ggplot(aes(x = onset_timing, y = total_discharge_cms, fill = station_nm)) +
  geom_boxplot() +
  facet_wrap(station_nm~., scales = "free", ncol = 4) +
  labs(x = NULL, y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 12, color = "black", face = "bold"),
    axis.text.x = element_text(size = 12, color = "black", face = "bold", 
                               angle = 45, hjust = 0.5, vjust = 0.8),
    axis.ticks.y = element_line(linewidth = 0.9, color = "black"),
    axis.ticks.length.y = unit(0.1, "cm"),
    axis.ticks.x = element_line(linewidth = 0.9, color = "black"),
    axis.ticks.length.x = unit(0.15, "cm"),
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold", color = "black"),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.border = element_rect(fill = NA, color = "black", size = 1.25),
    panel.background = element_rect(fill = "transparent"),
    plot.background = element_rect(fill = "transparent", color = NA),
    legend.position = "none",
    strip.text = element_blank(),
    panel.spacing.x = unit(1.5, "lines"),
    panel.spacing.y = unit(1.75, "lines")
  )

discharge_bps
```

```{r}
discharge_data <- discharge_data %>%
  filter(Onset_timing %in% c("pre", "post")) %>%
  filter(Season %in% c("early", "late")) %>%
  mutate(onset_season = paste(
    Onset_timing,
    Season,
    sep = "_"
  )) %>%
  mutate(
    station_season = interaction(site_no, Season, sep = "_")
  ) %>%
  mutate(onset_season = factor(onset_season, levels = c("pre_early","post_early", "pre_late", "post_late")))

fill_values <- c(
  "15743850_early" = "#F4A3A3",
  "15743850_late"  = "#D94B4B",
  "15564879_early" = "#B6D77A",
  "15564879_late"  = "#6FA800",
  "15744500_early" = "#7FD3CF",
  "15744500_late"  = "#009E9A",
  "15747000_early" = "#D4A6FF",
  "15747000_late"  = "#8B5CF6"
)


  # mutate(Onset_timing = factor(Onset_timing, levels = c("pre", "post")))
```

```{r}
discharge_bps <- discharge_data %>%
  filter(!is.na(onset_season)) %>%
  ggplot(aes(x = onset_season, y = discharge_cms, fill = station_season)) +
  geom_boxplot() +
  facet_wrap(station_nm~., scales = "free", ncol = 4) +
  scale_y_log10() +
  scale_fill_manual(values = fill_values) +
  labs(x = NULL, y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 12, color = "black", face = "bold"),
    axis.text.x = element_text(size = 12, color = "black", face = "bold", 
                               angle = 45, hjust = 0.55, vjust = 0.5),
    axis.ticks.y = element_line(linewidth = 0.9, color = "black"),
    axis.ticks.length.y = unit(0.1, "cm"),
    axis.ticks.x = element_line(linewidth = 0.9, color = "black"),
    axis.ticks.length.x = unit(0.15, "cm"),
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold", color = "black"),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.border = element_rect(fill = NA, color = "black", size = 1.25),
    panel.background = element_rect(fill = "transparent"),
    plot.background = element_rect(fill = "transparent", color = NA),
    legend.position = "none",
    strip.text = element_blank(),
    panel.spacing.x = unit(1.5, "lines"),
    panel.spacing.y = unit(1.75, "lines")
  )

discharge_bps

ggsave("C:/Users/tevinger/Downloads/Raw Discharge by Onset timing and season.png", discharge_bps, width = 10, height = 5)
```

## cumulative discharge per year
```{r}
# cumulative_discharge_by_year_stats <- cumulative_discharge_by_year %>%
# mutate(Temporal_status = ifelse(Year %in% c(2015, 2016, 2017, 2018), 'pre',
#                       ifelse(Year %in% c(2019, 2020, 2021, 2022, 2023, 2024), 'post', NA)))

cumulative_discharge_DahlCreek <- discharge_data_onset %>%
  filter(station_nm == "DAHL C NR KOBUK AK")

cumulative_discharge_KobukRiver <- discharge_data_onset %>%
  filter(station_nm == "KOBUK R NR KIANA AK")

cumulative_discharge_SlateCreek <- discharge_data_onset %>%
  filter(station_nm == "SLATE C AT COLDFOOT AK")

cumulative_discharge_WulikRiver <- discharge_data_onset %>%
  filter(station_nm == "WULIK R BL TUTAK C NR KIVALINA AK")

discharge_data_for_stats <- discharge_data %>%
  filter(!is.na(Onset_timing))
```

## Shapiro
```{r}
## total_discharge_cms shapiro analysis
shapiro_station_onset_models <- discharge_data_onset %>%
  filter(!is.na(average_discharge_cms),
         onset_timing %in% c("pre", "post")) %>%
  group_by(station_nm
           , onset_timing
           ) %>%
  summarise(
    n = n(),

    model = list(
      if (n >= 3) {
        lm(average_discharge_cms ~ 1,
           data = pick(average_discharge_cms))
      } else {
        NULL
      }
    ),

    shapiro = list(
      if (!is.null(model[[1]])) {
        shapiro.test(resid(model[[1]]))
      } else {
        NULL
      }
    ),

    W = if (!is.null(shapiro[[1]])) {
      unname(shapiro[[1]]$statistic)
    } else NA_real_,

    p_value = if (!is.null(shapiro[[1]])) {
      shapiro[[1]]$p.value
    } else NA_real_,

    Interpretation = if (!is.null(shapiro[[1]]) && shapiro[[1]]$p.value > 0.05) {
      "Residuals likely normal (fail to reject H0)."
    } else if (!is.null(shapiro[[1]])) {
      "Residuals not normal (reject H0)."
    } else {
      "Test not performed (n < 3)."
    },

    .groups = "drop"
  )

view(shapiro_station_onset_models)

#write_xlsx(shapiro_results_long, "C:/Users/tevinger/Downloads/total annual discharge Shapiro_12 30 2025.xlsx")
```

## wilcoxon test
unpaired Wilcoxon rank-sum test on the raw discharge_cms data because the raw data for each station_onset timing is non parametric
```{r}
wilcox_by_station <- discharge_data %>%
  filter(!is.na(discharge_cms),
         Onset_timing %in% c("pre", "post")) %>%
  mutate(Onset_timing = factor(Onset_timing, levels = c("pre", "post"))) %>%
  group_by(station_nm) %>%
  summarise(
    n_pre  = sum(Onset_timing == "pre"),
    n_post = sum(Onset_timing == "post"),

    test_result = list(
      if (n_pre >= 1 && n_post >= 1) {
        wilcox.test(
          discharge_cms ~ Onset_timing,
          data = pick(discharge_cms, Onset_timing),
          exact = FALSE
        )
      } else {
        NULL
      }
    ),

    W = if (!is.null(test_result[[1]])) unname(test_result[[1]]$statistic) else NA_real_,
    p_value = if (!is.null(test_result[[1]])) test_result[[1]]$p.value else NA_real_,

    Interpretation = if (!is.null(test_result[[1]]) && test_result[[1]]$p.value > 0.05) {
      "No evidence of a difference between pre and post."
    } else if (!is.null(test_result[[1]])) {
      "Evidence of a difference between pre and post."
    } else {
      "Test not performed (insufficient data)."
    },

    .groups = "drop"
  )

view(wilcox_by_station)
```

#Stats used for current figure as of 12/31/25
```{r}
## raw discharge_cms data shapiro analysis
shapiro_pre_post <- discharge_data %>%
  filter(!is.na(discharge_cms),
         onset_season %in% c("pre_early", "pre_late", "post_early", "post_late")) %>%
  group_by(station_nm, onset_season) %>%
  summarise(
    n = n(),
    W = if (n >= 3) shapiro.test(discharge_cms)$statistic else NA_real_,
    p_value = if (n >= 3) shapiro.test(discharge_cms)$p.value else NA_real_,
    Interpretation = if (n > 5000) {
      "Shapiro not performed (n > 5000; test not appropriate)."
    } else if (n < 3) {
      "Shapiro not performed (n < 3)."
    } else if (p_value > 0.05) {
      "Fail to reject normality."
    } else {
      "Reject normality."
    },
    .groups = "drop"
  )

view(shapiro_pre_post)
```

### pre_early vs post_early and pre_late vs post_late
unpaired Wilcoxon rank-sum test 
shapiro test results conclude that discharge_cms for each of these groups for each station is non parametric
```{r}
early_discharge_data <- discharge_data %>%
  filter(Season == "early")

late_discharge_data <- discharge_data %>%
  filter(Season == "late")
```

```{r}
wilcox_station_early <- early_discharge_data %>%
  filter(!is.na(discharge_cms),
         Onset_timing %in% c("pre", "post")) %>%
  mutate(Onset_timing = factor(Onset_timing, levels = c("pre", "post"))) %>%
  group_by(station_nm) %>%
  summarise(
    n_pre  = sum(Onset_timing == "pre"),
    n_post = sum(Onset_timing == "post"),

    test_result = list(
      if (n_pre >= 1 && n_post >= 1) {
        wilcox.test(
          discharge_cms ~ Onset_timing,
          data = pick(discharge_cms, Onset_timing),
          exact = FALSE
        )
      } else {
        NULL
      }
    ),

    W = if (!is.null(test_result[[1]])) unname(test_result[[1]]$statistic) else NA_real_,
    p_value = if (!is.null(test_result[[1]])) test_result[[1]]$p.value else NA_real_,

    Interpretation = if (!is.null(test_result[[1]]) && test_result[[1]]$p.value > 0.05) {
      "No evidence of a difference between pre and post."
    } else if (!is.null(test_result[[1]])) {
      "Evidence of a difference between pre and post."
    } else {
      "Test not performed (insufficient data)."
    },

    .groups = "drop"
  )

view(wilcox_station_early)
```

```{r}
wilcox_station_late <- late_discharge_data %>%
  filter(!is.na(discharge_cms),
         Onset_timing %in% c("pre", "post")) %>%
  mutate(Onset_timing = factor(Onset_timing, levels = c("pre", "post"))) %>%
  group_by(station_nm) %>%
  summarise(
    n_pre  = sum(Onset_timing == "pre"),
    n_post = sum(Onset_timing == "post"),

    test_result = list(
      if (n_pre >= 1 && n_post >= 1) {
        wilcox.test(
          discharge_cms ~ Onset_timing,
          data = pick(discharge_cms, Onset_timing),
          exact = FALSE
        )
      } else {
        NULL
      }
    ),

    W = if (!is.null(test_result[[1]])) unname(test_result[[1]]$statistic) else NA_real_,
    p_value = if (!is.null(test_result[[1]])) test_result[[1]]$p.value else NA_real_,

    Interpretation = if (!is.null(test_result[[1]]) && test_result[[1]]$p.value > 0.05) {
      "No evidence of a difference between pre and post."
    } else if (!is.null(test_result[[1]])) {
      "Evidence of a difference between pre and post."
    } else {
      "Test not performed (insufficient data)."
    },

    .groups = "drop"
  )

view(wilcox_station_late)
```

```{r}
direction_by_station <- discharge_data %>%
  filter(!is.na(discharge_cms),
         Onset_timing %in% c("pre", "post")) %>%
  group_by(station_nm, onset_season) %>%
  summarise(
    median_discharge = median(discharge_cms, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  tidyr::pivot_wider(
    names_from = onset_season,
    values_from = median_discharge
  ) %>%
  mutate(
    Direction_early = case_when(
      post_early > pre_early ~ "post > pre",
      post_early < pre_early ~ "post < pre",
      TRUE       ~ "no difference"
    )
  ) %>%
  mutate(
    Direction_late = case_when(
      post_late > pre_late ~ "post > pre",
      post_late < pre_late ~ "post < pre",
      TRUE       ~ "no difference"
    )
  )

view(direction_by_station)
```

## Welch t-test 
for the total discharge per year because total discharge was normally distributed
```{r}
library(dplyr)
library(rstatix)
library(purrr)

ttest_by_station <- discharge_data_onset %>%
  filter(!is.na(average_discharge_cms),
         onset_timing %in% c("pre", "post")) %>%
  group_by(station_nm) %>%
  summarise(
    n_pre  = sum(onset_timing == "pre"),
    n_post = sum(onset_timing == "post"),

    test_result = list(
      if (n_pre >= 2 && n_post >= 2) {
        t.test(
          average_discharge_cms ~ onset_timing,
          data = pick(average_discharge_cms, onset_timing),
          var.equal = FALSE   # Welch t-test
        )
      } else {
        NULL
      }
    ),

    t_stat  = if (!is.null(test_result[[1]])) unname(test_result[[1]]$statistic) else NA_real_,
    df      = if (!is.null(test_result[[1]])) unname(test_result[[1]]$parameter) else NA_real_,
    p_value = if (!is.null(test_result[[1]])) test_result[[1]]$p.value else NA_real_,

    Interpretation = if (!is.null(test_result[[1]]) && test_result[[1]]$p.value > 0.05) {
      "No evidence of a difference between pre and post."
    } else if (!is.null(test_result[[1]])) {
      "Evidence of a difference between pre and post."
    } else {
      "Test not performed (insufficient data)."
    },

    .groups = "drop"
  )

view(ttest_by_station)
```

##Emmeans
```{r}
Dahl_Discharge_data_model <- lm(average_discharge_cms ~ onset_timing, data = cumulative_discharge_DahlCreek)
Dahl_Discharge_data_emm <- emmeans(Dahl_Discharge_data_model, ~ onset_timing)
Dahl_Discharge_data_contrast <- contrast(Dahl_Discharge_data_emm, method = "trt.vs.ctrl",
         ref = "pre")
print(Dahl_Discharge_data_contrast)

Kobuk_Discharge_data_model <- lm(average_discharge_cms ~ onset_timing, data = cumulative_discharge_KobukRiver)
Kobuk_Discharge_data_emm <- emmeans(Kobuk_Discharge_data_model, ~ onset_timing)
Kobuk_Discharge_data_contrast <- contrast(Kobuk_Discharge_data_emm, method = "trt.vs.ctrl",
         ref = "pre")
print(Kobuk_Discharge_data_contrast)

Slate_Discharge_data_model <- lm(average_discharge_cms ~ onset_timing, data = cumulative_discharge_SlateCreek)
Slate_Discharge_data_emm <- emmeans(Slate_Discharge_data_model, ~ onset_timing)
Slate_Discharge_data_contrast <- contrast(Slate_Discharge_data_emm, method = "trt.vs.ctrl",
         ref = "pre")
print(Slate_Discharge_data_contrast)

Wulik_Discharge_data_model <- lm(average_discharge_cms ~ onset_timing, data = cumulative_discharge_WulikRiver)
Wulik_Discharge_data_emm <- emmeans(Wulik_Discharge_data_model, ~ onset_timing)
Wulik_Discharge_data_contrast <- contrast(Wulik_Discharge_data_emm, method = "trt.vs.ctrl",
         ref = "pre")
print(Wulik_Discharge_data_contrast)
```

Average and SD for pre and post
```{r}
str(discharge_data)

discharge_summary <- discharge_data %>%
  filter(!is.na(Onset_timing)) %>%  # Filter only for relevant periods
  group_by(station_nm, Onset_timing) %>%
  summarise(
    n        = n(),
    Mean_Discharge = round(mean(discharge_cms, na.rm = TRUE), 2),
    SD_Discharge = round(sd(discharge_cms, na.rm = TRUE), 2),
    median_discharge = round(median(discharge_cms, na.rm = TRUE), 2),
    SE_discharge = sd(discharge_cms, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

view(discharge_summary)

discharge_summary_wide <- discharge_summary %>%
  dplyr::select(-SD_Discharge) %>%
  pivot_wider(
    names_from = Period,
    values_from = Mean_Discharge
  ) %>%
  mutate(difference = .[[3]] - .[[2]])

view(discharge_summary_wide)

#write_xlsx(discharge_summary_wide, "C:/Users/tayta/Downloads/Brooks Range Pre and Post Discharge Averages.xlsx")
```

Individual station data pulls
```{r}
# Download data from Wulik station
wulik <- "15747000"

# Define the time period
start_date <- "2000-01-01"
end_date <- "2024-12-31"

# Retrieve daily discharge data for all sites
wulik_discharge_data <- readNWISdv(
  siteNumbers = wulik, 
  parameterCd = "00060", 
  startDate = start_date, 
  endDate = end_date
)

wulik_discharge_data <- wulik_discharge_data %>%
  mutate(Year = year(Date)) %>%
  dplyr::rename(discharge_cfs = X_00060_00003)

# Create period groups and summarize
discharge_summary <- wulik_discharge_data %>%
  mutate(Period = case_when(
    Year >= 2000 & Year <= 2018 ~ "2000-2018",
    Year >= 2019 & Year <= 2024 ~ "2019-2024",
    TRUE ~ NA_character_  # Assign NA to other years
  )) %>%
  filter(!is.na(Period)) %>%  # Filter only for relevant periods
  summarise(
    Mean_Discharge = round(mean(discharge_cfs, na.rm = TRUE), 2),
    SD_Discharge = round(sd(discharge_cfs, na.rm = TRUE), 2),
    .by = Period
  )

view(discharge_summary)

write_xlsx(wulik_discharge_data, "C:/Users/tayta/Downloads/raw Wulik Discharge.xlsx")
write_xlsx(discharge_summary, "C:/Users/tayta/Downloads/Wulik Discharge Summary.xlsx")
```

```{r}
# Download data from Wulik station
Kobuk <- "15744500"

# Define the time period
start_date <- "2000-01-01"
end_date <- "2024-12-31"

# Retrieve daily discharge data for all sites
Kobuk_discharge_data <- readNWISdv(
  siteNumbers = Kobuk, 
  parameterCd = "00060", 
  startDate = start_date, 
  endDate = end_date
)

Kobuk_discharge_data <- Kobuk_discharge_data %>%
  mutate(Year = year(Date)) %>%
  dplyr::rename(discharge_cfs = X_00060_00003)

# Create period groups and summarize
Kobuk_discharge_summary <- Kobuk_discharge_data %>%
  mutate(Period = case_when(
    Year >= 2000 & Year <= 2018 ~ "2000-2018",
    Year >= 2019 & Year <= 2024 ~ "2019-2024",
    TRUE ~ NA_character_  # Assign NA to other years
  )) %>%
  filter(!is.na(Period)) %>%  # Filter only for relevant periods
  summarise(
    Mean_Discharge = round(mean(discharge_cfs, na.rm = TRUE), 2),
    SD_Discharge = round(sd(discharge_cfs, na.rm = TRUE), 2),
    .by = Period
  )

view(Kobuk_discharge_summary)

write_xlsx(Kobuk_discharge_data, "C:/Users/tayta/Downloads/raw Kobuk Discharge.xlsx")
write_xlsx(Kobuk_discharge_summary, "C:/Users/tayta/Downloads/Kobuk Discharge Summary.xlsx")
```

```{r}
Wulik_q.p <- ggplot(wulik_discharge_data, aes(x = Date, y = X_00060_00003, color = site_no)) +
  geom_line() +
  #facet_grid(station_nm~., scales = "free")+
  labs(x = "Date",
       y = "Discharge (cfs)") +
  theme_minimal()

Wulik_q.p
```

# Load Aggie Data
```{r}
Agashashok_River_Data <- read_excel("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Datasheets/Ferrum Manuscript Datasheets/Agashashok_Temporal_Data.xlsx",
                                    sheet = "all_data")
View(Agashashok_River_Data)
```

## Add column for year and season
```{r}
Agashashok_River_Data <- Agashashok_River_Data %>%
mutate(
    sample_collection_year = year(as.Date(sample_collection_date_mm_dd_yy)),
    sample_collection_month = month(as.Date(sample_collection_date_mm_dd_yy), label = TRUE, abbr = FALSE)
  ) %>%
  mutate(
    sample_collection_season = case_when(
      sample_collection_month %in% c("May", "June") ~ "early",
      sample_collection_month == "July" ~ "middle",
      sample_collection_month %in% c("August", "September") ~ "late",
      TRUE ~ NA_character_
    )
  ) %>%
  relocate(sample_collection_year, sample_collection_month, sample_collection_season, .after = SamplingEventID)

View(Agashashok_River_Data)
```

```{r}
# Add a column for the count of each sample site
Aggie_SiteID_counts <- Agashashok_River_Data %>%
  count(SiteID_mod, name = "SiteID_total_count")

view(Aggie_SiteID_counts)

# join the count column to the total df
Agashashok_River_Data_with_counts <- Agashashok_River_Data %>%
 left_join(Aggie_SiteID_counts, by = "SiteID_mod") %>%
  relocate(SiteID_total_count, .after = SiteID_mod)

view(Agashashok_River_Data_with_counts)

# select site ID's that have been sampled at least 5 times
Agashashok_River_Data_filtered <- Agashashok_River_Data_with_counts %>%
  filter(SiteID_total_count > 4)

# list of sites that have been sampled since 2015
site_counts_by_year <- Agashashok_River_Data_filtered %>%
  count(sample_collection_year, SiteID_mod, name = "count_per_year") %>%
  filter(sample_collection_year == "2015")

view(site_counts_by_year)

write_xlsx(site_counts_by_year, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Aggie temporal sites per subcatchment.xlsx")
```

## Plot SiteID by year
```{r}
sampling_count <- 
  ggplot(Agashashok_River_Data_filtered, aes(x = SiteID_mod, y = SiteID_total_count)) +
  geom_point(aes(color = SiteID_mod)) +
  labs(
    title = "Total Sample Count per Site",
    x = "Site ID",
    y = "Total Count"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)  # tilt labels if many sites
  )

sampling_count
```

## Data for plots
```{r}
Agashashok_for_plots <- Agashashok_River_Data %>%
  #filter(SiteID_mod %in% site_counts_by_year$SiteID_mod) %>% # this was for when I was selecting only a certain set of sites to plot
  dplyr::select(ParkID,
                Watershed,
                #Subcatchment,
                #New_Groups,
                #New_Grouping,
                Field_label,
                SiteID_mod,
                #SiteID_total_count,
                Latitude,
                Longitude,
                sample_collection_year,
                sample_collection_month,
                sample_collection_season,
                #Watershed_Area,
                #Relative_MS_Watershed_Area,
                SamplingEventID,
                #VisualDescription,
                #Site_Classification,
                #Hyd_Classification,
                #Distance_km,
                #Elevation_ft,
                pH,
                Temp_deg_celsius,
                Diss_oxy_mg_per_l,
                Diss_oxy_percent_sat,
                Spec_Cond_microS_per_cm,
                DIC_mgC_per_l,
                Alk_mgCaCO3_per_l,
                DOC_mgC_per_l,
                f_Cl_mg_per_l,
                f_NO3_mgN_per_l,
                f_SO4_mg_per_l,
                f_Ca_mg_l,
                f_Mg_mg_l,
                f_Na_mg_l,
                f_K_mg_l,
                HCO3_mg_L)

# convert data columns to numeric
Agashashok_for_plots <- Agashashok_for_plots %>%
  mutate(across(11:26, as.numeric))

# remove sampled seeps from the dataframe
Agashashok_for_plots <- Agashashok_for_plots %>%
  filter(!grepl("seep", SamplingEventID, ignore.case = TRUE))

view(Agashashok_for_plots)

write_xlsx(Agashashok_for_plots, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Aggie temporal df.xlsx")
```

# Red Dog Temporal Analysis
```{r}
ADF_G_all_stns <- read_excel("C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Ferrum Project/Red Dog Data/FW_ Red Dog regional data/ADF&G all stns.xlsx")

View(ADF_G_all_stns)
```

## All years
```{r}
# this is a list of the metals to convert all units to ug/L in the datasheet
metals_to_convert <- c(
  "Aluminum","Barium","Cadmium","Chromium","Copper","Iron",
  "Lead","Manganese","Nickel","Selenium","Silver","Zinc",
  "Aluminum, dissolved","Barium, dissolved","Cadmium, dissolved","Chromium, dissolved",
  "Copper, dissolved","Iron, dissolved","Lead, dissolved","Manganese, dissolved",
  "Nickel, dissolved","Selenium, dissolved","Silver, dissolved","Zinc, dissolved"
)

Red_Dog_stn_9_ALL <- ADF_G_all_stns %>%
  filter(loc_name == "Station 9") %>%
  mutate(
    report_result_value = if_else(
      report_result_unit == "mg/L" & chemical_name %in% metals_to_convert,
      report_result_value * 1000,
      report_result_value
    ),
    report_result_unit = if_else(
      report_result_unit == "mg/L" & chemical_name %in% metals_to_convert,
      "ug/L",
      report_result_unit
    )
  )

unique(Red_Dog_stn_9_ALL$chemical_name)

# Aluminum, Cadmium, Copper, Lead, Manganese, Calcium, Magnesium, Bicarbonate (As CaCO3), Temperature, Field, Conductivity, Field
```

```{r}
Red_Dog_stn_9_ALL <- Red_Dog_stn_9_ALL %>%
  mutate(
    sample_collection_year = year(sample_date),
    sample_collection_month = month(sample_date, label = TRUE, abbr = TRUE)
  ) %>%
  mutate(
    sample_collection_season = case_when(
      sample_collection_month %in% c("May", "Jun") ~ "early",
      sample_collection_month == "Jul" ~ "middle",
      sample_collection_month %in% c("Aug", "Sep") ~ "late",
      TRUE ~ NA_character_
    )
  ) %>%
  relocate(sample_collection_year, sample_collection_month, sample_collection_season, .after = sample_date)
```

## 2015-2024
```{r}
Red_Dog_stn_9 <- Red_Dog_stn_9_ALL %>%
   mutate(sample_date = as.Date(sample_date)) %>%
  filter(lubridate::year(sample_date) >= 2015,
         lubridate::year(sample_date) <= 2024)
```

```{r}
Red_Dog_stn_9 <- Red_Dog_stn_9 %>%
  mutate(
    sample_collection_year = year(sample_date),
    sample_collection_month = month(sample_date, label = TRUE, abbr = TRUE)
  ) %>%
  mutate(
    sample_collection_season = case_when(
      sample_collection_month %in% c("May", "Jun") ~ "early",
      sample_collection_month == "Jul" ~ "middle",
      sample_collection_month %in% c("Aug", "Sep") ~ "late",
      TRUE ~ NA_character_
    )
  ) %>%
  relocate(sample_collection_year, sample_collection_month, sample_collection_season, .after = sample_date)
```


## Sulfate
```{r}
RD_sulfate <- Red_Dog_stn_9 %>%
  filter(chemical_name == "Sulfate") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) 

RD_sulfate_ALL <- Red_Dog_stn_9_ALL %>%
  filter(chemical_name == "Sulfate") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) 

#write_xlsx(RD_sulfate, "C:/Users/tevinger/Downloads/WulikR Station 9 Sulfate 2015 to 2024.xlsx")
```

```{r}
# sample size of each year_season

RD_sulfate_counts <- RD_sulfate %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  count(year_season)

print(RD_sulfate_counts)
```

```{r}
RD_Sulfate_temporal_bp <- RD_sulfate %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(year_season), y = report_result_value, fill = sample_collection_season)) +
  geom_boxplot(
    position = position_dodge2(width = 0.75), width = 0.55
    ) +
  scale_y_continuous(breaks = c(0,100,200,300,400,500,600,700,800,900,1000,1100,1200), labels = c(0,"",200,"",400,"",600,"",800,"",1000,"",1200)) +
  #scale_x_continuous(expand = expansion(mult = c(0.035, 0.025))) +
  scale_fill_manual(
    values = c("early" = "#e6bed6", "late" = "#bc5090")
  ) +
  coord_cartesian(ylim = c(0, 1200)) +
  geom_vline(xintercept = 9.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  #geom_vline(xintercept = 21.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  labs(
    title = NULL,
    #title = "Station 9 - Sulfate", 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    y = "Sulfate Concentration (mg/L)",
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

RD_Sulfate_temporal_bp

# library(plotly)
# Sulfate_temporal_bp_interactive <- ggplotly(Sulfate_temporal_bp)
# Sulfate_temporal_bp_interactive

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/SO4 seasonal temporal bp_V1.png", Sulfate_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

## dimensions for V3_smaller: w = 3.5, h = 4.25

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/Red Dog Temporal/Final_SO4 no labels.png", RD_Sulfate_temporal_bp, width = 4, height = 4.35, dpi = 300, bg = "transparent")
```

```{r}
RD_Sulfate_temporal_bp_ALL <- RD_sulfate_ALL %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = report_result_value, fill = sample_collection_season)) +
  geom_boxplot(
    position = position_dodge2(width = 0.75), width = 0.55
    ) +
  scale_y_continuous(breaks = c(0,100,200,300,400,500,600,700,800,900,1000,1100,1200), labels = c(0,"",200,"",400,"",600,"",800,"",1000,"",1200), expand = expansion(mult = c(0.02, 0.01))) +
  #scale_x_continuous(expand = expansion(mult = c(0.035, 0.025))) +
  scale_x_discrete(
    expand = expansion(mult = c(0.025, 0.025))
  ) +
  scale_fill_manual(
    values = c("early" = "#e6bed6", "late" = "#bc5090")
  ) +
  coord_cartesian(ylim = c(0, 1100)) +
   geom_vline(xintercept = 43.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  #geom_vline(xintercept = 22, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  labs(
    title = NULL,
    #title = "Station 9 - Sulfate", 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    y = "Sulfate Concentration (mg/L)",
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        # axis.text.y = element_blank(),
        # axis.ticks.x = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

RD_Sulfate_temporal_bp_ALL

# library(plotly)
# Sulfate_temporal_bp_interactive <- ggplotly(Sulfate_temporal_bp)
# Sulfate_temporal_bp_interactive

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/SO4 seasonal temporal bp_V1.png", Sulfate_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

## dimensions for V3_smaller: w = 3.5, h = 4.25

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/Red Dog Temporal/SI Final_SO4 bottom labels.png", RD_Sulfate_temporal_bp_ALL, width = 6.5, height = 5.3, dpi = 300, bg = "transparent")
```

## Alkalinity

```{r}
RD_alkalinity <- Red_Dog_stn_9 %>%
  filter(chemical_name == "Alkalinity (As CaC03)") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) 

RD_alkalinity_ALL <- Red_Dog_stn_9_ALL %>%
  filter(chemical_name == "Alkalinity (As CaC03)") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) 
```

```{r}
# sample size of each year_season

RD_alkalinity_counts <- RD_alkalinity %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  count(year_season)

print(RD_alkalinity_counts)
```

```{r}
RD_Alkalinity_temporal_bp <- RD_alkalinity %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = report_result_value, fill = sample_collection_season)) +
  geom_boxplot(
    #position = position_dodge2(width = 0.95), 
    width = 0.55
    ) +
  coord_cartesian(ylim = c(0,150)) +
  scale_y_continuous(breaks = c(0,25, 50,75,100,125,150,175,200,225), labels = c(0,"", 50, "", 100, "",150, "", 200, ""),expand = expansion(mult = c(0.02, 0.01))) +
  scale_x_discrete(
    expand = expansion(mult = c(0.05, 0.05))
  ) +
  scale_fill_manual(
    values = c("early" = "#e6bed6", "late" = "#bc5090")
  ) +
  # Add counts as text
  # geom_vline(xintercept = 4.5, linetype = "dashed", color = "black", size = 0.9, alpha = 0.7) +
  geom_vline(xintercept = 9.5, linetype = "dashed", color = "black", size = 0.9, alpha = 0.7) +
  labs(
    title = NULL,
    #title = "Station 9 - Alkalinity", 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    y = ylab_Alk,
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(
    legend.position = "none",
    legend.text = element_text(size = 8),       # smaller legend labels
    legend.title = element_text(size = 8),      # smaller legend title
    legend.key.size = unit(2, "cm"),
    axis.text.y = element_blank(),
    #axis.ticks.x = element_blank(),
    #axis.text.x = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.background = element_rect(fill = "transparent", color = NA),
    panel.background = element_rect(fill = "transparent", color = NA))

RD_Alkalinity_temporal_bp

# library(plotly)
# Alkalinity_temporal_bp_interactive <- ggplotly(Alkalinity_temporal_bp)
# Alkalinity_temporal_bp_interactive

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Alkalinity seasonal temporal bp_V1.png", Alkalinity_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Alkalinity seasonal temporal bp_V2.png", Alkalinity_temporal_bp, width = 5, height = 5, dpi = 300, bg = "transparent")

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/Red Dog Temporal/smaller SI Final_Alk bottom labels.png", RD_Alkalinity_temporal_bp, width = 3.5, height = 5, dpi = 300, bg = "transparent")
```

## SO4 vs Alk
```{r}
RD_SO4_alk <- Red_Dog_stn_9 %>%
  filter(chemical_name %in% c("Alkalinity (As CaC03)", "Sulfate")) %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) 

RD_SO4_alk_ALL <- Red_Dog_stn_9_ALL %>%
  filter(chemical_name %in% c("Alkalinity (As CaC03)", "Sulfate")) %>%
  dplyr::select(sample_date, chemical_name, report_result_value) 
  # mutate(year_season = paste(sample_collection_year,
  #                            sample_collection_season,
  #                            sep = "_")) %>%
  # arrange(chemical_name)

RD_SO4_alk_ALL_wide <- RD_SO4_alk_ALL %>%
  add_count(sample_date, chemical_name) %>%
  filter(n == 1) %>%        # keeps only non-duplicated combos
  dplyr::select(-n) %>%
  pivot_wider(
    names_from = chemical_name,     # column that becomes new column headers
    values_from = report_result_value     # column that fills the values
  ) %>%
  filter(!is.na("Alalinity (As CaCO3)"))

names(RD_SO4_alk_ALL_wide)[3] <- "Alk"

dups <- RD_SO4_alk_ALL %>%
  #filter(unique_ID == "2024-06-03_2024-06-03 11:57:00")
  group_by(across(9)) %>%   # columns 1–7 (ID cols) and column 8 (names_from)
  summarise(n = n(), .groups = "drop") %>%
  filter(n > 1)

#write_xlsx(RD_SO4_alk_ALL, "C:/Users/tevinger/Downloads/RD_SO4_alk data.xlsx")
```

```{r}
SO4_alk <- ggplot(RD_SO4_alk_ALL_wide,
       aes(x = Alk, y = Sulfate, color = sample_date)) +
  geom_point(size = 2) +
  coord_cartesian(ylim = c(5,1100), xlim = c(15,200)) +
  labs(
    x = "Alkalinity (mg CaCO₃/L)",
    y = "Filtered SO₄ (mg/L)",
    title = "SO₄ vs Alkalinity"
  ) +
  scale_x_log10() +
  scale_y_log10() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  theme_minimal()


SO4_alk
```

## pH
```{r}
RD_pH <- Red_Dog_stn_9 %>%
  filter(chemical_name == "pH, Field") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) 

RD_pH_ALL <- Red_Dog_stn_9_ALL %>%
  filter(chemical_name == "pH, Field") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_"))
```

```{r}
# sample size of each year_season

RD_pH_counts <- RD_pH %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  count(year_season)

print(RD_pH_counts)
```

```{r}
RD_pH_temporal_bp <- RD_pH_ALL %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = report_result_value, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.95)) +
  #coord_cartesian(ylim = c(7.6, 8.52)) +
  #scale_y_continuous(breaks = c(7.5, 7.75, 8.0, 8.25, 8.5), labels = c("7.50", 7.75, "8.00", 8.25, "8.50")) +
  #scale_x_continuous(expand = expansion(mult = c(0.035, 0.025))) +
  scale_fill_manual(
    values = c("early" = "#e6bed6", "late" = "#bc5090")
  ) +
  # Add counts as text
  # geom_vline(xintercept = 4.5, linetype = "dashed", color = "black", size = 0.9, alpha = 0.7) +
  geom_vline(xintercept = 19.5, linetype = "dashed", color = "black", size = 0.9, alpha = 0.7) +
  labs(
    title = NULL,
    #title = "Station 9 - pH", 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    y = ylab_Alk,
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        #axis.text.y = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

RD_pH_temporal_bp

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/pH seasonal temporal bp_V1.png", pH_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/Red Dog Temporal/pH for all years.png", RD_pH_temporal_bp, width = 7, height = 5, dpi = 300, bg = "transparent")
```

## Iron
```{r}
RD_iron <- Red_Dog_stn_9 %>%
  filter(chemical_name == "Iron") %>%
  filter(fraction == "T") %>%
  # filter(fraction == "D") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) 

RD_iron_ALL <- Red_Dog_stn_9_ALL %>%
  filter(chemical_name == "Iron") %>%
  #filter(fraction == "T") %>%
  #filter(fraction == "D") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) %>%
  mutate(
    report_result_value = if_else(
      report_result_unit == "mg/L",
      report_result_value * 1000,
      report_result_value
    ),
    report_result_unit = if_else(
      report_result_unit == "mg/L",
      "ug/L",
      report_result_unit
    )
  )
  #filter(lubridate::year(sample_date) >= 2011)
```

```{r}
# sample size of each year_season

RD_iron_counts <- RD_iron %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  count(year_season)

print(RD_iron_counts)
```

```{r}
RD_Iron_temporal_bp <- RD_iron_ALL %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = report_result_value, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.75), width = 0.55) +
  #scale_y_continuous(breaks = c(0,25,50,75,100,125,150,175,200,225,250), labels = c(0, "", 50, "", 100, "", 150, "", 200, "", 250)) +
  #scale_x_continuous(expand = expansion(mult = c(0.035, 0.025))) +
  scale_y_log10() +
  scale_fill_manual(
    values = c("early" = "#e6bed6", "late" = "#bc5090")
  ) +
  #coord_cartesian(ylim = c(0, 250)) +
  # Add counts as text
  #geom_vline(xintercept = 4.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  geom_vline(xintercept = 21.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  labs(
    title = NULL,
    #title = "Station 9 - Iron", 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    #y = NULL,
    y = "Concentration (µg/L)",
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        #axis.text.x = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

RD_Iron_temporal_bp

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Cl seasonal temporal bp_V1.png", Chloride_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/Red Dog Temporal/Iron_1998 to 2024.png", RD_Iron_temporal_bp, width = 7, height = 5, dpi = 300, bg = "transparent")
```

## Nickel
```{r}
RD_nickel <- Red_Dog_stn_9 %>%
  filter(chemical_name == "Nickel, dissolved") %>%
  #filter(fraction == "T") %>%
  # filter(fraction == "D") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) 

RD_nickel_ALL <- Red_Dog_stn_9_ALL %>%
  filter(chemical_name == "Nickel") %>%
  #filter(fraction == "T") %>%
  #filter(fraction == "D") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) 
  # mutate(
  #   report_result_value = if_else(
  #     report_result_unit == "mg/L",
  #     report_result_value * 1000,
  #     report_result_value
  #   ),
  #   report_result_unit = if_else(
  #     report_result_unit == "mg/L",
  #     "ug/L",
  #     report_result_unit
  #   )
  # )
  #filter(lubridate::year(sample_date) >= 2011)
```

```{r}
# sample size of each year_season

RD_iron_counts <- RD_iron %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  count(year_season)

print(RD_iron_counts)
```

```{r}
## Need to make this a continuous scale with the missing years
RD_Nickel_temporal_bp <- RD_nickel_ALL %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = report_result_value, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.95)) +
  #scale_y_continuous(breaks = c(0,25,50,75,100,125,150,175,200,225,250), labels = c(0, "", 50, "", 100, "", 150, "", 200, "", 250)) +
  #scale_x_continuous(expand = expansion(mult = c(0.035, 0.025))) +
  scale_y_log10() +
  scale_fill_manual(
    values = c("early" = "#e6bed6", "late" = "#bc5090")
  ) +
  #coord_cartesian(ylim = c(0, 250)) +
  # Add counts as text
  #geom_vline(xintercept = 4.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  labs(
    #title = NULL,
    title = "Station 9 - Nickel", 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    #y = NULL,
    y = "Concentration (µg/L)",
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        #axis.text.y = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

RD_Nickel_temporal_bp

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Cl seasonal temporal bp_V1.png", Chloride_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/Red Dog Temporal/Iron_2011 to 2024.png", RD_Iron_temporal_bp, width = 7, height = 5, dpi = 300, bg = "transparent")
```

## Zinc
```{r}
RD_zinc <- Red_Dog_stn_9 %>%
  filter(chemical_name == "Zinc") %>%
  #filter(fraction == "T") %>%
  # filter(fraction == "D") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_"))

RD_zinc_ALL <- Red_Dog_stn_9_ALL %>%
  filter(chemical_name == "Zinc") %>%
  #filter(fraction == "T") %>%
  #filter(fraction == "D") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) 
  #filter(lubridate::year(sample_date) >= 2011)

#write_xlsx(RD_zinc, "C:/Users/tevinger/Downloads/WulikR Station 9 Zinc 2015 to 2024.xlsx")

```

```{r}
n_x <- length(levels(as.factor(RD_zinc$year_season)))
```

```{r}
RD_Zinc_temporal_bp <- RD_zinc %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = report_result_value, fill = sample_collection_season)) +
  geom_boxplot(
    #position = position_dodge(width = 0.75), 
               width = 0.55) +
  #scale_y_log10() +
  # annotation_logticks(sides = "l") +
  scale_fill_manual(
    values = c("early" = "#e6bed6", "late" = "#bc5090")
  ) +
  coord_cartesian(ylim = c(50, 4650)) +
  scale_y_continuous(breaks = c(0,500,1000,1500,2000,2500,3000,3500,4000,4500,5000), labels = c(0,"",1000,"",2000,"",3000,"",4000,"",5000), expand = expansion(mult = c(0.02, 0.01))) +
  scale_x_discrete(
    expand = expansion(mult = c(0.05, 0.05))
  ) +
  geom_vline(xintercept = 9.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  labs(
    title = NULL,
    #title = "Station 9 - Zinc", 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    #y = NULL,
    y = "Concentration (µg/L)",
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(
    legend.position = "none",
    legend.text = element_text(size = 8),       # smaller legend labels
    legend.title = element_text(size = 8),      # smaller legend title
    legend.key.size = unit(2, "cm"),
    axis.text.y = element_blank(),
    #axis.ticks.x = element_blank(),
    #axis.text.x = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.background = element_rect(fill = "transparent", color = NA),
    panel.background = element_rect(fill = "transparent", color = NA))

RD_Zinc_temporal_bp

# library(plotly)
# RD_Zinc_temporal_bp_interactive <- ggplotly(RD_Zinc_temporal_bp)
# RD_Zinc_temporal_bp_interactive

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Cl seasonal temporal bp_V1.png", Chloride_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/Red Dog Temporal/smaller SI Final_Zn bottom labels.png", RD_Zinc_temporal_bp, width = 3.5, height = 5, dpi = 300, bg = "transparent")
```

## Cadmium
```{r}
RD_Cd <- Red_Dog_stn_9 %>%
  filter(chemical_name == "Cadmium") %>%
  #filter(fraction == "T") %>%
  # filter(fraction == "D") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_"))

RD_Cd_ALL <- Red_Dog_stn_9_ALL %>%
  filter(chemical_name == "Cadmium") %>%
  #filter(fraction == "T") %>%
  #filter(fraction == "D") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) 
  #filter(lubridate::year(sample_date) >= 2011)

#write_xlsx(RD_zinc, "C:/Users/tevinger/Downloads/WulikR Station 9 Zinc 2015 to 2024.xlsx")

```

```{r}
RD_Cd_temporal_bp <- RD_Cd_ALL %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = report_result_value, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.75), width = 0.55) +
  #scale_y_continuous(breaks = c(0,25,50,75,100,125,150,175,200,225,250), labels = c(0, "", 50, "", 100, "", 150, "", 200, "", 250)) +
  #scale_x_continuous(expand = expansion(mult = c(0.035, 0.025))) +
  scale_y_log10() +
  annotation_logticks(sides = "l") +
  scale_fill_manual(
    values = c("early" = "#e6bed6", "late" = "#bc5090")
  ) +
  #coord_cartesian(ylim = c(50, 60000)) +
  # Add counts as text
  #geom_vline(xintercept = 4.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  geom_vline(xintercept = 21.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  labs(
    title = NULL,
    #title = "Station 9 - Cadmium", 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    #y = NULL,
    y = "Concentration (µg/L)",
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        #axis.text.y = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

RD_Cd_temporal_bp

# library(plotly)
# RD_Zinc_temporal_bp_interactive <- ggplotly(RD_Zinc_temporal_bp)
# RD_Zinc_temporal_bp_interactive

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Cl seasonal temporal bp_V1.png", Chloride_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/Red Dog Temporal/Zinc_2015 to 2024.png", RD_Zinc_temporal_bp, width = 3.5, height = 4.25, dpi = 300, bg = "transparent")
```

## Aluminum
```{r}
RD_Al <- Red_Dog_stn_9 %>%
  filter(chemical_name == "Aluminum") %>%
  #filter(fraction == "T") %>%
  # filter(fraction == "D") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_"))

RD_Al_ALL <- Red_Dog_stn_9_ALL %>%
  filter(chemical_name == "Aluminum") %>%
  #filter(fraction == "T") %>%
  #filter(fraction == "D") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) 
  #filter(lubridate::year(sample_date) >= 2011)

#write_xlsx(RD_zinc, "C:/Users/tevinger/Downloads/WulikR Station 9 Zinc 2015 to 2024.xlsx")

```

```{r}
RD_Al_temporal_bp <- RD_Al_ALL %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = report_result_value, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.75), width = 0.55) +
  #scale_y_continuous(breaks = c(0,25,50,75,100,125,150,175,200,225,250), labels = c(0, "", 50, "", 100, "", 150, "", 200, "", 250)) +
  #scale_x_continuous(expand = expansion(mult = c(0.035, 0.025))) +
  scale_y_log10() +
  annotation_logticks(sides = "l") +
  scale_fill_manual(
    values = c("early" = "#e6bed6", "late" = "#bc5090")
  ) +
  #coord_cartesian(ylim = c(50, 60000)) +
  # Add counts as text
  #geom_vline(xintercept = 4.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  geom_vline(xintercept = 21.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  labs(
    title = NULL,
    #title = "Station 9 - Cadmium", 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    #y = NULL,
    y = "Concentration (µg/L)",
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        #axis.text.y = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

RD_Al_temporal_bp

# library(plotly)
# RD_Zinc_temporal_bp_interactive <- ggplotly(RD_Zinc_temporal_bp)
# RD_Zinc_temporal_bp_interactive

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Cl seasonal temporal bp_V1.png", Chloride_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/Red Dog Temporal/Zinc_2015 to 2024.png", RD_Zinc_temporal_bp, width = 3.5, height = 4.25, dpi = 300, bg = "transparent")
```

## SI - metals
```{r}
library(cowplot)

SI_metals <- plot_grid(RD_Iron_temporal_bp, RD_Zinc_temporal_bp, RD_Cd_temporal_bp, RD_Al_temporal_bp, ncol = 2)

SI_metals

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/Red Dog Temporal/SI metals_2015 to 2024.png", SI_metals, width = 12, height = 8, dpi = 300, bg = "transparent")
```

## Chloride
```{r}
RD_chloride <- Red_Dog_stn_9 %>%
  filter(chemical_name == "Chloride") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) 

RD_chloride_ALL <- Red_Dog_stn_9_ALL %>%
  filter(chemical_name == "Chloride") %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) 
```

```{r}
# sample size of each year_season

RD_chloride_counts <- RD_chloride %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  count(year_season)

print(RD_chloride_counts)
```

```{r}
RD_chloride_temporal_bp <- RD_chloride_ALL %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = report_result_value, fill = sample_collection_season)) +
  geom_boxplot(
    position = position_dodge2(width = 0.75), width = 0.55
    ) +
  #scale_y_continuous(breaks = c(0,25,50,75,100,125,150,175,200,225,250), labels = c(0, "", 50, "", 100, "", 150, "", 200, "", 250)) +
  scale_y_continuous(expand = expansion(mult = c(0.02, 0.01))) +
  scale_fill_manual(
    values = c("early" = "#e6bed6", "late" = "#bc5090")
  ) +
  scale_x_discrete(
    expand = expansion(mult = c(0.025, 0.025))
  ) +
  coord_cartesian(ylim = c(0, 10.3)) +
  # Add counts as text
  geom_vline(xintercept = 43.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  #geom_vline(xintercept = 22, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  labs(
    title = NULL,
    #title = "Station 9 - Iron", 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    y = NULL,
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        #axis.text.y = element_blank(),
        # axis.ticks.x = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

RD_chloride_temporal_bp

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/Red Dog Temporal/SI Final_Cl bottom labels.png", RD_chloride_temporal_bp, width = 6.5, height = 5.3, dpi = 300, bg = "transparent")

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Cl seasonal temporal bp_V1.png", Chloride_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/Red Dog Temporal/Chloride with all years.png", RD_chloride_temporal_bp, width = 7, height = 5, dpi = 300, bg = "transparent")
```

## SO4/Cl
```{r}
RD_SO4_Cl_ALL <- Red_Dog_stn_9_ALL %>%
  filter(chemical_name %in% c("Chloride", "Sulfate")) %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_"))

RD_SO4_Cl_clean_ALL <- RD_SO4_Cl_ALL %>%
  # select the columns I need to do the SO4:Cl calculation
  dplyr::select(
    sample_date,
    year_season,
    sample_collection_year,
    sample_collection_month,
    sample_collection_season,
    task_code,
    chemical_name,
    report_result_value
  ) %>%
  # group by these variables to group the duplicates together
    group_by(
    sample_date,
    year_season,
    sample_collection_year,
    sample_collection_month,
    sample_collection_season,
    task_code,
    chemical_name
  ) %>%
  # calculate the mean values for the duplicates and use that in place of the individual reported values
  summarise(
    report_result_value = mean(report_result_value, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  # pivot wider with no more duplicates
  pivot_wider(
    id_cols = c(
      sample_date,
      year_season,
      sample_collection_year,
      sample_collection_month,
      sample_collection_season,
      task_code
    ),
    names_from  = chemical_name,
    values_from = report_result_value
  ) %>%
  mutate(
    # 1. Convert mg/L → mmol/L  (divide by molecular weight in g/mol = mg/mmol)

    Chloride_mM  = Chloride  / 35.45,  # Cl⁻
    Sulfate_mM = Sulfate / 96.06,  # SO₄²⁻ (as sulfate)

    # 2. Molar SO4:Cl ratio
    SO4_to_Cl_molar  = Sulfate / Chloride
  )
```

```{r}
RD_SO4_Cl <- Red_Dog_stn_9 %>%
  filter(chemical_name %in% c("Chloride", "Sulfate")) %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_"))

RD_SO4_Cl_clean <- RD_SO4_Cl %>%
  # select the columns I need to do the SO4:Cl calculation
  dplyr::select(
    sample_date,
    year_season,
    sample_collection_year,
    sample_collection_month,
    sample_collection_season,
    task_code,
    chemical_name,
    report_result_value
  ) %>%
  # group by these variables to group the duplicates together
    group_by(
    sample_date,
    year_season,
    sample_collection_year,
    sample_collection_month,
    sample_collection_season,
    task_code,
    chemical_name
  ) %>%
  # calculate the mean values for the duplicates and use that in place of the individual reported values
  summarise(
    report_result_value = mean(report_result_value, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  # pivot wider with no more duplicates
  pivot_wider(
    id_cols = c(
      sample_date,
      year_season,
      sample_collection_year,
      sample_collection_month,
      sample_collection_season,
      task_code
    ),
    names_from  = chemical_name,
    values_from = report_result_value
  ) %>%
  mutate(
    # 1. Convert mg/L → mmol/L  (divide by molecular weight in g/mol = mg/mmol)

    Chloride_mM  = Chloride  / 35.45,  # Cl⁻
    Sulfate_mM = Sulfate / 96.06,  # SO₄²⁻ (as sulfate)

    # 2. Molar SO4:Cl ratio
    SO4_to_Cl_molar  = Sulfate / Chloride
  )
```

```{r}
# sample size of each year_season

RD_SO4_Cl_counts <- RD_SO4_Cl_clean %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  count(year_season)

print(RD_SO4_Cl_counts)
```

```{r}
RD_SO4_Cl_temporal_bp <- RD_SO4_Cl_clean_ALL %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = SO4_to_Cl_molar, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.75), width = 0.55) +
  scale_y_continuous(breaks = c(0,200,400,600,800,1000,1200,1400,1600), labels = c(0, "", 400, "", 800, "", 1200, "", 1600), expand = expansion(mult = c(0.02, 0.01))) +
  #scale_x_continuous(expand = expansion(mult = c(0.035, 0.025))) +
  #scale_y_log10() +
  scale_fill_manual(
    values = c("early" = "#e6bed6", "late" = "#bc5090")
  ) +
  scale_x_discrete(
    expand = expansion(mult = c(0.025, 0.025))
  ) +
  coord_cartesian(ylim = c(0, 1600)) +
  # Add counts as text
  # geom_vline(xintercept = 4.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  geom_vline(xintercept = 43.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  labs(
    title = NULL,
    #title = "Station 9 - SO4:Cl, 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    y = NULL,
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        #axis.text.y = element_blank(),
        # axis.ticks.x = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

RD_SO4_Cl_temporal_bp

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Cl seasonal temporal bp_V1.png", Chloride_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/Red Dog Temporal/SI Final_SO4 Cl ratio bottom labels.png", RD_SO4_Cl_temporal_bp, width = 6.5, height = 5.3, dpi = 300, bg = "transparent")
```

## Ca:SO4
```{r}
## Ca/SO4
RD_Ca_SO4_ALL <- Red_Dog_stn_9_ALL %>%
  filter(chemical_name %in% c("Calcium", "Sulfate")) %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_"))

RD_Ca_SO4_clean_ALL <- RD_Ca_SO4_ALL %>%
  # Select columns needed for ratio calculation
  dplyr::select(
    sample_date,
    year_season,
    sample_collection_year,
    sample_collection_month,
    sample_collection_season,
    task_code,
    chemical_name,
    report_result_value
  ) %>%
  # Collapse duplicates
  group_by(
    sample_date,
    year_season,
    sample_collection_year,
    sample_collection_month,
    sample_collection_season,
    task_code,
    chemical_name
  ) %>%
  summarise(
    report_result_value = mean(report_result_value, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  # Pivot wide
  pivot_wider(
    id_cols = c(
      sample_date,
      year_season,
      sample_collection_year,
      sample_collection_month,
      sample_collection_season,
      task_code
    ),
    names_from  = chemical_name,
    values_from = report_result_value
  ) %>%
  mutate(
    # Convert mg/L -> mmol/L (mg/mmol = MW in g/mol)
    Calcium_mM  = Calcium / 40.078,   # Ca2+
    Sulfate_mM  = Sulfate / 96.06,    # SO4--

    # Molar Ca:SO4 ratio
    Ca_to_SO4_molar = Calcium_mM / Sulfate_mM
  ) %>%
  filter(lubridate::year(sample_date) >= 1999)

```

```{r}
RD_Ca_SO4 <- Red_Dog_stn_9 %>%
  filter(chemical_name %in% c("Calcium", "Sulfate")) %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_"))

RD_Ca_SO4_clean <- RD_Ca_SO4 %>%
  dplyr::select(
    sample_date,
    year_season,
    sample_collection_year,
    sample_collection_month,
    sample_collection_season,
    task_code,
    chemical_name,
    report_result_value
  ) %>%
  group_by(
    sample_date,
    year_season,
    sample_collection_year,
    sample_collection_month,
    sample_collection_season,
    task_code,
    chemical_name
  ) %>%
  summarise(
    report_result_value = mean(report_result_value, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  pivot_wider(
    id_cols = c(
      sample_date,
      year_season,
      sample_collection_year,
      sample_collection_month,
      sample_collection_season,
      task_code
    ),
    names_from  = chemical_name,
    values_from = report_result_value
  ) %>%
  mutate(
    Calcium_mM  = Calcium / 40.078,
    Sulfate_mM  = Sulfate / 96.06,
    Ca_to_SO4_molar = Calcium_mM / Sulfate_mM
  )

```

```{r}
RD_Ca_SO4_counts <- RD_Ca_SO4_clean %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  count(year_season)

print(RD_Ca_SO4_counts)

```

```{r}
RD_Ca_SO4_temporal_bp <- RD_Ca_SO4_clean_ALL %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year),
             y = Ca_to_SO4_molar,
             fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.95)) +
  scale_y_log10() +
  scale_fill_manual(
    values = c("early" = "#A1E3F9", "late" = "#0a7ea4")
  ) +
  geom_vline(xintercept = 21.5, linetype = "dashed",
             color = "black", size = 0.8, alpha = 0.7) +
  labs(
    title = NULL,
    x = "Year",
    y = NULL,
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.background = element_rect(fill = "transparent", color = NA),
    panel.background = element_rect(fill = "transparent", color = NA)
  )

RD_Ca_SO4_temporal_bp

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/Red Dog Temporal/Red Dog Ca_to_SO4_for_all_years_V2.png",
       RD_Ca_SO4_temporal_bp,
       width = 7, height = 5, dpi = 300, bg = "transparent")

```

# Station 9 stats

```{r}
RD_temporal_stats <- Red_Dog_stn_9 %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  dplyr::select(4,9,10,11,12,42,45,28) %>% # selecting the columns I want (28 is the analysis date that I'm hoping to use as a unique identifier for pivotting wider)
  mutate(
    year_season = paste(sample_collection_year, sample_collection_season, sep = "_") 
  ) %>%
   mutate(
    Temporal_status = ifelse(year_season %in% c("2015_early", "2016_early", "2017_early", "2018_early", "2019_early", "2015_late", "2016_late", "2017_late", "2018_late"), 'pre',
                      ifelse(year_season %in% c("2019_late", "2020_early", "2020_late", "2021_early", "2021_late", "2022_early", "2022_late", "2023_early", "2023_late", "2024_early", "2024_late"), 'post', NA))
  ) %>%
  mutate(
    temporal_status_season = paste(Temporal_status, sample_collection_season, sep = "_")
  ) %>%
  relocate(temporal_status_season, Temporal_status, analysis_date, .after = sample_date) %>%
  mutate(Temporal_status = factor(Temporal_status, levels = c("pre", "post")))
```


```{r}
RD_early_temporal_stats <- RD_temporal_stats %>%
  filter(sample_collection_season == "early") %>%
  mutate(Temporal_status = factor(Temporal_status, levels = c("pre", "post")))

RD_late_temporal_stats <- RD_temporal_stats %>%
  filter(sample_collection_season == "late") %>%
  mutate(Temporal_status = factor(Temporal_status, levels = c("pre", "post")))
```

```{r}
RD_data_2018_2019 <- RD_temporal_stats %>%
  filter(sample_collection_year %in% c("2015", "2016", "2017", "2018", "2019", "2020", "2021", "2022", "2023", "2024")) %>%
  dplyr::select(4,6,8,9,10)

RD_data_2018_2019_summary <- RD_data_2018_2019 %>%
  filter(chemical_name %in% c("Alkalinity (As CaC03)", "Sulfate")) %>%
  #group_by(chemical_name, sample_collection_season, sample_collection_year) %>%
   # group_by(chemical_name, sample_collection_year) %>%
  group_by(chemical_name, sample_collection_season, Temporal_status) %>%
  summarise(
    n        = n(),                     # number of values
    mean     = mean(report_result_value, na.rm = TRUE),
    median   = median(report_result_value, na.rm = TRUE),
    sd       = sd(report_result_value, na.rm = TRUE),
    se       = sd(report_result_value, na.rm = TRUE) / sqrt(n()),
    min      = min(report_result_value, na.rm = TRUE),
    max      = max(report_result_value, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(sample_collection_season == "late")

write_xlsx(RD_data_2018_2019_summary, "C:/Users/tevinger/Downloads/late season pre and post Station 9 alkalinity and sulfate.xlsx")
```

```{r}
dups_1 <- RD_early_temporal_stats %>%
  #filter(unique_ID == "2024-06-03_2024-06-03 11:57:00")
  group_by(across(1:9)) %>%   # columns 1–7 (ID cols) and column 8 (names_from)
  summarise(n = n(), .groups = "drop") %>%
  filter(n > 1)

RD_early_temporal_stats_2 <- RD_early_temporal_stats %>%
 mutate(
    unique_ID = paste(sample_date, analysis_date, chemical_name, sep = "_")) %>%
  relocate(unique_ID, .after = analysis_date)
  
# remove duplicates because they are the exact same values
RD_early_temporal_stats_no_dupes <- RD_early_temporal_stats_2 %>%
  distinct(unique_ID, .keep_all = TRUE)

dups_2 <- RD_early_temporal_stats_no_dupes %>%
  #filter(unique_ID == "2024-06-03_2024-06-03 11:57:00")
  group_by(across(1:11)) %>%   # columns 1–7 (ID cols) and column 8 (names_from)
  summarise(n = n(), .groups = "drop") %>%
  filter(n > 1)

RD_early_temporal_stats_wide <- RD_early_temporal_stats_no_dupes %>%
  #dplyr::select(-c(analysis_date, unique_ID)) %>%
  pivot_wider(
    id_cols   = c(1:9),   # keep columns 1–7 as identifiers
    names_from  = 10,   # column 8 becomes the new headers
    values_from = 11    # column 9 fills the values
  )


```


## Summary Stats - pre and post
## Summary Stats
```{r}
RD_temporal_stats_summary <- RD_temporal_stats %>%
  filter(Temporal_status %in% c("pre", "post")) %>%   # keep only the two groups
  #filter(!is.na(report_result_value)) %>%
  group_by(chemical_name, Temporal_status) %>%
  # group_by(chemical_name, temporal_status_season) %>%
  summarise(
    n        = n(),                     # number of values
    mean     = mean(report_result_value, na.rm = TRUE),
    median   = median(report_result_value, na.rm = TRUE),
    sd       = sd(report_result_value, na.rm = TRUE),
    se       = sd(report_result_value, na.rm = TRUE) / sqrt(n()),
    min      = min(report_result_value, na.rm = TRUE),
    max      = max(report_result_value, na.rm = TRUE),
    .groups = "drop"
  )

view(RD_temporal_stats_summary)

# RD_temporal_stats_summary <- RD_temporal_stats_summary %>%
#   mutate(
#     temporal_status_season = factor(
#       temporal_status_season,
#       levels = c("pre_early", "pre_late", "post_early", "post_late")
#     )
#   ) %>%
#   arrange(chemical_name, temporal_status_season)

write_xlsx(RD_temporal_stats_summary, "C:/Users/tevinger/Downloads/Station 9 summary stats.xlsx")
```

## Early season Comparison
### Shapiro
```{r}
library(dplyr)
library(purrr)
library(broom)
library(rstatix)

# It must have: chemical_name, report_result_value, Temporal_status, and temporal_status_season
# Temporal_status is used to do a comparison of pre to post including both seasons
# temporal_status_season is used to compare pre to post within each season

data_long <- RD_early_temporal_stats  # <-- change to your df name

# List of columns to analyze
chemicals_to_model <- c("pH, Field", "Alkalinity (As CaC03)", "Aluminum", "Barium", 
  "Bicarbonate (As CaC03)", "Cadmium", "Chloride", "Conductivity, Field", "Copper", "Hardness, Total", "Temperature, Field", "Iron", "Lead", "Nickel", "Sulfate", "Zinc")

pdf("residuals_plots_long.pdf")  # Start a new PDF file

model_results <- list()

for (chem in chemicals_to_model) {
  
  # Filter data for this chemical
  df_chem <- data_long %>%
    filter(chemical_name == chem)
  
  # Optional: drop NAs in response or predictor
  df_chem <- df_chem %>%
    filter(!is.na(report_result_value), !is.na(Temporal_status))
  
  # Safety check: need enough data & at least 2 groups for the model
  if (nrow(df_chem) < 3 || dplyr::n_distinct(df_chem$Temporal_status) < 2) {
    model_results[[chem]] <- data.frame(
      Variable = chem,
      W = NA_real_,
      p_value = NA_real_,
      Interpretation = "Not enough data or only one Temporal_status level; model not fit."
    )
    next
  }
  
  # Fit the linear model: value ~ Temporal_status
  model <- lm(report_result_value ~ Temporal_status, data = df_chem)
  
  # Residuals
  residuals <- resid(model)
  
  # Residual histogram
  hist(
    residuals,
    main = paste("Residuals Histogram:", chem),
    xlab = "Residuals"
  )
  
  # QQ plot
  qqnorm(residuals, main = paste("QQ Plot of Residuals:", chem))
  qqline(residuals)
  
  # Shapiro-Wilk test on residuals
  test_result <- tryCatch(
    shapiro.test(residuals),
    error = function(e) NULL
  )
  
  # Interpretation text
  interpretation <- if (!is.null(test_result) && test_result$p.value > 0.05) {
    "The residuals are likely normally distributed (fail to reject H0)."
  } else if (!is.null(test_result)) {
    "The residuals are not normally distributed (reject H0) and a non-parametric test may be more appropriate."
  } else {
    "Test could not be performed due to insufficient data or errors."
  }
  
  # Store results
  model_results[[chem]] <- data.frame(
    Variable = chem,
    W = if (!is.null(test_result)) unname(test_result$statistic) else NA_real_,
    p_value = if (!is.null(test_result)) test_result$p.value else NA_real_,
    Interpretation = interpretation
  )
}

dev.off()  # Close the PDF

early_shapiro_results_long <- bind_rows(model_results)

View(early_shapiro_results_long)

write_xlsx(early_shapiro_results_long, "C:/Users/tevinger/Downloads/RD early_shapiro_results_long_12 30 2025.xlsx")

## -- NEW results --
## all not normally distributed
## Copper and Nickel had only one Temporal status so the model couldn't run for those

## --OLD results--
## pH, Alkalinity and Bicarboante are normally distributed and need to be compared with an ANOVA
```

### Not-Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

data_long <- RD_early_temporal_stats  # <-- change to your df name

# Variables that failed Shapiro (non-normal)
non_normal_vars <- c("pH, Field", "Alkalinity (As CaC03)", "Aluminum", "Barium", 
  "Bicarbonate (As CaC03)", "Cadmium", "Chloride", "Conductivity, Field", "Copper", "Hardness, Total", "Temperature, Field", "Iron", "Lead", "Nickel", "Sulfate", "Zinc")

# Function to run Wilcoxon test
run_wilcox_for_var <- function(var, data) {
  df_var <- data %>%
    filter(
      chemical_name == var,
      !is.na(report_result_value),
      !is.na(Temporal_status)
    )
  
  # Check for data sufficiency
  if (nrow(df_var) < 3 || n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "Wilcoxon rank-sum",
      statistic = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one group; test not run."
    ))
  }

  # Compute group sample sizes
  n_info <- df_var %>%
    count(Temporal_status) %>%
    pull(n)
  
  n1 <- n_info[1]
  n2 <- n_info[2]
  
  res <- wilcox_test(
    report_result_value ~ Temporal_status,
    data = df_var
  )
  
  res %>%
    mutate(
      variable = var,
      test = "Wilcoxon rank-sum",
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference (reject H0).",
        "No significant difference (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, p, Interpretation)
}

# Run Wilcoxon tests for all non-normal variables
wilcox_results <- map_dfr(non_normal_vars, run_wilcox_for_var, data = data_long)

view(wilcox_results)

## no difference for Lead, Temp, Chloride and Barium

# write_xlsx(wilcox_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/early season wilcox_results.xlsx")

write_xlsx(wilcox_results, "C:/Users/tevinger/Downloads/RD early wilcox_results_long_12 30 2025.xlsx")
```

### Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

# Long-format data frame
data_long <- RD_early_temporal_stats   # <-- replace with your df name

# Variables that passed Shapiro (normal)
normal_vars <- c("pH, Field", "Alkalinity (As CaC03)", "Bicarbonate (As CaC03)")

# Function to run t-test on one variable
run_t_for_var <- function(var, data) {
  df_var <- data %>%
    filter(
      chemical_name == var,
      !is.na(report_result_value),
      !is.na(Temporal_status)
    )
  
  # Check for data sufficiency
  if (nrow(df_var) < 3 || n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "t-test",
      statistic = NA_real_,
      df = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one group; test not run."
    ))
  }

  res <- t_test(
    report_result_value ~ Temporal_status,
    data = df_var,
    var.equal = FALSE  # Welch t-test
  )
  
  res %>%
    mutate(
      variable = var,
      test = "t-test",
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference (reject H0).",
        "No significant difference (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, df, p, Interpretation)
}

# Run t-tests for all normal variables
t_test_results <- map_dfr(normal_vars, run_t_for_var, data = data_long)

View(t_test_results)

write_xlsx(t_test_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/early season t_test results.xlsx")
```

## Late season
### Shapiro
```{r}
library(dplyr)
library(purrr)
library(broom)
library(rstatix)

# It must have: chemical_name, report_result_value, Temporal_status, and temporal_status_season
# Temporal_status is used to do a comparison of pre to post including both seasons

data_long <- RD_late_temporal_stats  # <-- change to your df name

# List of columns to analyze
chemicals_to_model <- c("pH, Field", "Alkalinity (As CaC03)", "Aluminum", "Barium", 
  "Bicarbonate (As CaC03)", "Cadmium", "Chloride", "Conductivity, Field", "Copper", "Hardness, Total", "Temperature, Field", "Iron", "Lead", "Nickel", "Sulfate", "Zinc")

pdf("residuals_plots_long.pdf")  # Start a new PDF file

model_results <- list()

for (chem in chemicals_to_model) {
  
  # Filter data for this chemical
  df_chem <- data_long %>%
    filter(chemical_name == chem)
  
  # Optional: drop NAs in response or predictor
  df_chem <- df_chem %>%
    filter(!is.na(report_result_value), !is.na(Temporal_status))
  
  # Safety check: need enough data & at least 2 groups for the model
  if (nrow(df_chem) < 3 || dplyr::n_distinct(df_chem$Temporal_status) < 2) {
    model_results[[chem]] <- data.frame(
      Variable = chem,
      W = NA_real_,
      p_value = NA_real_,
      Interpretation = "Not enough data or only one Temporal_status level; model not fit."
    )
    next
  }
  
  # Fit the linear model: value ~ Temporal_status
  model <- lm(report_result_value ~ Temporal_status, data = df_chem)
  
  # Residuals
  residuals <- resid(model)
  
  # Residual histogram
  hist(
    residuals,
    main = paste("Residuals Histogram:", chem),
    xlab = "Residuals"
  )
  
  # QQ plot
  qqnorm(residuals, main = paste("QQ Plot of Residuals:", chem))
  qqline(residuals)
  
  # Shapiro-Wilk test on residuals
  test_result <- tryCatch(
    shapiro.test(residuals),
    error = function(e) NULL
  )
  
  # Interpretation text
  interpretation <- if (!is.null(test_result) && test_result$p.value > 0.05) {
    "The residuals are likely normally distributed (fail to reject H0)."
  } else if (!is.null(test_result)) {
    "The residuals are not normally distributed (reject H0) and a non-parametric test may be more appropriate."
  } else {
    "Test could not be performed due to insufficient data or errors."
  }
  
  # Store results
  model_results[[chem]] <- data.frame(
    Variable = chem,
    W = if (!is.null(test_result)) unname(test_result$statistic) else NA_real_,
    p_value = if (!is.null(test_result)) test_result$p.value else NA_real_,
    Interpretation = interpretation
  )
}

dev.off()  # Close the PDF

late_shapiro_results_long <- bind_rows(model_results)

View(late_shapiro_results_long)

# write_xlsx(late_shapiro_results_long, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/late_shapiro_results_long.xlsx")

write_xlsx(late_shapiro_results_long, "C:/Users/tevinger/Downloads/RD LATE shapiro_results_long_12 30 2025.xlsx")

## Copper and Nickel had only one Temporal status so the model couldn't run for those
## Bicarboante Temp are normally distributed and need to be compared with an ANOVA
```

### Not-Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

data_long <- RD_early_temporal_stats  # <-- change to your df name

# Variables that failed Shapiro (non-normal)
non_normal_vars <- c("pH, Field", "Alkalinity (As CaC03)", "Aluminum", "Barium", "Cadmium", "Chloride", "Conductivity, Field", "Hardness, Total", "Iron", "Lead", "Sulfate", "Zinc")

# Function to run Wilcoxon test
run_wilcox_for_var <- function(var, data) {
  df_var <- data %>%
    filter(
      chemical_name == var,
      !is.na(report_result_value),
      !is.na(Temporal_status)
    )
  
  # Check for data sufficiency
  if (nrow(df_var) < 3 || n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "Wilcoxon rank-sum",
      statistic = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one group; test not run."
    ))
  }

  # Compute group sample sizes
  n_info <- df_var %>%
    count(Temporal_status) %>%
    pull(n)
  
  n1 <- n_info[1]
  n2 <- n_info[2]
  
  res <- wilcox_test(
    report_result_value ~ Temporal_status,
    data = df_var
  )
  
  res %>%
    mutate(
      variable = var,
      test = "Wilcoxon rank-sum",
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference (reject H0).",
        "No significant difference (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, p, Interpretation)
}

# Run Wilcoxon tests for all non-normal variables
wilcox_results <- map_dfr(non_normal_vars, run_wilcox_for_var, data = data_long)

view(wilcox_results)

## no difference for Lead, Alkalinity, Chloride and Barium

# write_xlsx(wilcox_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/late season wilcox_results.xlsx")

write_xlsx(wilcox_results, "C:/Users/tevinger/Downloads/RD LATE wilcox_results_long_12 30 2025.xlsx")
```

### Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

# Long-format data frame
data_long <- RD_late_temporal_stats   # <-- replace with your df name

# Variables that passed Shapiro (normal)
normal_vars <- c("Bicarbonate (As CaC03)", "Temperature, Field")

# Function to run t-test on one variable
run_t_for_var <- function(var, data) {
  df_var <- data %>%
    filter(
      chemical_name == var,
      !is.na(report_result_value),
      !is.na(Temporal_status)
    )
  
  # Check for data sufficiency
  if (nrow(df_var) < 3 || n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "t-test",
      statistic = NA_real_,
      df = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one group; test not run."
    ))
  }

  res <- t_test(
    report_result_value ~ Temporal_status,
    data = df_var,
    var.equal = FALSE  # Welch t-test
  )
  
  res %>%
    mutate(
      variable = var,
      test = "t-test",
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference (reject H0).",
        "No significant difference (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, df, p, Interpretation)
}

# Run t-tests for all normal variables
t_test_results <- map_dfr(normal_vars, run_t_for_var, data = data_long)

View(t_test_results)

## Significant difference in bicarbonate

# write_xlsx(t_test_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/late season t_test results.xlsx")

write_xlsx(t_test_results, "C:/Users/tevinger/Downloads/RD LATE t test_results_long_12 30 2025.xlsx")
```

## All seasons - pre vs post
### Shapiro
```{r}
library(dplyr)
library(purrr)
library(broom)
library(rstatix)

# It must have: chemical_name, report_result_value, Temporal_status, and temporal_status_season
# Temporal_status is used to do a comparison of pre to post including both seasons

data_long <- RD_temporal_stats  # <-- change to your df name

# List of columns to analyze
chemicals_to_model <- c("pH, Field", "Alkalinity (As CaC03)", "Aluminum", "Barium", 
  "Bicarbonate (As CaC03)", "Cadmium", "Chloride", "Conductivity, Field", "Copper", "Hardness, Total", "Temperature, Field", "Iron", "Lead", "Nickel", "Sulfate", "Zinc")

pdf("residuals_plots_long.pdf")  # Start a new PDF file

model_results <- list()

for (chem in chemicals_to_model) {
  
  # Filter data for this chemical
  df_chem <- data_long %>%
    filter(chemical_name == chem)
  
  # Optional: drop NAs in response or predictor
  df_chem <- df_chem %>%
    filter(!is.na(report_result_value), !is.na(Temporal_status))
  
  # Safety check: need enough data & at least 2 groups for the model
  if (nrow(df_chem) < 3 || dplyr::n_distinct(df_chem$Temporal_status) < 2) {
    model_results[[chem]] <- data.frame(
      Variable = chem,
      W = NA_real_,
      p_value = NA_real_,
      Interpretation = "Not enough data or only one Temporal_status level; model not fit."
    )
    next
  }
  
  # Fit the linear model: value ~ Temporal_status
  model <- lm(report_result_value ~ Temporal_status, data = df_chem)
  
  # Residuals
  residuals <- resid(model)
  
  # Residual histogram
  hist(
    residuals,
    main = paste("Residuals Histogram:", chem),
    xlab = "Residuals"
  )
  
  # QQ plot
  qqnorm(residuals, main = paste("QQ Plot of Residuals:", chem))
  qqline(residuals)
  
  # Shapiro-Wilk test on residuals
  test_result <- tryCatch(
    shapiro.test(residuals),
    error = function(e) NULL
  )
  
  # Interpretation text
  interpretation <- if (!is.null(test_result) && test_result$p.value > 0.05) {
    "The residuals are likely normally distributed (fail to reject H0)."
  } else if (!is.null(test_result)) {
    "The residuals are not normally distributed (reject H0) and a non-parametric test may be more appropriate."
  } else {
    "Test could not be performed due to insufficient data or errors."
  }
  
  # Store results
  model_results[[chem]] <- data.frame(
    Variable = chem,
    W = if (!is.null(test_result)) unname(test_result$statistic) else NA_real_,
    p_value = if (!is.null(test_result)) test_result$p.value else NA_real_,
    Interpretation = interpretation
  )
}

dev.off()  # Close the PDF

shapiro_results_long <- bind_rows(model_results)

View(shapiro_results_long)

write_xlsx(shapiro_results_long, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/both seasons shapiro_results_long.xlsx")

## Copper and Nickel had only one Temporal status so the model couldn't run for those
## Bicarboante and Alkalinity are normally distributed and need to be compared with an ANOVA
```

### Not-Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

data_long <- RD_temporal_stats  # <-- change to your df name

# Variables that failed Shapiro (non-normal)
non_normal_vars <- c("pH, Field", "Aluminum", "Barium", "Cadmium", "Chloride", "Conductivity, Field", "Copper", "Hardness, Total", "Temperature, Field", "Iron", "Lead", "Nickel", "Sulfate", "Zinc")

# Function to run Wilcoxon test
run_wilcox_for_var <- function(var, data) {
  df_var <- data %>%
    filter(
      chemical_name == var,
      !is.na(report_result_value),
      !is.na(Temporal_status)
    )
  
  # Check for data sufficiency
  if (nrow(df_var) < 3 || n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "Wilcoxon rank-sum",
      statistic = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one group; test not run."
    ))
  }

  # Compute group sample sizes
  n_info <- df_var %>%
    count(Temporal_status) %>%
    pull(n)
  
  n1 <- n_info[1]
  n2 <- n_info[2]
  
  res <- wilcox_test(
    report_result_value ~ Temporal_status,
    data = df_var
  )
  
  res %>%
    mutate(
      variable = var,
      test = "Wilcoxon rank-sum",
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference (reject H0).",
        "No significant difference (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, p, Interpretation)
}

# Run Wilcoxon tests for all non-normal variables
wilcox_results <- map_dfr(non_normal_vars, run_wilcox_for_var, data = data_long)

view(wilcox_results)

## no difference for Chloride and Temperature

write_xlsx(wilcox_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/all seasons wilcox_results.xlsx")
```

### Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

# Long-format data frame
data_long <- RD_temporal_stats   # <-- replace with your df name

# Variables that passed Shapiro (normal)
normal_vars <- c("Alkalinity (As CaC03)", "Bicarbonate (As CaC03)")

# Function to run t-test on one variable
run_t_for_var <- function(var, data) {
  df_var <- data %>%
    filter(
      chemical_name == var,
      !is.na(report_result_value),
      !is.na(Temporal_status)
    )
  
  # Check for data sufficiency
  if (nrow(df_var) < 3 || n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "t-test",
      statistic = NA_real_,
      df = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one group; test not run."
    ))
  }

  res <- t_test(
    report_result_value ~ Temporal_status,
    data = df_var,
    var.equal = FALSE  # Welch t-test
  )
  
  res %>%
    mutate(
      variable = var,
      test = "t-test",
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference (reject H0).",
        "No significant difference (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, df, p, Interpretation)
}

# Run t-tests for all normal variables
t_test_results <- map_dfr(normal_vars, run_t_for_var, data = data_long)

View(t_test_results)

## Significant difference in bicarbonate and alkalinity

write_xlsx(t_test_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/all seasons t_test results.xlsx")
```

## SO4:Cl stats
```{r}
# RD_SO4_Cl_clean_ALL made in SO4/Cl section
RD_SO4_Cl_clean_ALL_stats <- RD_SO4_Cl_clean_ALL %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  mutate(
    sample_collection_year = year(sample_date)
  ) %>%
  dplyr::select(1,3,4,5,11) %>% # selecting the columns I want (28 is the analysis date that I'm hoping to use as a unique identifier for pivotting wider)
   mutate(
    Temporal_status = ifelse(sample_collection_year %in% c(2015, 2016, 2017, 2018), 'pre',
                      ifelse(sample_collection_year %in% c(2019, 2020, 2021, 2022, 2023, 2024), 'post', NA))
  ) %>%
  mutate(
    temporal_status_season = paste(Temporal_status, sample_collection_season, sep = "_")
  ) %>%
  relocate(temporal_status_season, Temporal_status, .after = sample_date) %>%
  mutate(Temporal_status = factor(Temporal_status, levels = c("pre", "post"))) %>%
  filter(Temporal_status %in% c("pre", "post"))

```

```{r}
RD_SO4_Cl_clean_ALL_stats_summary <- RD_SO4_Cl_clean_ALL_stats %>%
  filter(Temporal_status %in% c("pre", "post")) %>%   # keep only the two groups
  group_by(Temporal_status) %>%
  summarise(
    n        = n(),                     # number of values
    mean     = mean(SO4_to_Cl_molar, na.rm = TRUE),
    median   = median(SO4_to_Cl_molar, na.rm = TRUE),
    sd       = sd(SO4_to_Cl_molar, na.rm = TRUE),
    se       = sd(SO4_to_Cl_molar, na.rm = TRUE) / sqrt(n()),
    min      = min(SO4_to_Cl_molar, na.rm = TRUE),
    max      = max(SO4_to_Cl_molar, na.rm = TRUE),
    .groups = "drop"
  )

#view(RD_temporal_stats_summary)

write_xlsx(RD_SO4_Cl_clean_ALL_stats_summary, "C:/Users/tevinger/Downloads/Red Dog Station 9 summary stats for SO4_Cl ratio.xlsx")
```

## Early season Comparison
### Shapiro
```{r}
# 1) Fit model and get residuals (lm will drop NAs automatically)
model <- lm(SO4_Cl_molar ~ 1, data = RD_SO4_Cl_clean_ALL_stats)
resids <- resid(model)

# 2) Run Shapiro test (only valid if there are at least 3 residuals)
test_result <- if (length(resids) >= 3) shapiro.test(resids) else NULL

# 3) Interpretation
interpretation <- if (!is.null(test_result) && test_result$p.value > 0.05) {
  "Residuals are likely normally distributed (fail to reject H0)."
} else if (!is.null(test_result)) {
  "Residuals are not normally distributed (reject H0)."
} else {
  "Test could not be performed (need at least 3 non-missing values)."
}

# 4) Output table
shapiro_residuals_results <- data.frame(
  Variable = "SO4_Cl_molar residuals",
  W = if (!is.null(test_result)) unname(test_result$statistic) else NA_real_,
  p_value = if (!is.null(test_result)) test_result$p.value else NA_real_,
  Interpretation = interpretation,
  n = length(resids)  # helpful sanity check
)

shapiro_residuals_results
```

### Not-Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

data_long <- RD_early_temporal_stats  # <-- change to your df name

# Variables that failed Shapiro (non-normal)
non_normal_vars <- c("Aluminum", "Barium", "Cadmium", "Chloride", "Conductivity, Field", "Hardness, Total", "Temperature, Field", "Iron", "Lead", "Sulfate", "Zinc")

# Function to run Wilcoxon test
run_wilcox_for_var <- function(var, data) {
  df_var <- data %>%
    filter(
      chemical_name == var,
      !is.na(report_result_value),
      !is.na(Temporal_status)
    )
  
  # Check for data sufficiency
  if (nrow(df_var) < 3 || n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "Wilcoxon rank-sum",
      statistic = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one group; test not run."
    ))
  }

  # Compute group sample sizes
  n_info <- df_var %>%
    count(Temporal_status) %>%
    pull(n)
  
  n1 <- n_info[1]
  n2 <- n_info[2]
  
  res <- wilcox_test(
    report_result_value ~ Temporal_status,
    data = df_var
  )
  
  res %>%
    mutate(
      variable = var,
      test = "Wilcoxon rank-sum",
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference (reject H0).",
        "No significant difference (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, p, Interpretation)
}

# Run Wilcoxon tests for all non-normal variables
wilcox_results <- map_dfr(non_normal_vars, run_wilcox_for_var, data = data_long)

view(wilcox_results)

## no difference for Lead, Temp, Chloride and Barium

write_xlsx(wilcox_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/early season wilcox_results.xlsx")
```

### Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

# Long-format data frame
data_long <- RD_early_temporal_stats   # <-- replace with your df name

# Variables that passed Shapiro (normal)
normal_vars <- c("pH, Field", "Alkalinity (As CaC03)", "Bicarbonate (As CaC03)")

# Function to run t-test on one variable
run_t_for_var <- function(var, data) {
  df_var <- data %>%
    filter(
      chemical_name == var,
      !is.na(report_result_value),
      !is.na(Temporal_status)
    )
  
  # Check for data sufficiency
  if (nrow(df_var) < 3 || n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "t-test",
      statistic = NA_real_,
      df = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one group; test not run."
    ))
  }

  res <- t_test(
    report_result_value ~ Temporal_status,
    data = df_var,
    var.equal = FALSE  # Welch t-test
  )
  
  res %>%
    mutate(
      variable = var,
      test = "t-test",
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference (reject H0).",
        "No significant difference (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, df, p, Interpretation)
}

# Run t-tests for all normal variables
t_test_results <- map_dfr(normal_vars, run_t_for_var, data = data_long)

View(t_test_results)

write_xlsx(t_test_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/early season t_test results.xlsx")
```

## Late season
### Shapiro
```{r}
library(dplyr)
library(purrr)
library(broom)
library(rstatix)

# It must have: chemical_name, report_result_value, Temporal_status, and temporal_status_season
# Temporal_status is used to do a comparison of pre to post including both seasons

data_long <- RD_late_temporal_stats  # <-- change to your df name

# List of columns to analyze
chemicals_to_model <- c("pH, Field", "Alkalinity (As CaC03)", "Aluminum", "Barium", 
  "Bicarbonate (As CaC03)", "Cadmium", "Chloride", "Conductivity, Field", "Copper", "Hardness, Total", "Temperature, Field", "Iron", "Lead", "Nickel", "Sulfate", "Zinc")

pdf("residuals_plots_long.pdf")  # Start a new PDF file

model_results <- list()

for (chem in chemicals_to_model) {
  
  # Filter data for this chemical
  df_chem <- data_long %>%
    filter(chemical_name == chem)
  
  # Optional: drop NAs in response or predictor
  df_chem <- df_chem %>%
    filter(!is.na(report_result_value), !is.na(Temporal_status))
  
  # Safety check: need enough data & at least 2 groups for the model
  if (nrow(df_chem) < 3 || dplyr::n_distinct(df_chem$Temporal_status) < 2) {
    model_results[[chem]] <- data.frame(
      Variable = chem,
      W = NA_real_,
      p_value = NA_real_,
      Interpretation = "Not enough data or only one Temporal_status level; model not fit."
    )
    next
  }
  
  # Fit the linear model: value ~ Temporal_status
  model <- lm(report_result_value ~ Temporal_status, data = df_chem)
  
  # Residuals
  residuals <- resid(model)
  
  # Residual histogram
  hist(
    residuals,
    main = paste("Residuals Histogram:", chem),
    xlab = "Residuals"
  )
  
  # QQ plot
  qqnorm(residuals, main = paste("QQ Plot of Residuals:", chem))
  qqline(residuals)
  
  # Shapiro-Wilk test on residuals
  test_result <- tryCatch(
    shapiro.test(residuals),
    error = function(e) NULL
  )
  
  # Interpretation text
  interpretation <- if (!is.null(test_result) && test_result$p.value > 0.05) {
    "The residuals are likely normally distributed (fail to reject H0)."
  } else if (!is.null(test_result)) {
    "The residuals are not normally distributed (reject H0) and a non-parametric test may be more appropriate."
  } else {
    "Test could not be performed due to insufficient data or errors."
  }
  
  # Store results
  model_results[[chem]] <- data.frame(
    Variable = chem,
    W = if (!is.null(test_result)) unname(test_result$statistic) else NA_real_,
    p_value = if (!is.null(test_result)) test_result$p.value else NA_real_,
    Interpretation = interpretation
  )
}

dev.off()  # Close the PDF

late_shapiro_results_long <- bind_rows(model_results)

View(late_shapiro_results_long)

write_xlsx(late_shapiro_results_long, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/late_shapiro_results_long.xlsx")

## Copper and Nickel had only one Temporal status so the model couldn't run for those
## Bicarboante Temp are normally distributed and need to be compared with an ANOVA
```

### Not-Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

data_long <- RD_early_temporal_stats  # <-- change to your df name

# Variables that failed Shapiro (non-normal)
non_normal_vars <- c("pH, Field", "Alkalinity (As CaC03)", "Aluminum", "Barium", "Cadmium", "Chloride", "Conductivity, Field", "Hardness, Total", "Iron", "Lead", "Sulfate", "Zinc")

# Function to run Wilcoxon test
run_wilcox_for_var <- function(var, data) {
  df_var <- data %>%
    filter(
      chemical_name == var,
      !is.na(report_result_value),
      !is.na(Temporal_status)
    )
  
  # Check for data sufficiency
  if (nrow(df_var) < 3 || n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "Wilcoxon rank-sum",
      statistic = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one group; test not run."
    ))
  }

  # Compute group sample sizes
  n_info <- df_var %>%
    count(Temporal_status) %>%
    pull(n)
  
  n1 <- n_info[1]
  n2 <- n_info[2]
  
  res <- wilcox_test(
    report_result_value ~ Temporal_status,
    data = df_var
  )
  
  res %>%
    mutate(
      variable = var,
      test = "Wilcoxon rank-sum",
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference (reject H0).",
        "No significant difference (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, p, Interpretation)
}

# Run Wilcoxon tests for all non-normal variables
wilcox_results <- map_dfr(non_normal_vars, run_wilcox_for_var, data = data_long)

view(wilcox_results)

## no difference for Lead, Alkalinity, Chloride and Barium

write_xlsx(wilcox_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/late season wilcox_results.xlsx")
```

### Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

# Long-format data frame
data_long <- RD_late_temporal_stats   # <-- replace with your df name

# Variables that passed Shapiro (normal)
normal_vars <- c("Bicarbonate (As CaC03)", "Temperature, Field")

# Function to run t-test on one variable
run_t_for_var <- function(var, data) {
  df_var <- data %>%
    filter(
      chemical_name == var,
      !is.na(report_result_value),
      !is.na(Temporal_status)
    )
  
  # Check for data sufficiency
  if (nrow(df_var) < 3 || n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "t-test",
      statistic = NA_real_,
      df = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one group; test not run."
    ))
  }

  res <- t_test(
    report_result_value ~ Temporal_status,
    data = df_var,
    var.equal = FALSE  # Welch t-test
  )
  
  res %>%
    mutate(
      variable = var,
      test = "t-test",
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference (reject H0).",
        "No significant difference (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, df, p, Interpretation)
}

# Run t-tests for all normal variables
t_test_results <- map_dfr(normal_vars, run_t_for_var, data = data_long)

View(t_test_results)

## Significant difference in bicarbonate

write_xlsx(t_test_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/late season t_test results.xlsx")
```

## All seasons - pre vs post
### Shapiro
```{r}
library(dplyr)
library(purrr)
library(broom)
library(rstatix)

# It must have: chemical_name, report_result_value, Temporal_status, and temporal_status_season
# Temporal_status is used to do a comparison of pre to post including both seasons

data_long <- RD_temporal_stats  # <-- change to your df name

# List of columns to analyze
chemicals_to_model <- c("pH, Field", "Alkalinity (As CaC03)", "Aluminum", "Barium", 
  "Bicarbonate (As CaC03)", "Cadmium", "Chloride", "Conductivity, Field", "Copper", "Hardness, Total", "Temperature, Field", "Iron", "Lead", "Nickel", "Sulfate", "Zinc")

pdf("residuals_plots_long.pdf")  # Start a new PDF file

model_results <- list()

for (chem in chemicals_to_model) {
  
  # Filter data for this chemical
  df_chem <- data_long %>%
    filter(chemical_name == chem)
  
  # Optional: drop NAs in response or predictor
  df_chem <- df_chem %>%
    filter(!is.na(report_result_value), !is.na(Temporal_status))
  
  # Safety check: need enough data & at least 2 groups for the model
  if (nrow(df_chem) < 3 || dplyr::n_distinct(df_chem$Temporal_status) < 2) {
    model_results[[chem]] <- data.frame(
      Variable = chem,
      W = NA_real_,
      p_value = NA_real_,
      Interpretation = "Not enough data or only one Temporal_status level; model not fit."
    )
    next
  }
  
  # Fit the linear model: value ~ Temporal_status
  model <- lm(report_result_value ~ Temporal_status, data = df_chem)
  
  # Residuals
  residuals <- resid(model)
  
  # Residual histogram
  hist(
    residuals,
    main = paste("Residuals Histogram:", chem),
    xlab = "Residuals"
  )
  
  # QQ plot
  qqnorm(residuals, main = paste("QQ Plot of Residuals:", chem))
  qqline(residuals)
  
  # Shapiro-Wilk test on residuals
  test_result <- tryCatch(
    shapiro.test(residuals),
    error = function(e) NULL
  )
  
  # Interpretation text
  interpretation <- if (!is.null(test_result) && test_result$p.value > 0.05) {
    "The residuals are likely normally distributed (fail to reject H0)."
  } else if (!is.null(test_result)) {
    "The residuals are not normally distributed (reject H0) and a non-parametric test may be more appropriate."
  } else {
    "Test could not be performed due to insufficient data or errors."
  }
  
  # Store results
  model_results[[chem]] <- data.frame(
    Variable = chem,
    W = if (!is.null(test_result)) unname(test_result$statistic) else NA_real_,
    p_value = if (!is.null(test_result)) test_result$p.value else NA_real_,
    Interpretation = interpretation
  )
}

dev.off()  # Close the PDF

shapiro_results_long <- bind_rows(model_results)

View(shapiro_results_long)

write_xlsx(shapiro_results_long, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/both seasons shapiro_results_long.xlsx")

## Copper and Nickel had only one Temporal status so the model couldn't run for those
## Bicarboante and Alkalinity are normally distributed and need to be compared with an ANOVA
```

### Not-Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

data_long <- RD_temporal_stats  # <-- change to your df name

# Variables that failed Shapiro (non-normal)
non_normal_vars <- c("pH, Field", "Aluminum", "Barium", "Cadmium", "Chloride", "Conductivity, Field", "Copper", "Hardness, Total", "Temperature, Field", "Iron", "Lead", "Nickel", "Sulfate", "Zinc")

# Function to run Wilcoxon test
run_wilcox_for_var <- function(var, data) {
  df_var <- data %>%
    filter(
      chemical_name == var,
      !is.na(report_result_value),
      !is.na(Temporal_status)
    )
  
  # Check for data sufficiency
  if (nrow(df_var) < 3 || n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "Wilcoxon rank-sum",
      statistic = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one group; test not run."
    ))
  }

  # Compute group sample sizes
  n_info <- df_var %>%
    count(Temporal_status) %>%
    pull(n)
  
  n1 <- n_info[1]
  n2 <- n_info[2]
  
  res <- wilcox_test(
    report_result_value ~ Temporal_status,
    data = df_var
  )
  
  res %>%
    mutate(
      variable = var,
      test = "Wilcoxon rank-sum",
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference (reject H0).",
        "No significant difference (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, p, Interpretation)
}

# Run Wilcoxon tests for all non-normal variables
wilcox_results <- map_dfr(non_normal_vars, run_wilcox_for_var, data = data_long)

view(wilcox_results)

## no difference for Chloride and Temperature

write_xlsx(wilcox_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/all seasons wilcox_results.xlsx")
```

### Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

# Long-format data frame
data_long <- RD_temporal_stats   # <-- replace with your df name

# Variables that passed Shapiro (normal)
normal_vars <- c("Alkalinity (As CaC03)", "Bicarbonate (As CaC03)")

# Function to run t-test on one variable
run_t_for_var <- function(var, data) {
  df_var <- data %>%
    filter(
      chemical_name == var,
      !is.na(report_result_value),
      !is.na(Temporal_status)
    )
  
  # Check for data sufficiency
  if (nrow(df_var) < 3 || n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "t-test",
      statistic = NA_real_,
      df = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one group; test not run."
    ))
  }

  res <- t_test(
    report_result_value ~ Temporal_status,
    data = df_var,
    var.equal = FALSE  # Welch t-test
  )
  
  res %>%
    mutate(
      variable = var,
      test = "t-test",
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference (reject H0).",
        "No significant difference (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, df, p, Interpretation)
}

# Run t-tests for all normal variables
t_test_results <- map_dfr(normal_vars, run_t_for_var, data = data_long)

View(t_test_results)

## Significant difference in bicarbonate and alkalinity

write_xlsx(t_test_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/Red Dog Station 9/all seasons t_test results.xlsx")
```

# Ferrum Sites Temporal Analysis 
## data frame modifications
```{r}
# Purpose of this chunk: Add years the are missing data to have a continuous x-axis on the plots

# complete() expands the data so that all combinations of season, watershed, year is present in the dataframe
temporal_filled <- Agashashok_for_plots %>%
  complete(
    sample_collection_season,
    Watershed,
    sample_collection_year = 2015:2024
  )
  
view(temporal_filled)
```

```{r}
temporal_filled$sample_collection_year <- factor(
  temporal_filled$sample_collection_year,
  levels = c(
    "2015", "2016", "2017", "2018", "2019", "2020", "2021", "2022", "2023", "2024"
  )
)

#temporal_filled[1, 17] <- NA

view(temporal_filled)
```

```{r}
temporal_df <- temporal_df %>%
  mutate(year = as.integer(year)) %>%
  complete(
    Subcatchment,
    variable,
    year = seq(2015, 2024, by = 0.5)  # Adds 2015, 2015.5, 2016, ..., 2024
  ) %>%
  mutate(
    Subcatchment = factor(Subcatchment, levels = c("South Fork", "North Fork", "Main")),
    year = as.character(year),  # Optional: only if treating year as a discrete axis
    year_sub = interaction(year, Subcatchment, sep = "_")
  )


temporal_df$year_sub <- factor(
  temporal_df$year_sub,
  levels = c(
  "2015_South Fork", "2015_North Fork", "2015_Main",
  "2015.5_South Fork", "2015.5_North Fork", "2015.5_Main",
  "2016_South Fork", "2016_North Fork", "2016_Main",
  "2016.5_South Fork", "2016.5_North Fork", "2016.5_Main",
  "2017_South Fork", "2017_North Fork", "2017_Main",
  "2017.5_South Fork", "2017.5_North Fork", "2017.5_Main",
  "2018_South Fork", "2018_North Fork", "2018_Main",
  "2018.5_South Fork", "2018.5_North Fork", "2018.5_Main",
  "2019_South Fork", "2019_North Fork", "2019_Main",
  "2019.5_South Fork", "2019.5_North Fork", "2019.5_Main",
  "2020_South Fork", "2020_North Fork", "2020_Main",
  "2020.5_South Fork", "2020.5_North Fork", "2020.5_Main",
  "2021_South Fork", "2021_North Fork", "2021_Main",
  "2021.5_South Fork", "2021.5_North Fork", "2021.5_Main",
  "2022_South Fork", "2022_North Fork", "2022_Main",
  "2022.5_South Fork", "2022.5_North Fork", "2022.5_Main",
  "2023_South Fork", "2023_North Fork", "2023_Main",
  "2023.5_South Fork", "2023.5_North Fork", "2023.5_Main",
  "2024_South Fork", "2024_North Fork", "2024_Main"
)
)

view(temporal_df)
```

## Sulfate
```{r}
# add a gap between 2018 and 2019 so there is more space on the figure
temporal_df_headers <- temporal_filled %>% slice(0)

temporal_df_headers <- temporal_df_headers %>%
  mutate(sample_collection_year = as.numeric(as.character(sample_collection_year)))

temporal_df_headers <- temporal_df_headers %>%
  add_row(sample_collection_year = 2018.5, f_SO4_mg_per_l = 0)

temporal_filled <- temporal_filled %>%
  mutate(sample_collection_year = as.numeric(as.character(sample_collection_year)))

temporal_filled <- bind_rows(temporal_df_headers, temporal_filled)

temporal_filled$sample_collection_year <- factor(
  temporal_filled$sample_collection_year,
  levels = c(
    "2015", "2016", "2017", "2018", "2018.5", "2019", "2020", "2021", "2022", "2023", "2024"
  )
)

temporal_filled_2 <- temporal_filled %>%
  mutate(
    sample_collection_season = factor(sample_collection_season, levels = c("early", "late")),
    year_season = interaction(sample_collection_year, sample_collection_season, sep = "_", drop = TRUE)
  )

temporal_filled_2$year_season <- factor(
  temporal_filled_2$year_season,
  levels = c(
    "2015_early","2015_late", "2016_early", "2016_late", "2017_early", "2017_late", "2018_early", "2018_late", "2019_early", "2019_late", "2020_early", "2020_late", "2021_early", "2021_late", "2022_early", "2022_late", "2023_early", "2023_late", "2024_early", "2024_late"
  )
)
```

```{r}
Sulfate_temporal_bp <- temporal_filled_2 %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = f_SO4_mg_per_l, fill = sample_collection_season)) +
  #ggplot(aes(x = as.factor(sample_collection_year), y = f_SO4_mg_per_l, fill = sample_collection_season)) +
  geom_boxplot(
    position = position_dodge2(width = 0.75), width = 0.55
    ) +
  #scale_x_discrete(expand = expansion(add = 0.6)) +
  scale_y_continuous(breaks = c(0,25,50,75,100,125,150,175,200,225,250,275), labels = c(0, "", 50, "", 100, "", 150, "", 200, "", 250, ""), expand = expansion(mult = c(0.02, 0.01))) +
  scale_x_discrete(expand = expansion(mult = c(0.05, 0.05))) +
  #scale_x_continuous(expand = expansion(mult = c(0.035, 0.025))) +
  scale_fill_manual(
    values = c("early" = "#A1E3F9", "late" = "#0a7ea4")
  ) +
  coord_cartesian(ylim = c(0, 240)) +
  # Add counts as text
  geom_vline(xintercept = 9.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  labs(
    title = NULL,
    #title = "Aggie", 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    y = "Sulfate Concentration (mg/L)",
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        #axis.text.y = element_blank(),
        # axis.ticks.x = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

Sulfate_temporal_bp

# library(plotly)
# Sulfate_temporal_bp_interactive <- ggplotly(Sulfate_temporal_bp)
# Sulfate_temporal_bp_interactive

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/SI/SI Final_SO4 bottom labels.png", Sulfate_temporal_bp, width = 3.5, height = 5.3, dpi = 300, bg = "transparent")

## dimensions for V3_smaller: w = 3.5, h = 4.25

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Final_SO4 no labels.png", Sulfate_temporal_bp, width = 4, height = 4.35, dpi = 300, bg = "transparent")
```

```{r}
Sulfate_temporal_bp <- temporal_filled %>%
  dplyr::filter(sample_collection_season %in% c("early", "late")) %>%
  dplyr::mutate(
    year_num = as.numeric(sample_collection_year),
    season_offset = dplyr::case_when(
      sample_collection_season == "early" ~ -0.20,
      sample_collection_season == "late"  ~  0.20,
      TRUE ~ 0
    ),
    x_pos = year_num + season_offset
  ) %>%
  ggplot(aes(
    x = x_pos,
    y = f_SO4_mg_per_l,
    fill = sample_collection_season,
    group = interaction(sample_collection_year, sample_collection_season)
  )) +
  geom_boxplot(width = 0.30) +
  geom_vline(xintercept = 5, linetype = "dashed", linewidth = 0.8, alpha = 0.7) +
  scale_x_continuous(
    breaks = sort(unique(as.numeric(temporal_filled$sample_collection_year))),
    labels = sort(unique(temporal_filled$sample_collection_year)),
    expand = expansion(add = 0.4)
  ) +
  scale_y_continuous(
    breaks = c(0,25,50,75,100,125,150,175,200,225,250,275),
    labels = c(0, "", 50, "", 100, "", 150, "", 200, "", 250,)
  ) +
  scale_fill_manual(values = c("early" = "#A1E3F9", "late" = "#0a7ea4")) +
  coord_cartesian(ylim = c(0, 275)) +
  labs(
    x = "Year",
    y = "Sulfate Concentration (mg/L)",
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(
    legend.position = "none",
    axis.text.y = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.background = element_rect(fill = "transparent", color = NA),
    panel.background = element_rect(fill = "transparent", color = NA)
  )

Sulfate_temporal_bp
```


## Alkalinity

```{r}
# add a negative value to early season 2015 so that the boxplots plot correctly
Alk_plot_df <- temporal_filled

Alk_plot_df[1, 17] <- 0
```

```{r}
Alkalinity_temporal_bp <- Alk_plot_df %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = Alk_mgCaCO3_per_l, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.95)) +
  coord_cartesian(ylim = c(25,225)) +
  scale_y_continuous(breaks = c(25, 50,75,100,125,150,175,200,225), labels = c("", 50, "", 100, "", 150, "", 200, "")) +
  #scale_x_continuous(expand = expansion(mult = c(0.035, 0.025))) +
  scale_fill_manual(
    values = c("early" = "#A1E3F9", "late" = "#0a7ea4")
  ) +
  # Add counts as text
  geom_vline(xintercept = 4.5, linetype = "dashed", color = "black", size = 0.9, alpha = 0.7) +
  labs(
    title = NULL, 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    y = ylab_Alk,
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        legend.text = element_text(size = 8),       # smaller legend labels
    legend.title = element_text(size = 8),      # smaller legend title
    legend.key.size = unit(2, "cm"),
        #axis.text.y = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

Alkalinity_temporal_bp

library(plotly)
Alkalinity_temporal_bp_interactive <- ggplotly(Alkalinity_temporal_bp)
Alkalinity_temporal_bp_interactive

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Alkalinity seasonal temporal bp_V1.png", Alkalinity_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Alkalinity seasonal temporal bp_V2.png", Alkalinity_temporal_bp, width = 5, height = 5, dpi = 300, bg = "transparent")

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/seasonal temporal bp LEGEND.png", Alkalinity_temporal_bp, width = 5, height = 5, dpi = 300, bg = "transparent")
```

## pH
```{r}
pH_temporal_bp <- temporal_filled %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = pH, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.95)) +
  coord_cartesian(ylim = c(7.6, 8.52)) +
  scale_y_continuous(breaks = c(7.5, 7.75, 8.0, 8.25, 8.5), labels = c("7.50", 7.75, "8.00", 8.25, "8.50")) +
  #scale_x_continuous(expand = expansion(mult = c(0.035, 0.025))) +
  scale_fill_manual(
    values = c("early" = "#A1E3F9", "late" = "#0a7ea4")
  ) +
  # Add counts as text
  geom_vline(xintercept = 4.5, linetype = "dashed", color = "black", size = 0.9, alpha = 0.7) +
  labs(
    title = NULL, 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    y = ylab_Alk,
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        #axis.text.y = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

pH_temporal_bp

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/pH seasonal temporal bp_V1.png", pH_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/pH seasonal temporal bp_V2.png", pH_temporal_bp, width = 5, height = 5, dpi = 300, bg = "transparent")
```

## Chloride
```{r}
Chloride_temporal_bp <- temporal_filled_2 %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = f_Cl_mg_per_l, fill = sample_collection_season)) +
  geom_boxplot(
    position = position_dodge2(width = 0.75), width = 0.55
    ) +
  # scale_y_log10() +
  scale_fill_manual(
    values = c("early" = "#A1E3F9", "late" = "#0a7ea4")
  ) +
  coord_cartesian(ylim = c(0, 8)) +
  scale_y_continuous(expand = expansion(mult = c(0.02, 0.01))) +
  scale_x_discrete(expand = expansion(mult = c(0.05, 0.05))) +
  # Add counts as text
  geom_vline(xintercept = 9.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  labs(
    title = NULL, 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    y = "Sulfate Concentration (mg/L)",
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        #axis.text.y = element_blank(),
        # axis.ticks.x = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

Chloride_temporal_bp

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/SI/SI Final_Cl bottom labels.png", Chloride_temporal_bp, width = 3.25, height = 5.3, dpi = 300, bg = "transparent")
# 
# ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Cl seasonal temporal bp_V2.png", Chloride_temporal_bp, width = 5, height = 5, dpi = 300, bg = "transparent")
```

## SO4:Cl
```{r}
Aggie_SO4_Cl <- temporal_filled_2 %>%
    mutate(
    # 1. Convert mg/L → mmol/L  (divide by molecular weight in g/mol = mg/mmol)

    f_Cl_mmol_per_l  = f_Cl_mg_per_l  / 35.45,  # Cl⁻
    f_SO4_mmol_per_l = f_SO4_mg_per_l / 96.06,  # SO₄²⁻ (as sulfate)

    # 2. Molar SO4:Cl ratio
    SO4_to_Cl_molar  = f_SO4_mmol_per_l / f_Cl_mmol_per_l
  )

# sample size of each year_season
SO4_Cl_counts <- Aggie_SO4_Cl %>%
  mutate(year_season = paste(sample_collection_year,
                             sample_collection_season,
                             sep = "_")) %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  count(year_season)

print(SO4_Cl_counts)
```

```{r}
Aggie_SO4_Cl_temporal_bp <- Aggie_SO4_Cl %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = SO4_to_Cl_molar, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.75), width = 0.55) +
  scale_fill_manual(
    values = c("early" = "#A1E3F9", "late" = "#0a7ea4")
  ) +
  #scale_y_continuous(breaks = c(0,25,50,75,100,125,150,175,200,225,250), labels = c(0, "", 50, "", 100, "", 150, "", 200, "", 250)) +
  #scale_x_continuous(expand = expansion(mult = c(0.035, 0.025))) +
  #scale_y_log10() +
  coord_cartesian(ylim = c(0, 127)) +
  # Add counts as text
  geom_vline(xintercept = 9.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  scale_y_continuous(expand = expansion(mult = c(0.02, 0.01))) +
  scale_x_discrete(expand = expansion(mult = c(0.05, 0.05))) +
  labs(
    title = NULL, 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    y = "Concentration Ratio",
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        #axis.text.y = element_blank(),
        # axis.ticks.x = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

Aggie_SO4_Cl_temporal_bp

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Cl seasonal temporal bp_V1.png", Chloride_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/SI/SI Final_Aggie SO4 to Cl bottom labels.png", Aggie_SO4_Cl_temporal_bp, width = 3.5, height = 5.3, dpi = 300, bg = "transparent")
```

## Sodium
```{r}
Sodium_temporal_bp <- temporal_filled %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = f_Na_mg_l, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.95)) +
  scale_y_continuous(breaks = c(0,1,2,3,4,5,6,7,8,9,10,11), labels = c(0,"",2,"",4,"",6,"",8,"",10,"")) +
  #scale_x_continuous(expand = expansion(mult = c(0.035, 0.025))) +
  #scale_y_log10() +
  scale_fill_manual(
    values = c("early" = "#A1E3F9", "late" = "#0a7ea4")
  ) +
  #coord_cartesian(ylim = c(0, 250)) +
  # Add counts as text
  geom_vline(xintercept = 4.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  labs(
    title = NULL, 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    y = "Sulfate Concentration (mg/L)",
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        #axis.text.y = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

Sodium_temporal_bp

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Na seasonal temporal bp_V1.png", Sodium_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Na seasonal temporal bp_V2.png", Sodium_temporal_bp, width = 5, height = 5, dpi = 300, bg = "transparent")
```

## Calcium
```{r}
## Calcium
Calcium_temporal_bp <- temporal_filled %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = f_Ca_mg_l, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.95)) +
  scale_y_continuous(breaks = c(0,25,50,75,100,125), labels = c(0,"",50,"",100,"")) +
  scale_fill_manual(
    values = c("early" = "#A1E3F9", "late" = "#0a7ea4")
  ) +
  geom_vline(xintercept = 4.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  labs(
    title = NULL,
    x = "Year",
    y = "Calcium Concentration (mg/L)",
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.background = element_rect(fill = "transparent", color = NA),
    panel.background = element_rect(fill = "transparent", color = NA)
  )

Calcium_temporal_bp

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Ca seasonal temporal bp_V1.png",
       Calcium_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Ca seasonal temporal bp_V2.png",
       Calcium_temporal_bp, width = 5, height = 5, dpi = 300, bg = "transparent")

```


## Magnesium
```{r}
## Magnesium
Magnesium_temporal_bp <- temporal_filled %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = f_Mg_mg_l, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.95)) +
  coord_cartesian(ylim = c(5, 41)) +
  scale_y_continuous(breaks = c(5,10,15,20,25,30,35,40), labels = c("",10,"",20,"",30,"",40,"",10,"")) +
  scale_fill_manual(
    values = c("early" = "#A1E3F9", "late" = "#0a7ea4")
  ) +
  geom_vline(xintercept = 4.5, linetype = "dashed", color = "black", size = 0.8, alpha = 0.7) +
  labs(
    title = NULL,
    x = "Year",
    y = "Magnesium Concentration (mg/L)",
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.background = element_rect(fill = "transparent", color = NA),
    panel.background = element_rect(fill = "transparent", color = NA)
  )

Magnesium_temporal_bp

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Mg seasonal temporal bp_V1.png",
       Magnesium_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Mg seasonal temporal bp_V2.png",
       Magnesium_temporal_bp, width = 5, height = 5, dpi = 300, bg = "transparent")

```

## temp
```{r}
temp_temporal_bp <- temporal_filled %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  ggplot(aes(x = as.factor(sample_collection_year), y = Temp_deg_celsius, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.95)) +
  #scale_y_continuous(breaks = c(7.5, 7.75, 8.0, 8.25, 8.5), labels = c("7.50", 7.75, "8.00", 8.25, "8.50")) +
  #scale_x_continuous(expand = expansion(mult = c(0.035, 0.025))) +
  scale_fill_manual(
    values = c("early" = "#A1E3F9", "late" = "#0a7ea4")
  ) +
  # Add means as text
  #geom_text(data = chloride_season_stats, aes(x = as.factor(Year), y = 0.5, 
                                     #label = paste0("mean =", mean_value), group = Season),
           # position = position_dodge(width = 0.75), size = 3) +
  # Add counts as text
  geom_vline(xintercept = 4.5, linetype = "dashed", color = "black", size = 0.9, alpha = 0.7) +
  labs(
    title = NULL, 
    #title = "Boxplot of Sulfate Concentration\nby Year and Season",  # Add \n for line break
    x = "Year",
    y = ylab_Alk,
    fill = "Season"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        #axis.text.y = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

temp_temporal_bp

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/temp seasonal temporal bp_V1.png", temp_temporal_bp, width = 4, height = 5, dpi = 300, bg = "transparent")
```

# Aggie Sites Stats - pre vs post
## Add temporal_status to df
```{r}
temporal_stats <- Agashashok_for_plots %>%
  filter(sample_collection_season %in% c("early", "late")) %>%
  mutate(
    year_season = paste(sample_collection_year, sample_collection_season, sep = "_") 
  ) %>%
   mutate(
    Temporal_status = ifelse(year_season %in% c("2015_early", "2016_early", "2017_early", "2018_early", "2019_early", "2015_late", "2016_late", "2017_late", "2018_late"), 'pre',
                      ifelse(year_season %in% c("2019_late", "2022_early", "2022_late", "2023_early", "2023_late", "2024_early", "2024_late"), 'post', NA))
  ) %>%
  mutate(
    temporal_status_season = paste(Temporal_status, sample_collection_season, sep = "_")
  ) %>%
  relocate(temporal_status_season, Temporal_status, .after = SamplingEventID) %>%
  mutate(Temporal_status = factor(Temporal_status, levels = c("pre", "post")))

temporal_stats <- temporal_stats %>%
  mutate(
    across(all_of(columns_to_model), as.numeric)
  )

temporal_stats_long <- temporal_stats %>%
  dplyr::select(7:15,17:27)
```

```{r}
early_temporal_stats <- temporal_stats %>%
  filter(sample_collection_season == "early") %>%
  mutate(Temporal_status = factor(Temporal_status, levels = c("pre", "post")))

late_temporal_stats <- temporal_stats %>%
  filter(sample_collection_season == "late") %>%
  mutate(Temporal_status = factor(Temporal_status, levels = c("pre", "post")))
```

```{r}
data_2018_2019 <- temporal_stats %>%
  filter(sample_collection_year %in% c("2018", "2019")) %>%
  dplyr::select(7,9,12,19,23)

data_2018_2019_summary <- data_2018_2019 %>%
  pivot_longer(
    cols = 4:5,
    names_to  = "chemical_name",          # or whatever you want to call the old col names
    values_to = "report_result_value"
  ) %>%
  #group_by(chemical_name, sample_collection_season, sample_collection_year) %>%
  group_by(chemical_name, sample_collection_year) %>%
  summarise(
    n        = n(),                     # number of values
    mean     = mean(report_result_value, na.rm = TRUE),
    median   = median(report_result_value, na.rm = TRUE),
    sd       = sd(report_result_value, na.rm = TRUE),
    se       = sd(report_result_value, na.rm = TRUE) / sqrt(n()),
    min      = min(report_result_value, na.rm = TRUE),
    max      = max(report_result_value, na.rm = TRUE),
    .groups = "drop"
  )
```

## Summary statas
```{r}
Aggie_temporal_stats_summary <- temporal_stats %>%
  filter(Temporal_status %in% c("pre", "post")) %>%   # keep only the two groups
  dplyr::select(7:15,17:27) %>%
  pivot_longer(
    cols = 7:20,
    names_to  = "chemical_name",          # or whatever you want to call the old col names
    values_to = "report_result_value"
  ) %>%
  filter(!is.na(report_result_value)) %>%
  group_by(chemical_name, Temporal_status) %>%
  # group_by(chemical_name, temporal_status_season) %>%
  summarise(
    n        = n(),                     # number of values
    mean     = mean(report_result_value, na.rm = TRUE),
    median   = median(report_result_value, na.rm = TRUE),
    sd       = sd(report_result_value, na.rm = TRUE),
    se       = sd(report_result_value, na.rm = TRUE) / sqrt(n()),
    min      = min(report_result_value, na.rm = TRUE),
    max      = max(report_result_value, na.rm = TRUE),
    .groups = "drop"
  )

view(Aggie_temporal_stats_summary)

# Aggie_temporal_stats_summary <- Aggie_temporal_stats_summary %>%
#   mutate(
#     temporal_status_season = factor(
#       temporal_status_season,
#       levels = c("pre_early", "pre_late", "post_early", "post_late")
#     )
#   ) %>%
#   arrange(chemical_name, temporal_status_season)

write_xlsx(Aggie_temporal_stats_summary, "C:/Users/tevinger/Downloads/Aggie temporal summary stats.xlsx")
```

## NEW - Early season
### Shapiro
```{r}
library(dplyr)
library(purrr)
library(broom)
library(rstatix)

# It must have: chemical_name, report_result_value, Temporal_status, and temporal_status_season
# Temporal_status is used to do a comparison of pre to post including both seasons

# List of columns to analyze
columns_to_model <- c("pH", "Alk_mgCaCO3_per_l", "DIC_mgC_per_l", "DOC_mgC_per_l", "f_Cl_mg_per_l", 
  "f_SO4_mg_per_l", "f_Ca_mg_l", "f_Mg_mg_l", "f_Na_mg_l", "f_K_mg_l")

pdf("residuals_plots.pdf")  # Start a new PDF file

# Initialize a results list
model_results <- list()

# Loop through each variable
for (col in columns_to_model) {
  
  # Fit the model (example: linear model with sample_collection_season as predictor)
  model <- lm(early_temporal_stats[[col]] ~ early_temporal_stats$Temporal_status, data = early_temporal_stats)
  
  # Extract residuals
  residuals <- resid(model)
  
  # Plot histogram
  hist(residuals, main = paste("Residuals Histogram:", col), xlab = "Residuals")
  
  # Plot QQ plot
  qqnorm(residuals, main = paste("QQ Plot of Residuals:", col))
  qqline(residuals)
  
  # Perform Shapiro-Wilk test on residuals
  test_result <- tryCatch(
    shapiro.test(residuals),
    error = function(e) NULL
  )
  
  # Create the interpretation
  interpretation <- if (!is.null(test_result) && test_result$p.value > 0.05) {
    "The residuals are likely normally distributed (fail to reject H0)."
  } else if (!is.null(test_result)) {
    "The residuals are not normally distributed (reject H0) and a non-parametric test may be more appropriate."
  } else {
    "Test could not be performed due to insufficient data or errors."
  }
  
  # Store the results in a data frame
  model_results[[col]] <- data.frame(
    Variable = col,
    W = if (!is.null(test_result)) test_result$statistic else NA,
    p_value = if (!is.null(test_result)) test_result$p.value else NA,
    Interpretation = interpretation
  )
}

dev.off()  # Close the PDF device

# Combine all results into a single data frame
early_shapiro_results <- bind_rows(model_results)

# Print results
view(early_shapiro_results)

#write_xlsx(early_shapiro_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/EARLY shapiro_results_long.xlsx")

write_xlsx(early_shapiro_results, "C:/Users/tevinger/Downloads/Aggie EARLY shapiro_results_long.xlsx")

## DOC is normally distributed --> t-test
```

### Not-Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

data <- early_temporal_stats  # same df

# Variables that FAILED Shapiro (NON-NORMAL)
non_normal_vars <- c("pH", "Alk_mgCaCO3_per_l", "DIC_mgC_per_l", "f_Cl_mg_per_l", 
  "f_SO4_mg_per_l", "f_Ca_mg_l", "f_Mg_mg_l", "f_Na_mg_l", "f_K_mg_l")

run_wilcox_for_col <- function(var, data) {
  df_var <- data %>%
    filter(
      !is.na(.data[[var]]),
      !is.na(Temporal_status)
    )
  
  # Check data sufficiency
  if (nrow(df_var) < 3 || dplyr::n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "Wilcoxon rank-sum",
      group1 = NA_character_,
      group2 = NA_character_,
      n1 = NA_real_,
      n2 = NA_real_,
      statistic = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one Temporal_status level; test not run."
    ))
  }
  
  # Sample sizes per group
  n_info <- df_var %>%
    count(Temporal_status)
  # ensure consistent order with the test output later
  # (we'll match by group name)
  
  # Build formula `<var> ~ Temporal_status`
  fml <- reformulate("Temporal_status", response = var)
  
  res <- wilcox_test(
    data = df_var,
    formula = fml
  )
  
  # Add n1 and n2 by matching group1/group2 to Temporal_status
  n1 <- n_info$n[match(res$group1, n_info$Temporal_status)]
  n2 <- n_info$n[match(res$group2, n_info$Temporal_status)]
  
  res %>%
    mutate(
      variable = var,
      test = "Wilcoxon rank-sum",
      n1 = n1,
      n2 = n2,
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference between groups (reject H0).",
        "No significant difference between groups (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, p, Interpretation)
}

# Run Wilcoxon tests on all non-normal variables
wilcox_results_wide <- map_dfr(non_normal_vars, run_wilcox_for_col, data = data)

View(wilcox_results_wide)


## no difference for Mg and K

#write_xlsx(wilcox_results_wide, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/EARLY season wilcox_results.xlsx")

write_xlsx(wilcox_results_wide, "C:/Users/tevinger/Downloads/Aggie EARLY Wilcox_results_long.xlsx")
```

### Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

# Wide-format data frame
data <- early_temporal_stats  # <-- your df

# Variables that passed Shapiro (NORMAL)
normal_vars <- c("DOC_mgC_per_l")

# Function to run a t-test on one wide column
run_t_for_col <- function(var, data) {
  df_var <- data %>%
    filter(
      !is.na(.data[[var]]),
      !is.na(Temporal_status)
    )
  
  # Need enough data and at least 2 groups
  if (nrow(df_var) < 3 || dplyr::n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "t-test",
      group1 = NA_character_,
      group2 = NA_character_,
      n1 = NA_real_,
      n2 = NA_real_,
      statistic = NA_real_,
      df = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one Temporal_status level; test not run."
    ))
  }
  
  # Build formula: `<var> ~ Temporal_status` (handles spaces/commas via reformulate)
  fml <- reformulate("Temporal_status", response = var)
  
  res <- t_test(
    data = df_var,
    formula = fml,
    var.equal = FALSE   # Welch t-test
  )
  
  res %>%
    mutate(
      variable = var,
      test = "t-test",
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference between groups (reject H0).",
        "No significant difference between groups (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, df, p, Interpretation)
}

# Run t-tests on all normal variables
t_test_results <- map_dfr(normal_vars, run_t_for_col, data = data)

View(t_test_results)


#write_xlsx(t_test_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/EARLY season t_test results.xlsx")

write_xlsx(t_test_results, "C:/Users/tevinger/Downloads/Aggie EARLY t test_results_long.xlsx")
```

## Late season
### Shapiro
```{r}
library(dplyr)
library(purrr)
library(broom)
library(rstatix)

# It must have: chemical_name, report_result_value, Temporal_status, and temporal_status_season
# Temporal_status is used to do a comparison of pre to post including both seasons

# List of columns to analyze
columns_to_model <- c("pH", "Alk_mgCaCO3_per_l", "DIC_mgC_per_l", "DOC_mgC_per_l", "f_Cl_mg_per_l", 
  "f_SO4_mg_per_l", "f_Ca_mg_l", "f_Mg_mg_l", "f_Na_mg_l", "f_K_mg_l")

pdf("residuals_plots.pdf")  # Start a new PDF file

# Initialize a results list
model_results <- list()

# Loop through each variable
for (col in columns_to_model) {
  
  # Fit the model (example: linear model with sample_collection_season as predictor)
  model <- lm(late_temporal_stats[[col]] ~ late_temporal_stats$Temporal_status, data = late_temporal_stats)
  
  # Extract residuals
  residuals <- resid(model)
  
  # Plot histogram
  hist(residuals, main = paste("Residuals Histogram:", col), xlab = "Residuals")
  
  # Plot QQ plot
  qqnorm(residuals, main = paste("QQ Plot of Residuals:", col))
  qqline(residuals)
  
  # Perform Shapiro-Wilk test on residuals
  test_result <- tryCatch(
    shapiro.test(residuals),
    error = function(e) NULL
  )
  
  # Create the interpretation
  interpretation <- if (!is.null(test_result) && test_result$p.value > 0.05) {
    "The residuals are likely normally distributed (fail to reject H0)."
  } else if (!is.null(test_result)) {
    "The residuals are not normally distributed (reject H0) and a non-parametric test may be more appropriate."
  } else {
    "Test could not be performed due to insufficient data or errors."
  }
  
  # Store the results in a data frame
  model_results[[col]] <- data.frame(
    Variable = col,
    W = if (!is.null(test_result)) test_result$statistic else NA,
    p_value = if (!is.null(test_result)) test_result$p.value else NA,
    Interpretation = interpretation
  )
}

dev.off()  # Close the PDF device

# Combine all results into a single data frame
late_shapiro_results <- bind_rows(model_results)

# Print results
view(late_shapiro_results)

#write_xlsx(early_shapiro_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/EARLY shapiro_results_long.xlsx")

## pH, Alkalinity, DIC, and Mg are normally distributed --> t-test

write_xlsx(late_shapiro_results, "C:/Users/tevinger/Downloads/Aggie LATE Shapiro_results_long.xlsx")
```

### Not-Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

data <- late_temporal_stats  # same df

# Variables that FAILED Shapiro (NON-NORMAL)
non_normal_vars <- c("DOC_mgC_per_l", "f_Cl_mg_per_l", 
  "f_SO4_mg_per_l", "f_Ca_mg_l", "f_Na_mg_l", "f_K_mg_l")

run_wilcox_for_col <- function(var, data) {
  df_var <- data %>%
    filter(
      !is.na(.data[[var]]),
      !is.na(Temporal_status)
    )
  
  # Check data sufficiency
  if (nrow(df_var) < 3 || dplyr::n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "Wilcoxon rank-sum",
      group1 = NA_character_,
      group2 = NA_character_,
      n1 = NA_real_,
      n2 = NA_real_,
      statistic = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one Temporal_status level; test not run."
    ))
  }
  
  # Sample sizes per group
  n_info <- df_var %>%
    count(Temporal_status)
  # ensure consistent order with the test output later
  # (we'll match by group name)
  
  # Build formula `<var> ~ Temporal_status`
  fml <- reformulate("Temporal_status", response = var)
  
  res <- wilcox_test(
    data = df_var,
    formula = fml
  )
  
  # Add n1 and n2 by matching group1/group2 to Temporal_status
  n1 <- n_info$n[match(res$group1, n_info$Temporal_status)]
  n2 <- n_info$n[match(res$group2, n_info$Temporal_status)]
  
  res %>%
    mutate(
      variable = var,
      test = "Wilcoxon rank-sum",
      n1 = n1,
      n2 = n2,
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference between groups (reject H0).",
        "No significant difference between groups (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, p, Interpretation)
}

# Run Wilcoxon tests on all non-normal variables
wilcox_results_wide <- map_dfr(non_normal_vars, run_wilcox_for_col, data = data)

View(wilcox_results_wide)


## no difference for Ca

#write_xlsx(wilcox_results_wide, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/LATE season wilcox_results.xlsx")

write_xlsx(wilcox_results_wide, "C:/Users/tevinger/Downloads/Aggie LATE Wilcox_results_long.xlsx")
```

### Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

# Wide-format data frame
data <- late_temporal_stats  # <-- your df

# Variables that passed Shapiro (NORMAL)
normal_vars <- c("pH", "Alk_mgCaCO3_per_l", "DIC_mgC_per_l", "f_Mg_mg_l")

# Function to run a t-test on one wide column
run_t_for_col <- function(var, data) {
  df_var <- data %>%
    filter(
      !is.na(.data[[var]]),
      !is.na(Temporal_status)
    )
  
  # Need enough data and at least 2 groups
  if (nrow(df_var) < 3 || dplyr::n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "t-test",
      group1 = NA_character_,
      group2 = NA_character_,
      n1 = NA_real_,
      n2 = NA_real_,
      statistic = NA_real_,
      df = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one Temporal_status level; test not run."
    ))
  }
  
  # Build formula: `<var> ~ Temporal_status` (handles spaces/commas via reformulate)
  fml <- reformulate("Temporal_status", response = var)
  
  res <- t_test(
    data = df_var,
    formula = fml,
    var.equal = FALSE   # Welch t-test
  )
  
  res %>%
    mutate(
      variable = var,
      test = "t-test",
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference between groups (reject H0).",
        "No significant difference between groups (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, df, p, Interpretation)
}

# Run t-tests on all normal variables
t_test_results <- map_dfr(normal_vars, run_t_for_col, data = data)

View(t_test_results)

# no difference for all

#write_xlsx(t_test_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/LATE season t_test results.xlsx")

write_xlsx(t_test_results, "C:/Users/tevinger/Downloads/Aggie LATE t test_results_long.xlsx")
```

## All seasons - pre vs post
### Shapiro
```{r}
library(dplyr)
library(purrr)
library(broom)
library(rstatix)

# It must have: chemical_name, report_result_value, Temporal_status, and temporal_status_season
# Temporal_status is used to do a comparison of pre to post including both seasons

# List of columns to analyze
columns_to_model <- c("pH", "Alk_mgCaCO3_per_l", "HCO3_mg_L", "DIC_mgC_per_l", "DOC_mgC_per_l", "f_Cl_mg_per_l", 
  "f_SO4_mg_per_l", "f_Ca_mg_l", "f_Mg_mg_l", "f_Na_mg_l", "f_K_mg_l")

pdf("residuals_plots.pdf")  # Start a new PDF file

# Initialize a results list
model_results <- list()

# Loop through each variable
for (col in columns_to_model) {
  
  # Fit the model (example: linear model with sample_collection_season as predictor)
  model <- lm(temporal_stats[[col]] ~ temporal_stats$Temporal_status, data = temporal_stats)
  
  # Extract residuals
  residuals <- resid(model)
  
  # Plot histogram
  hist(residuals, main = paste("Residuals Histogram:", col), xlab = "Residuals")
  
  # Plot QQ plot
  qqnorm(residuals, main = paste("QQ Plot of Residuals:", col))
  qqline(residuals)
  
  # Perform Shapiro-Wilk test on residuals
  test_result <- tryCatch(
    shapiro.test(residuals),
    error = function(e) NULL
  )
  
  # Create the interpretation
  interpretation <- if (!is.null(test_result) && test_result$p.value > 0.05) {
    "The residuals are likely normally distributed (fail to reject H0)."
  } else if (!is.null(test_result)) {
    "The residuals are not normally distributed (reject H0) and a non-parametric test may be more appropriate."
  } else {
    "Test could not be performed due to insufficient data or errors."
  }
  
  # Store the results in a data frame
  model_results[[col]] <- data.frame(
    Variable = col,
    W = if (!is.null(test_result)) test_result$statistic else NA,
    p_value = if (!is.null(test_result)) test_result$p.value else NA,
    Interpretation = interpretation
  )
}

dev.off()  # Close the PDF device

# Combine all results into a single data frame
all_shapiro_results <- bind_rows(model_results)

# Print results
view(all_shapiro_results)

#write_xlsx(early_shapiro_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/EARLY shapiro_results_long.xlsx")

## only DIC normally distributed --> t-test
```

### Not-Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

data <- temporal_stats  # same df

# Variables that FAILED Shapiro (NON-NORMAL)
non_normal_vars <- c("pH", "Alk_mgCaCO3_per_l", "HCO3_mg_L", "DOC_mgC_per_l", "f_Cl_mg_per_l", 
  "f_SO4_mg_per_l", "f_Ca_mg_l", "f_Mg_mg_l", "f_Na_mg_l", "f_K_mg_l")

run_wilcox_for_col <- function(var, data) {
  df_var <- data %>%
    filter(
      !is.na(.data[[var]]),
      !is.na(Temporal_status)
    )
  
  # Check data sufficiency
  if (nrow(df_var) < 3 || dplyr::n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "Wilcoxon rank-sum",
      group1 = NA_character_,
      group2 = NA_character_,
      n1 = NA_real_,
      n2 = NA_real_,
      statistic = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one Temporal_status level; test not run."
    ))
  }
  
  # Sample sizes per group
  n_info <- df_var %>%
    count(Temporal_status)
  # ensure consistent order with the test output later
  # (we'll match by group name)
  
  # Build formula `<var> ~ Temporal_status`
  fml <- reformulate("Temporal_status", response = var)
  
  res <- wilcox_test(
    data = df_var,
    formula = fml
  )
  
  # Add n1 and n2 by matching group1/group2 to Temporal_status
  n1 <- n_info$n[match(res$group1, n_info$Temporal_status)]
  n2 <- n_info$n[match(res$group2, n_info$Temporal_status)]
  
  res %>%
    mutate(
      variable = var,
      test = "Wilcoxon rank-sum",
      n1 = n1,
      n2 = n2,
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference between groups (reject H0).",
        "No significant difference between groups (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, p, Interpretation)
}

# Run Wilcoxon tests on all non-normal variables
wilcox_results_wide <- map_dfr(non_normal_vars, run_wilcox_for_col, data = data)

View(wilcox_results_wide)


## no difference for pH, Ca, Mg

write_xlsx(wilcox_results_wide, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/all seasons wilcox_results.xlsx")
```

### Normally distributed data
```{r}
library(dplyr)
library(rstatix)
library(purrr)

# Wide-format data frame
data <- temporal_stats  # <-- your df

# Variables that passed Shapiro (NORMAL)
normal_vars <- c("DIC_mgC_per_l")

# Function to run a t-test on one wide column
run_t_for_col <- function(var, data) {
  df_var <- data %>%
    filter(
      !is.na(.data[[var]]),
      !is.na(Temporal_status)
    )
  
  # Need enough data and at least 2 groups
  if (nrow(df_var) < 3 || dplyr::n_distinct(df_var$Temporal_status) < 2) {
    return(tibble(
      variable = var,
      test = "t-test",
      group1 = NA_character_,
      group2 = NA_character_,
      n1 = NA_real_,
      n2 = NA_real_,
      statistic = NA_real_,
      df = NA_real_,
      p = NA_real_,
      Interpretation = "Not enough data or only one Temporal_status level; test not run."
    ))
  }
  
  # Build formula: `<var> ~ Temporal_status` (handles spaces/commas via reformulate)
  fml <- reformulate("Temporal_status", response = var)
  
  res <- t_test(
    data = df_var,
    formula = fml,
    var.equal = FALSE   # Welch t-test
  )
  
  res %>%
    mutate(
      variable = var,
      test = "t-test",
      Interpretation = ifelse(
        p < 0.05,
        "Significant difference between groups (reject H0).",
        "No significant difference between groups (fail to reject H0)."
      )
    ) %>%
    dplyr::select(variable, test, group1, group2, n1, n2, statistic, df, p, Interpretation)
}

# Run t-tests on all normal variables
t_test_results <- map_dfr(normal_vars, run_t_for_col, data = data)

View(t_test_results)

# significant difference for DIC

write_xlsx(t_test_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/all seasons t_test results.xlsx")
```

## OLD - Early season
### Shapiro
```{r}
library(dplyr)
library(purrr)
library(broom)
library(rstatix)

# List of columns to analyze
columns_to_model <- c("pH", "Alk_mgCaCO3_per_l", "DOC_mgC_per_l", "f_Cl_mg_per_l", 
  "f_SO4_mg_per_l", "f_Ca_mg_l", "f_Mg_mg_l", "f_Na_mg_l", "f_K_mg_l")

pdf("residuals_plots.pdf")  # Start a new PDF file

# Initialize a results list
model_results <- list()

# Loop through each variable
for (col in columns_to_model) {
  
  # Fit the model (example: linear model with sample_collection_season as predictor)
  model <- lm(early_temporal_stats[[col]] ~ early_temporal_stats$Temporal_status, data = early_temporal_stats)
  
  # Extract residuals
  residuals <- resid(model)
  
  # Plot histogram
  hist(residuals, main = paste("Residuals Histogram:", col), xlab = "Residuals")
  
  # Plot QQ plot
  qqnorm(residuals, main = paste("QQ Plot of Residuals:", col))
  qqline(residuals)
  
  # Perform Shapiro-Wilk test on residuals
  test_result <- tryCatch(
    shapiro.test(residuals),
    error = function(e) NULL
  )
  
  # Create the interpretation
  interpretation <- if (!is.null(test_result) && test_result$p.value > 0.05) {
    "The residuals are likely normally distributed (fail to reject H0)."
  } else if (!is.null(test_result)) {
    "The residuals are not normally distributed (reject H0) and a non-parametric test may be more appropriate."
  } else {
    "Test could not be performed due to insufficient data or errors."
  }
  
  # Store the results in a data frame
  model_results[[col]] <- data.frame(
    Variable = col,
    W = if (!is.null(test_result)) test_result$statistic else NA,
    p_value = if (!is.null(test_result)) test_result$p.value else NA,
    Interpretation = interpretation
  )
}

dev.off()  # Close the PDF device

# Combine all results into a single data frame
early_shapiro_results <- bind_rows(model_results)

# Print results
view(early_shapiro_results)

## Alkalinity and Chloride are normally distributed and need to be compared with an ANOVA
```

### Kruskal
```{r}
library(dplyr)
library(rstatix)

# List of columns to analyze - alkalinity removed from the list because shapiro showed normality
nonparametric_columns <- c("pH", "DOC_mgC_per_l", "f_Mg_mg_l", 
  "f_SO4_mg_per_l", "f_Ca_mg_l", "f_Na_mg_l", "f_K_mg_l")

# Initialize a results list
kruskal_results_list <- list()

# Loop through each variable in your list
for (col in nonparametric_columns) {
  
  # Filter out NAs for the current variable
  df_filtered <- early_temporal_stats %>%
    filter(!is.na(.data[[col]]))
  
  # Perform Kruskal-Wallis test comparing sample_collection_season values
  test_result <- tryCatch(
    {
      result <- kruskal_test(as.formula(paste(col, "~ Temporal_status")), data = df_filtered)
      result$variable <- col  # Add variable name to the result
      result
    },
    error = function(e) {
      # Return a default result if test fails
      data.frame(
        variable = col,
        statistic = NA,
        p = NA,
        df = NA
      )
    }
  )
  
  # Create interpretation
  interpretation <- if (!is.null(test_result$p) && !is.na(test_result$p) && test_result$p < 0.05) {
    "Significant difference among groups (reject H0)."
  } else if (!is.null(test_result$p)) {
    "No significant difference among groups (fail to reject H0)."
  } else {
    "Test could not be performed due to insufficient data or errors."
  }
  
  test_result$Interpretation <- interpretation
  
  # Store the result
  kruskal_results_list[[col]] <- test_result
}

# Combine all results into a single dataframe
early_kruskal_results_df <- bind_rows(kruskal_results_list)


# Print the results
view(early_kruskal_results_df)

## only a difference in sulfate

write_xlsx(early_kruskal_results_df, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/early_kruskal_results.xlsx")
```

### Dunn test 
```{r}
# List of columns to do the dunn post hoc test for 
# I removed analytes that did not have any differences identified by the kruskal wallis 
columns_for_dunn <- c("f_SO4_mg_per_l")

library(dplyr)
library(rstatix)
library(multcompView)

# Initialize a results and cld list
dunn_results_list <- list()
cld_results_list <- list()

# Loop through each variable in columns_for_dunn
for (col in columns_for_dunn) {
  
  # Filter out NAs for the current variable
  df_filtered <- early_temporal_stats %>%
    filter(!is.na(.data[[col]]))
  
  # Try performing Dunn's test with Bonferroni adjustment
  test_result <- tryCatch(
    {
      df_filtered %>%
        dunn_test(as.formula(paste(col, "~ Temporal_status")), p.adjust.method = "bonferroni")
    },
    error = function(e) {
      # Return a default result if test fails
      data.frame(
        Variable = col,
        group1 = NA,
        group2 = NA,
        Z = NA,
        p = NA,
        p.adj = NA
      )
    }
  )
  
  # Add the variable name to each row
  test_result$Variable <- col
  
  # Store the result
  dunn_results_list[[col]] <- test_result
  
  # If there is at least one valid pairwise comparison, generate the CLD
  if (!all(is.na(test_result$p.adj))) {
     # Build a matrix of p-values manually
    groups <- sort(unique(c(test_result$group1, test_result$group2)))
    pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                          dimnames = list(groups, groups))
    
    for (i in seq_len(nrow(test_result))) {
      g1 <- as.character(test_result$group1[i])
      g2 <- as.character(test_result$group2[i])
      pval <- test_result$p.adj[i]
      
      pval_matrix[g1, g2] <- pval
      pval_matrix[g2, g1] <- pval  # symmetric
    }
    
    # Generate CLD using multcompView
    cld <- multcompLetters(pval_matrix)
    
    # Convert to a tidy data frame
    cld_df <- data.frame(
      Variable = col,
      Group = names(cld$Letters),
      Letters = cld$Letters
    )
    
    # Store the CLD result
    cld_results_list[[col]] <- cld_df
  }
}

# Combine all Dunn's test results into a single dataframe
early_dunn_results_df <- bind_rows(dunn_results_list)

# Combine all CLD results into a single dataframe
early_cld_results_df <- bind_rows(cld_results_list)

# Print the results
view(early_dunn_results_df)
view(early_cld_results_df)

write_xlsx(early_dunn_results_df, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/early_dunn_results.xlsx")

write_xlsx(early_cld_results_df, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/early_cld_results.xlsx")
```

### ANOVA
```{r}
# make model for Alkalinity
# using lmer because alkalinity was measured multiple times per site in this dataset across 2022 and 2023 making them not entirely independent 
temporal_alk_model <- lm(Alk_mgCaCO3_per_l ~ Temporal_status, data = early_temporal_stats)

# run a one-way ANOVA on Alkalinity
temporal_alk_anova <- anova(temporal_alk_model) # Gives Type III ANOVA table with p-values
temporal_alk_anova
write.csv(as.data.frame(temporal_alk_anova), "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/temporal_alk_anova_results.csv", row.names = TRUE) # save ANOVA table

#ANOVA Results explanation
  # Sum Sq (5214.7): The variation in alkalinity explained by New_Grouping
  # Mean Sq (1303.7): The average variation per degree of freedom
  # NumDF (4): Degrees of freedom for New_Grouping (number of levels - 1)
  # DenDF (20.201): Denominator DF, estimated using Satterthwaite's method (accounts for random effect structure)
  # F value (2.9566): The F-statistic — a ratio of explained to unexplained variance
  # Pr(>F) (0.045): The p-value — the probability that this effect is due to random chance
    # Due to the p-value of 0.045 (< 0.05), there is moderate evidence that New_Grouping has a statistically significant effect on Alk_mgCaCO3_per_l, even after accounting for random variation across Field_label

# Estimated marginal means (group means adjusted for random effects)
temporal_alk_means <- emmeans(temporal_alk_model, ~ Temporal_status)
temporal_alk_means

temporal_pairwise_df <- as.data.frame(summary(temporal_alk_means))
write.csv(temporal_pairwise_df, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/temporal_alk_means.csv", row.names = FALSE)

# No differences from the tukey adjusted pairwise comparison
```

```{r}
# make model for Alkalinity
# using lmer because alkalinity was measured multiple times per site in this dataset across 2022 and 2023 making them not entirely independent 
temporal_Cl_model <- lm(f_Cl_mg_per_l ~ Temporal_status, data = early_temporal_stats)

# run a one-way ANOVA on Alkalinity
temporal_Cl_anova <- anova(temporal_Cl_model) # Gives Type III ANOVA table with p-values
temporal_Cl_anova
write.csv(as.data.frame(temporal_Cl_anova), "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/temporal_Chloride_anova_results.csv", row.names = TRUE) # save ANOVA table

#ANOVA Results explanation
  # Sum Sq (5214.7): The variation in alkalinity explained by New_Grouping
  # Mean Sq (1303.7): The average variation per degree of freedom
  # NumDF (4): Degrees of freedom for New_Grouping (number of levels - 1)
  # DenDF (20.201): Denominator DF, estimated using Satterthwaite's method (accounts for random effect structure)
  # F value (2.9566): The F-statistic — a ratio of explained to unexplained variance
  # Pr(>F) (0.045): The p-value — the probability that this effect is due to random chance
    # Due to the p-value of 0.045 (< 0.05), there is moderate evidence that New_Grouping has a statistically significant effect on Alk_mgCaCO3_per_l, even after accounting for random variation across Field_label

# Estimated marginal means (group means adjusted for random effects)
temporal_Cl_means <- emmeans(temporal_Cl_model, ~ Temporal_status)
temporal_Cl_means

temporal_pairwise_df <- as.data.frame(summary(temporal_Cl_means))
write.csv(temporal_pairwise_df, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/temporal_Chloride_means.csv", row.names = FALSE)

# No differences from the tukey adjusted pairwise comparison
```

## OLD - Late season
### Shapiro
```{r}
library(dplyr)
library(purrr)
library(broom)
library(rstatix)

# List of columns to analyze
columns_to_model <- c("pH", "Alk_mgCaCO3_per_l", "DOC_mgC_per_l", "f_Cl_mg_per_l", 
  "f_SO4_mg_per_l", "f_Ca_mg_l", "f_Mg_mg_l", "f_Na_mg_l", "f_K_mg_l")

pdf("residuals_plots.pdf")  # Start a new PDF file

# Initialize a results list
model_results <- list()

# Loop through each variable
for (col in columns_to_model) {
  
  # Fit the model (example: linear model with sample_collection_season as predictor)
  model <- lm(late_temporal_stats[[col]] ~ late_temporal_stats$Temporal_status, data = late_temporal_stats)
  
  # Extract residuals
  residuals <- resid(model)
  
  # Plot histogram
  hist(residuals, main = paste("Residuals Histogram:", col), xlab = "Residuals")
  
  # Plot QQ plot
  qqnorm(residuals, main = paste("QQ Plot of Residuals:", col))
  qqline(residuals)
  
  # Perform Shapiro-Wilk test on residuals
  test_result <- tryCatch(
    shapiro.test(residuals),
    error = function(e) NULL
  )
  
  # Create the interpretation
  interpretation <- if (!is.null(test_result) && test_result$p.value > 0.05) {
    "The residuals are likely normally distributed (fail to reject H0)."
  } else if (!is.null(test_result)) {
    "The residuals are not normally distributed (reject H0) and a non-parametric test may be more appropriate."
  } else {
    "Test could not be performed due to insufficient data or errors."
  }
  
  # Store the results in a data frame
  model_results[[col]] <- data.frame(
    Variable = col,
    W = if (!is.null(test_result)) test_result$statistic else NA,
    p_value = if (!is.null(test_result)) test_result$p.value else NA,
    Interpretation = interpretation
  )
}

dev.off()  # Close the PDF device

# Combine all results into a single data frame
late_shapiro_results <- bind_rows(model_results)

# Print results
view(late_shapiro_results)

## pH, Alkalinity and magnesium are normally distributed and need to be compared with an ANOVA
```

### Kruskal
```{r}
library(dplyr)
library(rstatix)

# List of columns to analyze - alkalinity removed from the list because shapiro showed normality
nonparametric_columns <- c("DOC_mgC_per_l", "f_Cl_mg_per_l", 
  "f_SO4_mg_per_l", "f_Ca_mg_l", "f_Na_mg_l", "f_K_mg_l")

# Initialize a results list
kruskal_results_list <- list()

# Loop through each variable in your list
for (col in nonparametric_columns) {
  
  # Filter out NAs for the current variable
  df_filtered <- late_temporal_stats %>%
    filter(!is.na(.data[[col]]))
  
  # Perform Kruskal-Wallis test comparing sample_collection_season values
  test_result <- tryCatch(
    {
      result <- kruskal_test(as.formula(paste(col, "~ Temporal_status")), data = df_filtered)
      result$variable <- col  # Add variable name to the result
      result
    },
    error = function(e) {
      # Return a default result if test fails
      data.frame(
        variable = col,
        statistic = NA,
        p = NA,
        df = NA
      )
    }
  )
  
  # Create interpretation
  interpretation <- if (!is.null(test_result$p) && !is.na(test_result$p) && test_result$p < 0.05) {
    "Significant difference among groups (reject H0)."
  } else if (!is.null(test_result$p)) {
    "No significant difference among groups (fail to reject H0)."
  } else {
    "Test could not be performed due to insufficient data or errors."
  }
  
  test_result$Interpretation <- interpretation
  
  # Store the result
  kruskal_results_list[[col]] <- test_result
}

# Combine all results into a single dataframe
late_kruskal_results_df <- bind_rows(kruskal_results_list)


# Print the results
view(late_kruskal_results_df)

## only a difference in sulfate, sodium and potassium

write_xlsx(late_kruskal_results_df, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/late_kruskal_results.xlsx")
```

### Dunn test 
```{r}
# List of columns to do the dunn post hoc test for 
# I removed analytes that did not have any differences identified by the kruskal wallis 
columns_for_dunn <- c("f_SO4_mg_per_l", "f_Na_mg_l", "f_K_mg_l")

library(dplyr)
library(rstatix)
library(multcompView)

# Initialize a results and cld list
dunn_results_list <- list()
cld_results_list <- list()

# Loop through each variable in columns_for_dunn
for (col in columns_for_dunn) {
  
  # Filter out NAs for the current variable
  df_filtered <- late_temporal_stats %>%
    filter(!is.na(.data[[col]]))
  
  # Try performing Dunn's test with Bonferroni adjustment
  test_result <- tryCatch(
    {
      df_filtered %>%
        dunn_test(as.formula(paste(col, "~ Temporal_status")), p.adjust.method = "bonferroni")
    },
    error = function(e) {
      # Return a default result if test fails
      data.frame(
        Variable = col,
        group1 = NA,
        group2 = NA,
        Z = NA,
        p = NA,
        p.adj = NA
      )
    }
  )
  
  # Add the variable name to each row
  test_result$Variable <- col
  
  # Store the result
  dunn_results_list[[col]] <- test_result
  
  # If there is at least one valid pairwise comparison, generate the CLD
  if (!all(is.na(test_result$p.adj))) {
     # Build a matrix of p-values manually
    groups <- sort(unique(c(test_result$group1, test_result$group2)))
    pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                          dimnames = list(groups, groups))
    
    for (i in seq_len(nrow(test_result))) {
      g1 <- as.character(test_result$group1[i])
      g2 <- as.character(test_result$group2[i])
      pval <- test_result$p.adj[i]
      
      pval_matrix[g1, g2] <- pval
      pval_matrix[g2, g1] <- pval  # symmetric
    }
    
    # Generate CLD using multcompView
    cld <- multcompLetters(pval_matrix)
    
    # Convert to a tidy data frame
    cld_df <- data.frame(
      Variable = col,
      Group = names(cld$Letters),
      Letters = cld$Letters
    )
    
    # Store the CLD result
    cld_results_list[[col]] <- cld_df
  }
}

# Combine all Dunn's test results into a single dataframe
late_dunn_results_df <- bind_rows(dunn_results_list)

# Combine all CLD results into a single dataframe
late_cld_results_df <- bind_rows(cld_results_list)

# Print the results
view(late_dunn_results_df)
view(late_cld_results_df)

write_xlsx(late_dunn_results_df, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/late_dunn_results.xlsx")

write_xlsx(late_cld_results_df, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/late_cld_results.xlsx")
```

### ANOVA
```{r}
# make model for Alkalinity
# using lmer because alkalinity was measured multiple times per site in this dataset across 2022 and 2023 making them not entirely independent 
temporal_alk_model <- lm(Alk_mgCaCO3_per_l ~ Temporal_status, data = late_temporal_stats)

# run a one-way ANOVA on Alkalinity
temporal_alk_anova <- anova(temporal_alk_model) # Gives Type III ANOVA table with p-values
temporal_alk_anova
write.csv(as.data.frame(temporal_alk_anova), "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/late_temporal_alk_anova_results.csv", row.names = TRUE) # save ANOVA table

# Estimated marginal means (group means adjusted for random effects)
late_temporal_alk_means <- emmeans(temporal_alk_model, ~ Temporal_status)
late_temporal_alk_means

temporal_pairwise_df <- as.data.frame(summary(late_temporal_alk_means))
write.csv(temporal_pairwise_df, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/late_temporal_alk_means.csv", row.names = FALSE)

# No differences from the tukey adjusted pairwise comparison
```

```{r}
# make model for pH
# using lm because alkalinity was measured multiple times per site in this dataset across 2022 and 2023 making them not entirely independent 
temporal_Mg_model <- lm(f_Mg_mg_l ~ Temporal_status, data = late_temporal_stats)

# run a one-way ANOVA on Alkalinity
temporal_Mg_anova <- anova(temporal_Mg_model) # Gives Type III ANOVA table with p-values
temporal_Mg_anova
write.csv(as.data.frame(temporal_Mg_anova), "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/late_temporal_magnesium_anova_results.csv", row.names = TRUE) # save ANOVA table

# Estimated marginal means (group means adjusted for random effects)
late_temporal_Mg_means <- emmeans(temporal_Mg_model, ~ Temporal_status)
late_temporal_Mg_means

temporal_pairwise_df <- as.data.frame(summary(late_temporal_Mg_means))
write.csv(temporal_pairwise_df, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/late_temporal_Magnesium_means.csv", row.names = FALSE)

# No differences from the tukey adjusted pairwise comparison
```

```{r}
## pH
temporal_pH_model <- lm(pH ~ Temporal_status, data = late_temporal_stats)

# Run a one-way ANOVA on pH
temporal_pH_anova <- anova(temporal_pH_model) # Gives ANOVA table with p-values
temporal_pH_anova

# Save ANOVA table
write.csv(as.data.frame(temporal_pH_anova),
          "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/late_temporal_pH_anova_results.csv",
          row.names = TRUE)

# Estimated marginal means for pH by Temporal_status
late_temporal_pH_means <- emmeans(temporal_pH_model, ~ Temporal_status)
late_temporal_pH_means

# Save estimated marginal means
temporal_pairwise_df <- as.data.frame(summary(late_temporal_pH_means))
write.csv(temporal_pairwise_df,
          "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Agashashok Temporal Analysis/late_temporal_pH_means.csv",
          row.names = FALSE)
```

# Add Subcatchment Column
```{r}
Agashashok_for_plots <- Agashashok_for_plots %>%
  mutate(
    Subcatchment = case_when(
      startsWith(SiteID_mod, "AN") ~ "North Fork",
      startsWith(SiteID_mod, "AS") ~ "South Fork",
      startsWith(SiteID_mod, "AM") ~ "Main",
      TRUE ~ NA_character_  # Optional: sets others to NA
    )
  ) %>%
  relocate(Subcatchment, .after = Field_label)

Agashashok_for_plots <- Agashashok_for_plots %>%
  mutate(Subcatchment_year = paste(Subcatchment, sample_collection_year, sep = "_")) %>%
  relocate(Subcatchment_year, .after = Subcatchment)
```

# Summary Stats by Subcatment_year
```{r}
elements <- c(
  "pH", "Temp", "Diss_oxy", "Diss_oxy_percent_sat", "Spec_Cond", "DIC", 
  "Alk", "DOC", "f_Cl", "f_NO3", "f_SO4", "f_Ca", "f_Mg", "f_Na", "f_K",
  "f_SiO2",
  "f_Pb", 
  "f_Ag",
  "f_Al",
  "f_As",
  "f_Ba",
  #"f_Be",
  "f_Cd",
  "f_Ce",
  "f_Co",
  "f_Cr",
  "f_Cu",
  "f_Dy",
  "f_Fe",
  "f_La",
  "f_Mn",
  "f_Nd",
  "f_Ni",
  "f_Pr",
  "f_Se",
  #"f_Th",
  "f_Tl",
  "f_U",
  "f_V",
  "f_Y",
  "f_Zn"
)

columns <- c(
  "pH", "Temp_deg_celsius", "Diss_oxy_mg_per_l", "Diss_oxy_percent_sat", "Spec_Cond_microS_per_cm", 
  "DIC_mgC_per_l", "Alk_mgCaCO3_per_l", "DOC_mgC_per_l", "f_Cl_mg_per_l", "f_NO3_mgN_per_l", 
  "f_SO4_mg_per_l", "f_Ca_mg_l", "f_Mg_mg_l", "f_Na_mg_l", "f_K_mg_l",
  "f_SiO2_mg_per_l",
  "f_Pb_mcg_per_l", 
  "f_Ag_mcg_per_l",
  "f_Al_mcg_per_l",
  "f_As_mcg_per_l",
  "f_Ba_mcg_per_l",
  #"f_Be_mcg_per_l",
  #"f_Br_mcg_per_l",
  "f_Cd_mcg_per_l",
  "f_Ce_mcg_per_l",
  "f_Co_mcg_per_l",
  "f_Cr_mcg_per_l",
  "f_Cu_mcg_per_l",
  "f_Dy_mcg_per_l",
  "f_Fe_mcg_per_l",
  "f_La_mcg_per_l",
  "f_Mn_mcg_per_l",
  "f_Nd_mcg_per_l",
  "f_Ni_mcg_per_l",
  "f_Pr_mcg_per_l",
  "f_Se_mcg_per_l",
  #"f_Th_mcg_per_l",
  "f_Tl_mcg_per_l",
  "f_U_mcg_per_l",
  "f_V_mcg_per_l",
  "f_Y_mcg_per_l",
  "f_Zn_mcg_per_l"
)
```

```{r}
# loop for summary stats using rstatix instead of base R
library(dplyr)
library(rstatix)

# Initialize an empty list to store results
summary_stats_list <- list()
quartiles_list <- list()

# Loop through elements and columns
for (i in seq_along(elements)) {
  element <- elements[i]
  column <- columns[i]
  
  # Perform summary operation with a default empty tibble if an error occurs
  summary <- 
    Agashashok_for_plots %>% # to group by New Grouping (seeps included)
    dplyr::select(5,14:52) %>% # all data
    #dplyr::select(2,4,19:82) %>% # New Grouping
    filter(!is.na(.data[[column]])) %>%
     group_by(Subcatchment_year) %>% #This is where you can change what variable you want to group the data by
      get_summary_stats(vars = column, type = "common")

  
  # Calculate Q1 and Q3
  q1_q3 <- 
    Agashashok_for_plots %>% # to group by New Grouping (seeps included)
    dplyr::select(5,14:52) %>% # all data
    #dplyr::select(2,4,19:82) %>% # New Grouping
    filter(!is.na(.data[[column]])) %>%
     group_by(Subcatchment_year) %>% #This is where you can change what variable you want to group the data by
      summarise(
        variable = column,
        Q1 = round(quantile(.data[[column]], probs = 0.25, na.rm = TRUE), 2),
        Q3 = round(quantile(.data[[column]], probs = 0.75, na.rm = TRUE), 2),
        .groups = "drop"
      )
  
  # Combine summary with Q1 and Q3
  #summary_combined <- summary %>%
    #left_join(q1_q3, by = c("New_Grouping", "variable"))
  
  # Store result
  summary_stats_list[[i]] <- summary
  quartiles_list[[i]] <- q1_q3
}

# Combine into one dataframe
summary_df <- do.call(rbind, summary_stats_list)
quartiles_df <- do.call(rbind, quartiles_list)

quartiles_df <- quartiles_df %>%
  mutate(joining = paste(Subcatchment_year, variable, sep = "_"))

summary_df <- summary_df %>%
  mutate(joining = paste(Subcatchment_year, variable, sep = "_"))

view(summary_df) # Grouped by New_Grouping and Watershed
view(quartiles_df)

summary_combined <- summary_df %>%
  left_join(quartiles_df, by = "joining") %>%
  dplyr::select(-joining, -Subcatchment_year.y, -variable.y)

summary_combined <-  summary_combined %>%
  dplyr::rename(variable = variable.x) %>%
  dplyr::rename(Subcatchment_year = Subcatchment_year.x)
view(summary_combined)
#view(summary_df) # grouped by New_Grouping only

#write_xlsx(summary_combined, "C:/Users/tevinger/Downloads/Group with Watersheds summary stats_rstatix.xlsx")
```


# Stats - Pre vs Post onset comparison
```{r}
onset_df <- Agashashok_for_plots %>%
  mutate(temporal_status = case_when(
    sample_collection_year %in% c("2015", "2016", "2017", "2018") ~ "pre",
    sample_collection_year %in% c("2019", "2020", "2021","2022","2023","2024") ~ "post",
    TRUE ~ NA_character_
  )) %>%
  relocate(temporal_status, .after = Subcatchment_year) %>%
  mutate(sub_temp = paste(Subcatchment, temporal_status, sep = "_")) %>%
  relocate(sub_temp, .after = temporal_status)

view(onset_df)
```

```{r}
onset_means <- onset_df %>%
  group_by(sample_collection_season, temporal_status) %>%
  summarise(across(
    .cols = where(is.numeric) & !any_of(c("sample_collection_year")),  # exclude non-data numeric columns if needed
    .fns = \(x) mean(x, na.rm = TRUE)
  ), .groups = "drop") %>% # to return an ungrouped data frame 
  dplyr::select(-SiteID_total_count)
  
view(onset_means)

write_xlsx(onset_means, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Aggie temporal sulfate pre vs post means_V3.xlsx")
```

```{r}
# specific data frames for each subcatchment for statistics
Aggie_Main_onset_df <- onset_df %>%
  filter(Subcatchment == "Main")

Aggie_SF_onset_df <- onset_df %>%
  filter(Subcatchment == "South Fork")

Aggie_NF_onset_df <- onset_df %>%
  filter(Subcatchment == "North Fork")
```

## Sulfate Stats
```{r}
# use onset_df with sub_temp column that has pre and post
library(lme4)
library(emmeans)

AMS_SO4_model <- lm(f_SO4_mg_per_l ~ temporal_status, data = Aggie_Main_onset_df)
AMS_SO4_emm <- emmeans(AMS_SO4_model, ~ temporal_status)
AMS_SO4_contrast <- contrast(AMS_SO4_emm, method = "pairwise")
print(AMS_SO4_contrast)

ANF_SO4_model <- lm(f_SO4_mg_per_l ~ temporal_status, data = Aggie_NF_onset_df)
ANF_SO4_emm <- emmeans(ANF_SO4_model, ~ temporal_status)
ANF_SO4_contrast <- contrast(ANF_SO4_emm, method = "pairwise")
print(ANF_SO4_contrast)

ASF_SO4_model <- lm(f_SO4_mg_per_l ~ temporal_status, data = Aggie_SF_onset_df)
ASF_SO4_emm <- emmeans(ASF_SO4_model, ~ temporal_status)
ASF_SO4_contrast <- contrast(ASF_SO4_emm, method = "pairwise")
print(ASF_SO4_contrast)

# Convert to data frames
df1 <- as.data.frame(AMS_SO4_contrast)
df2 <- as.data.frame(ANF_SO4_contrast)
df3 <- as.data.frame(ASF_SO4_contrast)

# Add a column to identify the model or variable
df1$Subcatchment <- "Main"
df2$Subcatchment <- "NF"
df3$Subcatchment <- "SF"

df1$Variable <- "f_SO4_mg_l"
df2$Variable <- "f_SO4_mg_l"
df3$Variable <- "f_SO4_mg_l"

# Combine them into one data frame
combined_contrasts_SO4 <- bind_rows(df1, df2, df3)

# View the result
view(combined_contrasts_SO4)

write_xlsx(combined_contrasts_SO4, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Aggie temporal sulfate pre vs post.xlsx")
```

## Alkalinity Stats
```{r}
# use onset_df with sub_temp column that has pre and post
library(lme4)
library(emmeans)

# Models for Alkalinity instead of Sulfate
AMS_Alk_model <- lm(Alk_mgCaCO3_per_l ~ temporal_status, data = Aggie_Main_onset_df)
AMS_Alk_emm <- emmeans(AMS_Alk_model, ~ temporal_status)
AMS_Alk_contrast <- contrast(AMS_Alk_emm, method = "pairwise")
print(AMS_Alk_contrast)

ANF_Alk_model <- lm(Alk_mgCaCO3_per_l ~ temporal_status, data = Aggie_NF_onset_df)
ANF_Alk_emm <- emmeans(ANF_Alk_model, ~ temporal_status)
ANF_Alk_contrast <- contrast(ANF_Alk_emm, method = "pairwise")
print(ANF_Alk_contrast)

ASF_Alk_model <- lm(Alk_mgCaCO3_per_l ~ temporal_status, data = Aggie_SF_onset_df)
ASF_Alk_emm <- emmeans(ASF_Alk_model, ~ temporal_status)
ASF_Alk_contrast <- contrast(ASF_Alk_emm, method = "pairwise")
print(ASF_Alk_contrast)

# Convert to data frames
df1 <- as.data.frame(AMS_Alk_contrast)
df2 <- as.data.frame(ANF_Alk_contrast)
df3 <- as.data.frame(ASF_Alk_contrast)

# Add a column to identify the model or variable
df1$Subcatchment <- "Main"
df2$Subcatchment <- "NF"
df3$Subcatchment <- "SF"

df1$Variable <- "Alk_mgCaCO3_per_l"
df2$Variable <- "Alk_mgCaCO3_per_l"
df3$Variable <- "Alk_mgCaCO3_per_l"

# Combine them into one data frame
combined_contrasts_Alk <- bind_rows(df1, df2, df3)

# View the result
view(combined_contrasts_Alk)

write_xlsx(combined_contrasts_Alk, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Aggie temporal alkalinity pre vs post.xlsx")
```


# Subcatchment specific Temporal Boxplots
## df
```{r}
temporal_df <- summary_combined %>%
  separate(Subcatchment_year, into = c("Subcatchment", "year"), sep = "_") %>%
  mutate(year = as.integer(year))  # Ensure year is an integer
```

```{r}
# Add missing years
temporal_filled <- temporal_df %>%
  complete(
    Subcatchment,
    variable,
    year = 2015:2024
  ) %>%
  mutate(
    Subcatchment = factor(Subcatchment, levels = c("South Fork", "North Fork", "Main")),
    year = as.character(year),  # ensure year is treated as categorical if needed
    year_sub = interaction(year, Subcatchment, sep = "_")
  ) 
  
```

```{r}
temporal_filled$year_sub <- factor(
  temporal_filled$year_sub,
  levels = c(
    "2015_South Fork", "2015_North Fork", "2015_Main",
    "2016_South Fork", "2016_North Fork", "2016_Main",
    "2017_South Fork", "2017_North Fork", "2017_Main",
    "2018_South Fork", "2018_North Fork", "2018_Main",
    "2019_South Fork", "2019_North Fork", "2019_Main",
    "2020_South Fork", "2020_North Fork", "2020_Main",
    "2021_South Fork", "2021_North Fork", "2021_Main",
    "2022_South Fork", "2022_North Fork", "2022_Main",
    "2023_South Fork", "2023_North Fork", "2023_Main",
    "2024_South Fork", "2024_North Fork", "2024_Main"
  )
)

view(temporal_filled)

temporal_df <- temporal_filled
```

```{r}
temporal_df <- temporal_df %>%
  mutate(year = as.integer(year)) %>%
  complete(
    Subcatchment,
    variable,
    year = seq(2015, 2024, by = 0.5)  # Adds 2015, 2015.5, 2016, ..., 2024
  ) %>%
  mutate(
    Subcatchment = factor(Subcatchment, levels = c("South Fork", "North Fork", "Main")),
    year = as.character(year),  # Optional: only if treating year as a discrete axis
    year_sub = interaction(year, Subcatchment, sep = "_")
  )


temporal_df$year_sub <- factor(
  temporal_df$year_sub,
  levels = c(
  "2015_South Fork", "2015_North Fork", "2015_Main",
  "2015.5_South Fork", "2015.5_North Fork", "2015.5_Main",
  "2016_South Fork", "2016_North Fork", "2016_Main",
  "2016.5_South Fork", "2016.5_North Fork", "2016.5_Main",
  "2017_South Fork", "2017_North Fork", "2017_Main",
  "2017.5_South Fork", "2017.5_North Fork", "2017.5_Main",
  "2018_South Fork", "2018_North Fork", "2018_Main",
  "2018.5_South Fork", "2018.5_North Fork", "2018.5_Main",
  "2019_South Fork", "2019_North Fork", "2019_Main",
  "2019.5_South Fork", "2019.5_North Fork", "2019.5_Main",
  "2020_South Fork", "2020_North Fork", "2020_Main",
  "2020.5_South Fork", "2020.5_North Fork", "2020.5_Main",
  "2021_South Fork", "2021_North Fork", "2021_Main",
  "2021.5_South Fork", "2021.5_North Fork", "2021.5_Main",
  "2022_South Fork", "2022_North Fork", "2022_Main",
  "2022.5_South Fork", "2022.5_North Fork", "2022.5_Main",
  "2023_South Fork", "2023_North Fork", "2023_Main",
  "2023.5_South Fork", "2023.5_North Fork", "2023.5_Main",
  "2024_South Fork", "2024_North Fork", "2024_Main"
)
)

view(temporal_df)
```

## regression data frames
Make a data frame for each subcatchment 
```{r}
Aggie_Main <- temporal_filled %>%
  filter(Subcatchment == "Main")

Aggie_SF <- temporal_filled %>%
  filter(Subcatchment == "South Fork")

Aggie_NF <- temporal_filled %>%
  filter(Subcatchment == "North Fork")
```

## Labels
```{r}
ylab_DOC <- expression(bold(DOC)~(mg~L^-1))
ylab_DIC <- expression(bold(DIC)~(mgC~L^-1))

ylab_Ca <- expression(bold(Ca)~bold((mg~L^-1)))
ylab_Mg <- expression(bold(Mg)~bold((mg~L^-1)))
ylab_Chloride <- expression(bold(Chloride)~bold((mg~L^-1)))
ylab_Sulfate <- expression(bold(SO[4]^-2)~bold((mg~L^-1)))
ylab_SpC <- expression(bold(Specific~Conductivity)~bold((μS~cm^-1)))
ylab_Alk <- expression(bold(Alkalinity~bold((mgCaCO[3]~L^-1))))

north_fork_ticks <- levels(temporal_filled$year_sub)[grepl("North Fork$", levels(temporal_filled$year_sub))]
north_fork_labels <- gsub("_North Fork", "", north_fork_ticks)
```

##Theme
```{r}
temporal_theme <- 
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.y = element_text(size = 16, color = "black", face = "bold"),
    axis.text.x = element_text(size = 12, color = "black", face = "bold"),
    axis.ticks.y = element_line(linewidth = 0.9, color = "black"),  # Thicker y-axis ticks
    axis.ticks.length.y = unit(0.1, "cm"),  # Longer tick marks
    
    axis.ticks.x = element_line(linewidth = 0.9, color = "black"),  # Thicker y-axis ticks
    #axis.ticks.length.x = unit(0.15, "cm"),  # Longer tick marks
    
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold", color = "black"),
    legend.position = "top",
    legend.text = element_text(size = 15),
    legend.title = element_text(size = 17, face = "bold", hjust = 0.5),
    
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    #panel.background = element_rect(fill = "white"),
    panel.border = element_rect(fill = NA, color = "black", size = 1.25),
    panel.background = element_rect(fill = "transparent"), # Panel background
    plot.background = element_rect(fill = "transparent", color = NA) # Plot background

  )
```

## Statistics
Regressions to evaluate concentrations over time
```{r}
AMS_sulfate_df <- Aggie_Main %>%
  filter(variable == "f_SO4_mg_per_l") %>%
  mutate(year = as.integer(as.character(year))) # make year continuous 

AMS_sulfate_model <- lm(mean ~ year, data = AMS_sulfate_df)
summary(AMS_sulfate_model)


ANF_sulfate_df <- Aggie_NF %>%
  filter(variable == "f_SO4_mg_per_l") %>%
  mutate(year = as.integer(as.character(year))) # make year continuous 

ANF_sulfate_model <- lm(mean ~ year, data = ANF_sulfate_df)
summary(ANF_sulfate_model)


ASF_sulfate_df <- Aggie_SF %>%
  filter(variable == "f_SO4_mg_per_l") %>%
  mutate(year = as.integer(as.character(year))) # make year continuous 

ASF_sulfate_model <- lm(mean ~ year, data = ASF_sulfate_df)
summary(ASF_sulfate_model)
  
```

```{r}
library(dplyr)
library(purrr)

# Vectors of variable names
elements_2 <- c(
  "pH",  "Spec_Cond", "DIC", "Alk", "DOC", "f_Cl", "f_NO3", "f_SO4", "f_Ca", "f_Mg", "f_Na", "f_K",
  "f_SiO2", "f_Al", "p_Al", "f_As", "p_As", "f_Ba", "p_Ba", "f_Cd", "p_Cd", "f_Ce", "p_Ce",
  "f_Co", "p_Co", "f_Cr", "p_Cr", "f_Cu", "p_Cu", "f_Dy", "p_Dy", "f_Fe", "p_Fe", "f_La", "p_La",
  "f_Mn", "p_Mn", "f_Nd", "p_Nd", "f_Ni", "p_Ni", "f_Pb", "p_Pb", "f_Pr", "p_Pr", "f_Se", "p_Se",
  "f_Tl", "p_Tl", "f_U", "p_U", "f_Y", "p_Y", "f_Zn", "p_Zn", "f_REE", "p_REE"
)

columns_2 <- c(
  "pH", "Spec_Cond_microS_per_cm", "DIC_mgC_per_l", "Alk_mgCaCO3_per_l", "DOC_mgC_per_l", "f_Cl_mg_per_l", "f_NO3_mgN_per_l", 
  "f_SO4_mg_per_l", "f_Ca_mg_l", "f_Mg_mg_l", "f_Na_mg_l", "f_K_mg_l", "f_SiO2_mg_per_l",
  "f_Al_mcg_per_l", "p_Al_mcg_per_l", "f_As_mcg_per_l", "p_As_mcg_per_l", "f_Ba_mcg_per_l", "p_Ba_mcg_per_l",
  "f_Cd_mcg_per_l", "p_Cd_mcg_per_l", "f_Ce_mcg_per_l", "p_Ce_mcg_per_l", "f_Co_mcg_per_l", "p_Co_mcg_per_l",
  "f_Cr_mcg_per_l", "p_Cr_mcg_per_l", "f_Cu_mcg_per_l", "p_Cu_mcg_per_l", "f_Dy_mcg_per_l", "p_Dy_mcg_per_l",
  "f_Fe_mcg_per_l", "p_Fe_mcg_per_l", "f_La_mcg_per_l", "p_La_mcg_per_l", "f_Mn_mcg_per_l", "p_Mn_mcg_per_l",
  "f_Nd_mcg_per_l", "p_Nd_mcg_per_l", "f_Ni_mcg_per_l", "p_Ni_mcg_per_l", "f_Pb_mcg_per_l", "p_Pb_mcg_per_l",
  "f_Pr_mcg_per_l", "p_Pr_mcg_per_l", "f_Se_mcg_per_l", "p_Se_mcg_per_l", "f_Tl_mcg_per_l", "p_Tl_mcg_per_l",
  "f_U_mcg_per_l", "p_U_mcg_per_l", "f_Y_mcg_per_l", "p_Y_mcg_per_l", "f_Zn_mcg_per_l", "p_Zn_mcg_per_l",
  "f_REE", "p_REE"
)

site_dfs <- list(Aggie_Main = Aggie_Main, Aggie_NF = Aggie_NF, Aggie_SF = Aggie_SF)

results_list <- list()

for (i in seq_along(elements_2)) {
  element <- elements_2[i]
  column <- columns_2[i]
  
  for (site_name in names(site_dfs)) {
    site_df <- site_dfs[[site_name]] %>%
      filter(variable == column) %>%
      mutate(year = as.integer(as.character(year)))
    
    if (nrow(site_df) >= 3) {
      model <- lm(mean ~ year, data = site_df)
      model_sum <- summary(model)
      
      results_list[[paste0(site_name, "_", element)]] <- data.frame(
        Site = site_name,
        Variable = element,
        Intercept = coef(model_sum)[1, 1],
        Intercept_SE = coef(model_sum)[1, 2],
        Estimate = coef(model_sum)[2, 1],
        Std_Error = coef(model_sum)[2, 2],
        t_value = coef(model_sum)[2, 3],
        p_value = coef(model_sum)[2, 4],
        R_squared = model_sum$r.squared
      )
    }
  }
}

# Combine all into one dataframe
final_results <- dplyr::bind_rows(results_list)

view(final_results)

write_xlsx(final_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Aggie temporal regression results.xlsx")
```

## Sulfate
regression equations
```{r}
sulfate_equation_df <- final_results %>%
  filter(Variable == "f_SO4") %>%
  group_by(Site) %>%
  mutate(
    intercept = round(Intercept,1),
    slope     = round(Estimate,1),
    r2        = round(R_squared,2),
    eq_label  = paste0("y = ", slope, "x + ", intercept, "\nR² = ", r2),
    x = 1,
    y = 250
  ) %>%
  mutate(
    Subcatchment = case_when(
      Site == "Aggie_Main" ~ "Main",
      Site == "Aggie_NF" ~ "North Fork",
      Site == "Aggie_SF" ~ "South Fork"
    )
  ) %>%
  mutate( # set the y axis position for each equation
  y = case_when(
    Subcatchment == "North Fork" ~ 250,
    Subcatchment == "South Fork" ~ 240,
    Subcatchment == "Main" ~ 230
  )
)

view(sulfate_equation_df)
```

```{r}
# SO4 by subcatchment
SO4_aggie <- temporal_df %>%
  filter(variable == "f_SO4_mg_per_l") %>%
  ggplot(aes(x = year_sub, y = mean, fill = Subcatchment, shape = Subcatchment)) +
  
  #geom_smooth(method = "lm", se = FALSE, formula = y ~ x, aes(group = Subcatchment, color = Subcatchment)) +
  
  labs(
    x = "Year",
    y = "Mean Value",
    color = "Subcatchment"
  ) +
  
  geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.2) +
  geom_point(aes(size = Subcatchment), color = "black", stroke = 1.1) +
  
  scale_fill_manual(values = c("Main" = "#71d5f6", "North Fork" = "#f67192", "South Fork" = "#f1c029")) +
  scale_color_manual(values = c("Main" = "#71d5f6", "North Fork" = "#f67192", "South Fork" = "#efb911")) +
  scale_shape_manual(values = c("Main" = 23, "North Fork" = 21, "South Fork" = 24)) +
  scale_size_manual(values = c("Main" = 3, "North Fork" = 4, "South Fork" = 3)) +
  
   geom_vline(xintercept = 23, linetype = "dashed", color = "black", size = 1, alpha = 0.6) +
  
  scale_x_discrete(
    breaks = north_fork_ticks,
    labels = north_fork_labels,
    expand = expansion(mult = c(0.03, 0.03))
  ) +
  
  scale_y_continuous(
    breaks = c(0,25,50,75,100,125,150,175,200,225,250,275),
    labels = c(0,"",50,"",100,"",150,"",200,"",250,""),
    expand = expansion(mult = c(0.01, 0.03))
  ) +
  
  labs(
    title = NULL,
    x = "Year",
    y = "Mean SO4",
    color = "Subcatchment"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        #axis.text.y = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

SO4_aggie

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/SO4_V7 no regressions.png", SO4_aggie, width = 4, height = 5, dpi = 300, bg = "transparent")
```

```{r}
sulfate_temporal <- Agashashok_for_plots %>%
ggplot(aes(x = factor(sample_collection_year), y = f_SO4_mg_per_l, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.8)) +
  labs(
    title = "Concentration by Year and Season",
    x = "Year",
    y = "Concentration (units)",  # replace with actual units
    fill = "Season"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

sulfate_temporal
```

## Calcium
```{r}
# SO4 by subcatchment
Ca_aggie <- temporal_df %>%
  filter(variable == "f_Ca_mg_l") %>%
  ggplot(aes(x = year_sub, y = mean, fill = Subcatchment, shape = Subcatchment)) +
  
  geom_smooth(method = "lm", se = FALSE, formula = y ~ x, aes(group = Subcatchment, color = Subcatchment)) +
  
  labs(
    x = "Year",
    y = "Mean Value",
    color = "Subcatchment"
  ) +
  
  geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.2) +
  geom_point(aes(size = Subcatchment), color = "black", stroke = 1.1) +
  
  scale_fill_manual(values = c("Main" = "#71d5f6", "North Fork" = "#f67192", "South Fork" = "#f6d571")) +
  scale_color_manual(values = c("Main" = "#71d5f6", "North Fork" = "#f67192", "South Fork" = "#f6d571")) +
  scale_shape_manual(values = c("Main" = 23, "North Fork" = 21, "South Fork" = 24)) +
  scale_size_manual(values = c("Main" = 3, "North Fork" = 4, "South Fork" = 3)) +
  
   geom_vline(xintercept = 23, linetype = "dashed", color = "black", size = 1, alpha = 0.6) +
  
  scale_x_discrete(
    breaks = north_fork_ticks,
    labels = north_fork_labels,
    expand = expansion(mult = c(0.03, 0.03))
  ) +
  
  scale_y_continuous(
    breaks = c(0,25,50,75,100,125,150,175,200,225,250,275),
    labels = c(0,25,50,75,100,125,150,"",200,"",250,""),
    expand = expansion(mult = c(0.01, 0.03))
  ) +
  
  labs(
    title = NULL,
    x = "Year",
    y = "Mean SO4",
    color = "Subcatchment"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none"
        ,axis.text.y = element_blank()
        )

Ca_aggie

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Ca_V2 no labels.png",Ca_aggie, width = 4, height = 5, dpi = 300)
```

## DOC
```{r}
# SO4 by subcatchment
DOC_aggie <- temporal_df %>%
  filter(variable == "DOC_mgC_per_l") %>%
  ggplot(aes(x = year_sub, y = mean, fill = Subcatchment, shape = Subcatchment)) +
  
  geom_smooth(method = "lm", se = FALSE, formula = y ~ x, aes(group = Subcatchment, color = Subcatchment)) +
  
  labs(
    x = "Year",
    y = "Mean Value",
    color = "Subcatchment"
  ) +
  
  geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.2) +
  geom_point(aes(size = Subcatchment), color = "black", stroke = 1.1) +
  
  scale_fill_manual(values = c("Main" = "#71d5f6", "North Fork" = "#f67192", "South Fork" = "#f6d571")) +
  scale_color_manual(values = c("Main" = "#71d5f6", "North Fork" = "#f67192", "South Fork" = "#f6d571")) +
  scale_shape_manual(values = c("Main" = 23, "North Fork" = 21, "South Fork" = 24)) +
  scale_size_manual(values = c("Main" = 3, "North Fork" = 4, "South Fork" = 3)) +
  
   geom_vline(xintercept = 23, linetype = "dashed", color = "black", size = 1, alpha = 0.6) +
  
  scale_x_discrete(
    breaks = north_fork_ticks,
    labels = north_fork_labels,
    expand = expansion(mult = c(0.03, 0.03))
  ) +
  
  scale_y_continuous(
    #breaks = c(0,5,10,15,20,25,30,35,40,45),
    #labels = c(0,"",10,"",20,"",30,"",40,45),
    expand = expansion(mult = c(0.01, 0.03))
  ) +
  
  labs(
    title = NULL,
    x = "Year",
    y = "Mean SO4",
    color = "Subcatchment"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none"
        ,axis.text.y = element_blank()
        )

DOC_aggie

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/DOC_V2 no labels.png",DOC_aggie, width = 4, height = 5, dpi = 300)
```

## Magnesium
```{r}
# SO4 by subcatchment
Mg_aggie <- temporal_df %>%
  filter(variable == "f_Mg_mg_l") %>%
  ggplot(aes(x = year_sub, y = mean, fill = Subcatchment, shape = Subcatchment)) +
  
  geom_smooth(method = "lm", se = FALSE, formula = y ~ x, aes(group = Subcatchment, color = Subcatchment)) +
  
  labs(
    x = "Year",
    y = "Mean Value",
    color = "Subcatchment"
  ) +
  
  geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.2) +
  geom_point(aes(size = Subcatchment), color = "black", stroke = 1.1) +
  
  scale_fill_manual(values = c("Main" = "#71d5f6", "North Fork" = "#f67192", "South Fork" = "#f6d571")) +
  scale_color_manual(values = c("Main" = "#71d5f6", "North Fork" = "#f67192", "South Fork" = "#f6d571")) +
  scale_shape_manual(values = c("Main" = 23, "North Fork" = 21, "South Fork" = 24)) +
  scale_size_manual(values = c("Main" = 3, "North Fork" = 4, "South Fork" = 3)) +
  
   geom_vline(xintercept = 23, linetype = "dashed", color = "black", size = 1, alpha = 0.6) +
  
  scale_x_discrete(
    breaks = north_fork_ticks,
    labels = north_fork_labels,
    expand = expansion(mult = c(0.03, 0.03))
  ) +
  
  scale_y_continuous(
    breaks = c(0,5,10,15,20,25,30,35,40,45),
    labels = c(0,"",10,"",20,"",30,"",40,45),
    expand = expansion(mult = c(0.01, 0.03))
  ) +
  
  labs(
    title = NULL,
    x = "Year",
    y = "Mean SO4",
    color = "Subcatchment"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none"
        #,axis.text.y = element_blank()
        )

Mg_aggie

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Ca_V2 no labels.png",Ca_aggie, width = 4, height = 5, dpi = 300)
```

## SpC
```{r}
SpC_aggie <- temporal_df %>%
  filter(variable == "Spec_Cond_microS_per_cm") %>%
  ggplot(aes(x = year_sub, y = median, color = Subcatchment)) +
   geom_vline(xintercept = 12.5, linetype = "dashed", color = "black", size = 1, alpha = 0.5) +
  #geom_line(size = 1) +
  geom_point(size = 3) +
  #geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.2) +
  geom_errorbar(aes(ymin = Q1, ymax = Q3), width = 0.2) +
  scale_x_discrete(
    breaks = north_fork_ticks,
    labels = north_fork_labels
  ) +
  #scale_x_discrete(labels = x_labels) +
  labs(
    title = "Median SpC by Year and Subcatchment",
    x = "Year",
    y = "Median SpC",
    color = "Subcatchment"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  temporal_theme

SpC_aggie

ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/SO4.png", SO4_aggie, width = 4, height = 5, dpi = 300)
```

## pH
```{r}
# pH by subcatchment
pH_aggie <- temporal_df %>%
  filter(variable == "pH") %>%
  ggplot(aes(x = year_sub, y = mean, fill = Subcatchment, shape = Subcatchment)) +
  
  #geom_smooth(method = "lm", se = FALSE, formula = y ~ x, aes(group = Subcatchment, color = Subcatchment)) +
  
  labs(
    x = "Year",
    y = "Mean Value",
    color = "Subcatchment"
  ) +
  
  geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.2) +
  geom_point(aes(size = Subcatchment), color = "black", stroke = 1.1) +
  
  scale_fill_manual(values = c("Main" = "#71d5f6", "North Fork" = "#f67192", "South Fork" = "#f6d571")) +
  scale_color_manual(values = c("Main" = "#71d5f6", "North Fork" = "#f67192", "South Fork" = "#f6d571")) +
  scale_shape_manual(values = c("Main" = 23, "North Fork" = 21, "South Fork" = 24)) +
  scale_size_manual(values = c("Main" = 3, "North Fork" = 4, "South Fork" = 3)) +
  
   geom_vline(xintercept = 23, linetype = "dashed", color = "black", size = 1, alpha = 0.6) +
  
  scale_x_discrete(
    breaks = north_fork_ticks,
    labels = north_fork_labels,
    expand = expansion(mult = c(0.03, 0.03))
  ) +
  
  scale_y_continuous(
    #breaks = c(0,25,50,75,100,125,150,175,200,225,250,275),
    #labels = c(0,"",50,"",100,"",150,"",200,"",250,""),
    expand = expansion(mult = c(0.01, 0.03))
  ) +
  
  labs(
    title = NULL,
    x = "Year",
    y = "Mean pH",
    color = "Subcatchment"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none"
        ,axis.text.y = element_blank()
        )

pH_aggie

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/pH_V2 no labels.png", pH_aggie, width = 4, height = 5, dpi = 300)
```

```{r}
# pH by season
pH_temporal <- Agashashok_for_plots %>%
ggplot(aes(x = factor(sample_collection_year), y = pH, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.8)) +
  labs(
    title = "Concentration by Year and Season",
    x = "Year",
    y = "Concentration (units)",  # replace with actual units
    fill = "Season"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

pH_temporal
```

## DIC
```{r}
DIC_aggie <- temporal_df %>%
  filter(variable == "DIC_mgC_per_l") %>%
  ggplot(aes(x = year_sub, y = median, color = Subcatchment)) +
  geom_vline(xintercept = 9.5, linetype = "dashed", color = "black", size = 1, alpha = 0.5) +
  #geom_line(size = 1) +
  geom_point(size = 3) +
  #geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.2) +
  geom_errorbar(aes(ymin = Q1, ymax = Q3), width = 0.2) +
  scale_x_discrete(
    breaks = north_fork_ticks,
    labels = north_fork_labels
  ) +
  #scale_x_discrete(labels = x_labels) +
  labs(
    title = "Median DIC by Year and Subcatchment",
    x = "Year",
    y = "Median DIC",
    color = "Subcatchment"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  temporal_theme

DIC_aggie
```


```{r}
DIC_temporal <- Agashashok_for_plots %>%
ggplot(aes(x = factor(sample_collection_year), y = DIC_mgC_per_l, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.8)) +
  labs(
    title = "Concentration by Year and Season",
    x = "Year",
    y = "Concentration (units)",  # replace with actual units
    fill = "Season"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

DIC_temporal
```

## Alk
```{r}
Alk_aggie <- temporal_df %>%
  filter(variable == "Alk_mgCaCO3_per_l") %>%
  ggplot(aes(x = year_sub, y = mean, fill = Subcatchment, shape = Subcatchment)) +
  
  #geom_smooth(method = "lm", se = FALSE, formula = y ~ x, aes(group = Subcatchment, color = Subcatchment)) +
  
  labs(
    x = "Year",
    y = "Mean Value",
    color = "Subcatchment"
  ) +
  
  geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.2) +
  geom_point(aes(size = Subcatchment), color = "black", stroke = 1.1) +
  
  scale_fill_manual(values = c("Main" = "#71d5f6", "North Fork" = "#f67192", "South Fork" = "#f1c029")) +
  scale_color_manual(values = c("Main" = "#71d5f6", "North Fork" = "#f67192", "South Fork" = "#efb911")) +
  scale_shape_manual(values = c("Main" = 23, "North Fork" = 21, "South Fork" = 24)) +
  scale_size_manual(values = c("Main" = 3, "North Fork" = 4, "South Fork" = 3)) +
  
   geom_vline(xintercept = 23, linetype = "dashed", color = "black", size = 1, alpha = 0.6) +
  
  scale_x_discrete(
    breaks = north_fork_ticks,
    labels = north_fork_labels,
    expand = expansion(mult = c(0.03, 0.03))
  ) +
  
  scale_y_continuous(
    breaks = c(0,25,50,75,100,125,150,175,200,225,250,275),
    labels = c(0,"",50,"",100,"",150,"",200,"",250,""),
    expand = expansion(mult = c(0.01, 0.03))
  ) +
  
  labs(
    title = NULL,
    x = "Year",
    y = "Mean Alk",
    color = "Subcatchment"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none",
        #axis.text.y = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA))

Alk_aggie

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/Alk_V7 no regression.png",Alk_aggie, width = 4, height = 5, dpi = 300, bg = "transparent")
```


```{r}
Alk_temporal <- Agashashok_for_plots %>%
ggplot(aes(x = factor(sample_collection_year), y = Alk_mgCaCO3_per_l, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.8)) +
  labs(
    title = "Concentration by Year and Season",
    x = "Year",
    y = "Concentration (units)",  # replace with actual units
    fill = "Season"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

Alk_temporal
```

## Fe
```{r}
Fe_temporal <- temporal_df %>%
  filter(variable == "f_Fe_mcg_per_l") %>%
  ggplot(aes(x = year_sub, y = mean, fill = Subcatchment, shape = Subcatchment)) +
  
  #geom_smooth(method = "lm", se = FALSE, formula = y ~ x, aes(group = Subcatchment, color = Subcatchment)) +
  
  labs(
    x = "Year",
    y = "Mean Value",
    color = "Subcatchment"
  ) +
  
  geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.2) +
  geom_point(aes(size = Subcatchment), color = "black", stroke = 1.1) +
  
  scale_fill_manual(values = c("Main" = "#71d5f6", "North Fork" = "#f67192", "South Fork" = "#f6d571")) +
  scale_color_manual(values = c("Main" = "#71d5f6", "North Fork" = "#f67192", "South Fork" = "#f6d571")) +
  scale_shape_manual(values = c("Main" = 23, "North Fork" = 21, "South Fork" = 24)) +
  scale_size_manual(values = c("Main" = 3, "North Fork" = 4, "South Fork" = 3)) +
  
   geom_vline(xintercept = 23, linetype = "dashed", color = "black", size = 1, alpha = 0.6) +
  
  scale_x_discrete(
    breaks = north_fork_ticks,
    labels = north_fork_labels,
    expand = expansion(mult = c(0.03, 0.03))
  ) +
  
  scale_y_continuous(
    #breaks = c(0,25,50,75,100,125,150,175,200,225,250,275),
    #labels = c(0,"",50,"",100,"",150,"",200,"",250,""),
    expand = expansion(mult = c(0.01, 0.03))
  ) +
  
  labs(
    title = NULL,
    x = "Year",
    y = "Mean pH",
    color = "Subcatchment"
  ) +
  theme_minimal() +
  temporal_theme +
  theme(legend.position = "none"
        #,axis.text.y = element_blank()
        )

Fe_temporal

#ggsave("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Figures/04_Agashashok Temporal Analysis/pH_V2 no labels.png", Fe_temporal, width = 4, height = 5, dpi = 300)


```

## Ni
```{r}
Cd_temporal <- Agashashok_for_plots %>%
ggplot(aes(x = factor(sample_collection_year), y = f_Cd_mcg_per_l, fill = sample_collection_season)) +
  geom_boxplot(position = position_dodge(width = 0.8)) +
  labs(
    title = "Concentration by Year and Season",
    x = "Year",
    y = "Concentration (units)",  # replace with actual units
    fill = "Season"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

Cd_temporal
```


# stats
```{r}
library(dplyr)
library(purrr)
library(broom)
library(rstatix)

# List of columns to analyze
columns_to_model <- c("pH", "Spec_Cond_microS_per_cm", 
  "DIC_mgC_per_l", "Alk_mgCaCO3_per_l", "DOC_mgC_per_l", "f_Cl_mg_per_l", "f_NO3_mgN_per_l", 
  "f_SO4_mg_per_l", "f_Ca_mg_l", "f_Mg_mg_l", "f_Na_mg_l", "f_K_mg_l",
  "f_SiO2_mg_per_l",
  "f_Al_mcg_per_l",
  "f_As_mcg_per_l",
  "f_Ba_mcg_per_l",
  "f_Cd_mcg_per_l",
  "f_Ce_mcg_per_l",
  "f_Co_mcg_per_l",
  "f_Cr_mcg_per_l",
  "f_Cu_mcg_per_l",
  "f_Dy_mcg_per_l",
  "f_Fe_mcg_per_l",
  "f_La_mcg_per_l",
  "f_Mn_mcg_per_l",
  "f_Nd_mcg_per_l",
  "f_Ni_mcg_per_l",
  "f_Pb_mcg_per_l", 
  "f_Pr_mcg_per_l",
  "f_Se_mcg_per_l",
  "f_Tl_mcg_per_l",
  "f_U_mcg_per_l",
  "f_Y_mcg_per_l",
  "f_Zn_mcg_per_l")


pdf("Aggie_temporal_residuals_plots.pdf")  # Start a new PDF file

# Initialize a results list
model_results <- list()

# Loop through each variable
for (col in columns_to_model) {

  # Get the relevant subset
  df_sub <- onset_df %>%
    dplyr::select(sub_temp, all_of(col)) %>%
    filter(!is.na(.data[[col]]), !is.na(sub_temp))

  # Check if temporal_status and the variable both have enough data
  if (n_distinct(df_sub$sub_temp) < 2 || nrow(df_sub) < 3) {
    model_results[[col]] <- data.frame(
      Variable = col,
      W = NA,
      p_value = NA,
      Interpretation = "Insufficient data or sub_temp lacks ≥2 levels"
    )
    next
  }

  # Fit the model
  model <- lm(df_sub[[col]] ~ df_sub$sub_temp)

  # Extract residuals
  residuals <- resid(model)

  # Plot histogram
  hist(residuals, main = paste("Residuals Histogram:", col), xlab = "Residuals")

  # QQ plot
  qqnorm(residuals, main = paste("QQ Plot of Residuals:", col))
  qqline(residuals)

  # Shapiro-Wilk test
  test_result <- tryCatch(
    shapiro.test(residuals),
    error = function(e) NULL
  )

  interpretation <- if (!is.null(test_result) && test_result$p.value > 0.05) {
    "Residuals likely normally distributed (fail to reject H0)."
  } else if (!is.null(test_result)) {
    "Residuals not normally distributed (reject H0); consider non-parametric test."
  } else {
    "Shapiro test failed or insufficient data."
  }

  # Save results
  model_results[[col]] <- data.frame(
    Variable = col,
    W = if (!is.null(test_result)) test_result$statistic else NA,
    p_value = if (!is.null(test_result)) test_result$p.value else NA,
    Interpretation = interpretation
  )
}

dev.off()  # Close the PDF device

# Combine all results into a single data frame
shapiro_results <- bind_rows(model_results)

# Print results
view(shapiro_results)

#write_xlsx(shapiro_results, "C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Alaska BITE_HEAT (Taylor Evinger)/Evinger Manuscripts/Ferrum Manuscript/Results and Discussion/Aggie temporal - pre vs post dataset shapiro.xlsx")
```



```{r}
# List of columns to analyze - variables removed from the list because shapiro showed normality
nonparametric_columns <- c("pH", "Spec_Cond_microS_per_cm", 
  "DIC_mgC_per_l", 
  #"Alk_mgCaCO3_per_l", 
  "DOC_mgC_per_l", "f_Cl_mg_per_l", "f_NO3_mgN_per_l", 
  "f_SO4_mg_per_l", 
  #"f_Ca_mg_l", 
  #"f_Mg_mg_l", 
  "f_Na_mg_l", "f_K_mg_l")

# set the data to be used as stats_data
stats_data <- Aggie_Main_onset_df
#stats_data <- Aggie_SF_onset_df
#stats_data <- Aggie_NF_onset_df

# Initialize a results list
kruskal_results_list <- list()

# Loop through each variable in your list
for (col in nonparametric_columns) {
  
  # Filter out NAs for the current variable
  df_filtered <- onset_df %>%
    filter(!is.na(.data[[col]]))
  
  # Perform Kruskal-Wallis test
  test_result <- tryCatch(
    {
      kruskal_test(as.formula(paste(col, "~ sub_temp")), data = df_filtered)
    },
    error = function(e) {
      # Return a default result if test fails
      data.frame(
        variable = col,
        statistic = NA,
        p = NA,
        df = NA
      )
    }
  )
  
  # Create interpretation
  interpretation <- if (!is.null(test_result$p) && test_result$p < 0.05) {
    "Significant difference among groups (reject H0)."
  } else if (!is.null(merged_result$p)) {
    "No significant difference among groups (fail to reject H0)."
  } else {
    "Test could not be performed due to insufficient data or errors."
  }
  
  test_result$Interpretation <- interpretation
  
  # Store the result
  kruskal_results_list[[col]] <- test_result
}

# Combine all results into a single dataframe
kruskal_results_df <- bind_rows(kruskal_results_list)

# Print the results
view(kruskal_results_df)
```


```{r}

columns_for_dunn <- c(
  #"pH", 
  "Spec_Cond_microS_per_cm", 
  "DIC_mgC_per_l", 
  "DOC_mgC_per_l", 
  "f_Cl_mg_per_l", 
  #"f_NO3_mgN_per_l", 
  "f_SO4_mg_per_l", 
  "f_Na_mg_l", 
  "f_K_mg_l")


# Initialize a results list
dunn_results_list <- list()

# Loop through each variable in columns_for_dunn
for (col in columns_for_dunn) {
  
  # Filter out NAs for the current variable
  df_filtered <- onset_df %>%
    filter(!is.na(.data[[col]]))
  
  # Try performing Dunn's test with Bonferroni adjustment
  test_result <- tryCatch(
    {
      df_filtered %>%
        dunn_test(as.formula(paste(col, "~ sub_temp")), p.adjust.method = "bonferroni")
    },
    error = function(e) {
      # Return a default result if test fails
      data.frame(
        Variable = col,
        group1 = NA,
        group2 = NA,
        Z = NA,
        p = NA,
        p.adj = NA
      )
    }
  )
  
  # Add the variable name to each row
  test_result$Variable <- col
  
  # Store the result
  dunn_results_list[[col]] <- test_result
  
  # If there is at least one valid pairwise comparison, generate the CLD
  if (!all(is.na(test_result$p.adj))) {
     # Build a matrix of p-values manually
    groups <- unique(c(test_result$group1, test_result$group2))
    pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                          dimnames = list(groups, groups))
    
    for (i in seq_len(nrow(test_result))) {
      g1 <- as.character(test_result$group1[i])
      g2 <- as.character(test_result$group2[i])
      pval <- test_result$p.adj[i]
      
      pval_matrix[g1, g2] <- pval
      pval_matrix[g2, g1] <- pval  # symmetric
    }
    
    # Generate CLD using multcompView
    cld <- multcompLetters(pval_matrix)
    
    # Convert to a tidy data frame
    cld_df <- data.frame(
      Variable = col,
      Group = names(cld$Letters),
      Letters = cld$Letters
    )
    
    # Store the CLD result
    cld_results_list[[col]] <- cld_df
  }
}

# Combine all Dunn's test results into a single dataframe
dunn_results_df <- bind_rows(dunn_results_list)

# Combine all CLD results into a single dataframe
cld_results_df <- bind_rows(cld_results_list)

# Print the results
view(dunn_results_df)
view(cld_results_df)
```