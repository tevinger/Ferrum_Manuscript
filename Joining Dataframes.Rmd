---
title: "Joining Dataframes"
output: html_document
date: "2025-02-03"
---
# Load Data
# Use this if starting from Ferrum_Manuscript_Data 
```{r}
working_Alaska_DataRelease_2022_2023_Ferrum <- read_excel("C:/Users/tayta/OneDrive/Desktop/Lab/Alaska Projects/Master Spreadsheet/working_Alaska_DataRelease_2022_2023_Ferrum.xlsx",
                                                          sheet = "Sheet1")
```

# Use this if need to start from the master spreadsheet
## Load master spreadsheet

```{r}
Alaska_2024_DataRelease_V2.4 <- read_excel("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Becca Frei/Alaska_ProjectData/Alaska_2024_DataRelease_V2.4_20250528_for Brett to review.xlsx", 
                                           sheet = "Table3_Water")

Alaska_Project_Master_Spreadsheet <- Alaska_2024_DataRelease_V2.4
view(Alaska_Project_Master_Spreadsheet)
```

### Keep only 2022 and 2023 Ferrum project data

```{r}
# Select 2022 and 2023 data into a new sheet in the master spreadsheet to import
Alaska_DataRelease_2022_2023_Ferrum_OG <- Alaska_Project_Master_Spreadsheet %>%
  filter(year(sample_collection_date_mm_dd_yy) %in% c(2022, 2023)) %>% # Filter for 2022 & 2023
  filter(`Project Name` == "Alaska FERRUM" | `Project Name` == "Hydro-Ecology of Arctic Thaw")  # Select only Ferrum Project data

view(Alaska_DataRelease_2022_2023_Ferrum_OG)

# Save the file to modify manually
write_xlsx(Alaska_DataRelease_2022_2023_Ferrum_OG, "C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Alaska_DataRelease_2022_2023_Ferrum_to_modify.xlsx")  # Saves a new Excel file

# In the exported Alaska_DataRelease_2022_2023_Ferrum file, I moved the four rows of data from the CCAL Cl, SO4, Na, K, Ca, and Mg to Poulin Lab Cl, SO4, Na, K, Ca, and Mg, added field measurements for the 2022 samples I have them for, deleted columns 265-274 and 277 (UC Davis Becca cation measurements), and deleted UC Davis Poulin Lab f_SiO2 columns, and the CCAL Cl, SO4, Na, K, Ca, and Mg columns)

# Bring the spreadsheet back in after those changes to use for the DL correction
Alaska_DataRelease_2022_2023_Ferrum <- read_excel("C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Alaska_DataRelease_2022_2023_Ferrum_to_modify.xlsx")
```


### remove "<" character
``` {r}
# Replace all "<" characters with "" across all columns
Alaska_DataRelease_2022_2023_Ferrum_modified <- Alaska_DataRelease_2022_2023_Ferrum %>%
  mutate(across(everything(), ~ str_replace_all(.x, "<", "")))

view(Alaska_DataRelease_2022_2023_Ferrum_modified)
```

## Convert Columns to Numeric
``` {r}
# Define the vector of column indices to convert
columns_to_convert <- c(27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 88, 100, 102, 104, 106, 108, 110, 112, 117, 119, 121, 123, 125, 127, 129, 131, 133, 135, 137, 139, 141, 143, 145, 147, 149, 151, 153, 155, 157, 159, 161, 163, 165, 167, 169, 171, 173, 175, 177, 179, 181, 183, 185, 187, 189, 191, 193, 195, 197, 199, 201, 203, 205, 207, 209, 211, 213, 215, 217, 219, 221, 223, 225, 227, 229, 231, 233, 235, 237, 239, 241, 243, 245, 247, 249)

Alaska_DataRelease_2022_2023_Ferrum_modified <- Alaska_DataRelease_2022_2023_Ferrum_modified %>%
  mutate(across(all_of(columns_to_convert), as.numeric))  # Convert specified columns to numeric

str(Alaska_DataRelease_2022_2023_Ferrum_modified)
```

## Change duplicate column names
```{r}
colnames(Alaska_DataRelease_2022_2023_Ferrum_modified)[40] <- "CCAL_f_NO3_mgN_per_l" 
colnames(Alaska_DataRelease_2022_2023_Ferrum_modified)[145] <- "f_NO3_mgN_per_l"

colnames(Alaska_DataRelease_2022_2023_Ferrum_modified)[41] <- "CCAL_f_NO3_mgN_per_l_qa" 
colnames(Alaska_DataRelease_2022_2023_Ferrum_modified)[146] <- "f_NO3_mgN_per_l_qa"

Alaska_DataRelease_2022_2023_Ferrum_V1 <- Alaska_DataRelease_2022_2023_Ferrum_modified

# Save the modified file as the version prior to calculations
write_xlsx(Alaska_DataRelease_2022_2023_Ferrum_modified, "C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Alaska_DataRelease_2022_2023_Ferrum_V1.xlsx")  # Saves a new Excel file
```

## <DL Transformation
####percent of data that is <DL
```{r}
# Calculate the percentage of data that is below DL for each variable
columns_to_check <- c(
  "Alk_mgCaCO3_per_l_qa",
  "f_NH3_mgN_per_l_qa",
  "f_PO4_mgP_per_l_qa",
  "TDP_mgP_per_l_qa",
  "UTP_mgP_per_l_qa",
  "f_Cl_mg_per_l_qa",
  "f_NO3_mgN_per_l_qa",
  "f_SO4_mg_per_l_qa",
  "f_K_mg_l_qa",
  "f_Na_mg_l_qa",
  "f_Ca_mg_l_qa",
  "f_Mg_mg_l_qa",
  "f_SiO2_mg_per_l_qa",
  "f_Al_mcg_per_l_qa", "f_V_mcg_per_l_qa", 
  "f_Cr_mcg_per_l_qa", "f_Mn_mcg_per_l_qa", 
  "f_Fe_mcg_per_l_qa", "f_Co_mcg_per_l_qa", 
  "f_Ni_mcg_per_l_qa", "f_Cu_mcg_per_l_qa", 
  "f_Zn_mcg_per_l_qa", "f_As_mcg_per_l_qa", 
  "f_Se_mcg_per_l_qa", "f_Y_mcg_per_l_qa", 
  "f_Ag_mcg_per_l_qa", "f_Cd_mcg_per_l_qa", 
  "f_Ba_mcg_per_l_qa", "f_La_mcg_per_l_qa", 
  "f_Ce_mcg_per_l_qa", "f_Pr_mcg_per_l_qa", 
  "f_Nd_mcg_per_l_qa", "f_Dy_mcg_per_l_qa", 
  "f_Tl_mcg_per_l_qa", "f_U_mcg_per_l_qa",
  "f_Pb_mcg_per_l_qa", "u_SiO2_mcg_per_l_qa", 
  "u_Al_mcg_per_l_qa", "u_V_mcg_per_l_qa", 
  "u_Cr_mcg_per_l_qa", "u_Mn_mcg_per_l_qa", 
  "u_Fe_mcg_per_l_qa", "u_Co_mcg_per_l_qa", 
  "u_Ni_mcg_per_l_qa", "u_Cu_mcg_per_l_qa", 
  "u_Zn_mcg_per_l_qa", "u_As_mcg_per_l_qa", 
  "u_Se_mcg_per_l_qa", "u_Y_mcg_per_l_qa", 
  "u_Ag_mcg_per_l_qa", "u_Cd_mcg_per_l_qa", 
  "u_Ba_mcg_per_l_qa", "u_La_mcg_per_l_qa", 
  "u_Ce_mcg_per_l_qa", "u_Pr_mcg_per_l_qa", 
  "u_Nd_mcg_per_l_qa", "u_Dy_mcg_per_l_qa", 
  "u_Tl_mcg_per_l_qa", "u_U_mcg_per_l_qa", 
  "u_Pb_mcg_per_l_qa"
)

# count the number of cells in each qa column that is <DL to calculate the percent of total data
DL_counts <- sapply(columns_to_check, function(col) {
  sum(grepl("DL", Alaska_DataRelease_2022_2023_Ferrum_modified[[col]], ignore.case = TRUE), na.rm = TRUE)
})

print(DL_counts)

#Convert to dataframe
DL_counts_df <- data.frame(Column = names(DL_counts), DL_Count = DL_counts)

# Add percent_DL column
DL_counts_df$percent_DL <- (DL_counts_df$DL_Count / 135) * 100

view(DL_counts_df)

# f_V and f_Ag had high censoring but these metals aren't going to be used in any analysis anyways

# Save the percentage data frame
write_xlsx(DL_counts_df, "C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/percent of data below DL.xlsx")
```


####<DL values as sqrt(2)/2 of DL

```{r}
library(dplyr)

# Define your measurement columns and their corresponding QA columns
measure_cols <- c(
  "Alk_mgCaCO3_per_l",
  "f_NH3_mgN_per_l",
  "f_PO4_mgP_per_l",
  "TDP_mgP_per_l",
  "UTP_mgP_per_l",
  #"f_Cl_mg_per_l",
  "f_NO3_mgN_per_l",
  "f_SO4_mg_per_l",
  "f_K_mg_l",
  "f_Na_mg_l",
  "f_Al_mcg_per_l", 
  #"f_V_mcg_per_l", 
  "f_Cr_mcg_per_l", "f_Mn_mcg_per_l", 
  "f_Fe_mcg_per_l", "f_Co_mcg_per_l", 
  "f_Ni_mcg_per_l", "f_Cu_mcg_per_l", 
  "f_Zn_mcg_per_l", "f_As_mcg_per_l", 
  "f_Se_mcg_per_l", "f_Y_mcg_per_l", 
  #"f_Ag_mcg_per_l",
  "f_Cd_mcg_per_l", 
  "f_Ba_mcg_per_l", "f_La_mcg_per_l", 
  "f_Ce_mcg_per_l", "f_Pr_mcg_per_l", 
  "f_Nd_mcg_per_l", "f_Dy_mcg_per_l", 
  "f_Tl_mcg_per_l", "f_U_mcg_per_l",
  "f_Pb_mcg_per_l", "u_SiO2_mcg_per_l", 
  "u_Al_mcg_per_l", 
  #"u_V_mcg_per_l", 
  "u_Cr_mcg_per_l", "u_Mn_mcg_per_l", 
  "u_Fe_mcg_per_l", "u_Co_mcg_per_l", 
  "u_Ni_mcg_per_l", "u_Cu_mcg_per_l", 
  "u_Zn_mcg_per_l", "u_As_mcg_per_l", 
  "u_Se_mcg_per_l", "u_Y_mcg_per_l", 
  #"u_Ag_mcg_per_l", 
  "u_Cd_mcg_per_l", 
  "u_Ba_mcg_per_l", "u_La_mcg_per_l", 
  "u_Ce_mcg_per_l", "u_Pr_mcg_per_l", 
  "u_Nd_mcg_per_l", "u_Dy_mcg_per_l", 
  "u_Tl_mcg_per_l", "u_U_mcg_per_l", 
  "u_Pb_mcg_per_l" 
)

# Create the transformed dataframe
Alaska_DataRelease_2022_2023_Ferrum_DL_transformation <- Alaska_DataRelease_2022_2023_Ferrum

# Loop through each column and apply the DL transformation if QA column contains "DL"
for (col in measure_cols) {
  qa_col <- paste0(col, "_qa")
  
  Alaska_DataRelease_2022_2023_Ferrum_DL_transformation[[col]] <- ifelse(
    grepl("DL", Alaska_DataRelease_2022_2023_Ferrum[[qa_col]]),
    (sqrt(2) / 2) * Alaska_DataRelease_2022_2023_Ferrum[[col]],
    Alaska_DataRelease_2022_2023_Ferrum[[col]]
  )
}

# round final values
Alaska_DataRelease_2022_2023_Ferrum_DL_transformation <- Alaska_DataRelease_2022_2023_Ferrum_DL_transformation %>%
    mutate(across(c(f_PO4_mgP_per_l, TDP_mgP_per_l, UTP_mgP_per_l, f_NH3_mgN_per_l, f_Al_mcg_per_l, f_V_mcg_per_l, 
f_Cr_mcg_per_l, f_Mn_mcg_per_l, 
f_Fe_mcg_per_l, f_Co_mcg_per_l, 
f_Ni_mcg_per_l, f_Cu_mcg_per_l, 
f_Zn_mcg_per_l, f_As_mcg_per_l, 
f_Se_mcg_per_l, f_Y_mcg_per_l, 
f_Ag_mcg_per_l, f_Cd_mcg_per_l, 
f_Ba_mcg_per_l, f_La_mcg_per_l, 
f_Ce_mcg_per_l, f_Pr_mcg_per_l, 
f_Nd_mcg_per_l, f_Dy_mcg_per_l, 
f_Tl_mcg_per_l, f_U_mcg_per_l,
f_Pb_mcg_per_l, u_SiO2_mcg_per_l, 
u_Al_mcg_per_l, u_V_mcg_per_l, 
u_Cr_mcg_per_l, u_Mn_mcg_per_l, 
u_Fe_mcg_per_l, u_Co_mcg_per_l, 
u_Ni_mcg_per_l, u_Cu_mcg_per_l, 
u_Zn_mcg_per_l, u_As_mcg_per_l, 
u_Se_mcg_per_l, u_Y_mcg_per_l, 
u_Ag_mcg_per_l, u_Cd_mcg_per_l, 
u_Ba_mcg_per_l, u_La_mcg_per_l, 
u_Ce_mcg_per_l, u_Pr_mcg_per_l, 
u_Nd_mcg_per_l, u_Dy_mcg_per_l, 
u_Tl_mcg_per_l, u_U_mcg_per_l, 
u_Pb_mcg_per_l
), round, 3)
           ) %>%
  mutate(across(c(f_K_mg_l, f_Na_mg_l, f_Ca_mg_l, f_Mg_mg_l, Alk_mgCaCO3_per_l, f_Cl_mg_per_l, f_NO3_mgN_per_l, f_SO4_mg_per_l), round, 2))
  

view(Alaska_DataRelease_2022_2023_Ferrum_DL_transformation)
view(Alaska_DataRelease_2022_2023_Ferrum)

# Save the modified file to check
write_xlsx(Alaska_DataRelease_2022_2023_Ferrum_DL_transformation, "C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Alaska_DataRelease_2022_2023_Ferrum_DL corrected.xlsx")  # Saves a new Excel file

```

```{r}
#This is the non loop version of the DL correction calculation that I started with

Alaska_DataRelease_2022_2023_Ferrum_DL_transformation <- Alaska_DataRelease_2022_2023_Ferrum %>%
 mutate(
    Alk_mgCaCO3_per_l = ifelse(grepl("DL", Alk_mgCaCO3_per_l_qa), (sqrt(2)/2) * Alk_mgCaCO3_per_l, Alk_mgCaCO3_per_l),
    f_NH3_mgN_per_l = ifelse(grepl("DL", f_NH3_mgN_per_l_qa), (sqrt(2)/2) * f_NH3_mgN_per_l, f_NH3_mgN_per_l),
    f_PO4_mgP_per_l = ifelse(grepl("DL", f_PO4_mgP_per_l_qa), (sqrt(2)/2) * f_PO4_mgP_per_l, f_PO4_mgP_per_l),
    TDP_mgP_per_l = ifelse(grepl("DL", TDP_mgP_per_l_qa), (sqrt(2)/2) * TDP_mgP_per_l, TDP_mgP_per_l),
    UTP_mgP_per_l = ifelse(grepl("DL", UTP_mgP_per_l_qa), (sqrt(2)/2) * UTP_mgP_per_l, UTP_mgP_per_l),
    f_Cl_mg_per_l = ifelse(grepl("DL", f_Cl_mg_per_l_qa), (sqrt(2)/2) * f_Cl_mg_per_l, f_Cl_mg_per_l),
    f_NO3_mg_per_l = ifelse(grepl("DL", f_NO3_mgN_per_l_qa), (sqrt(2)/2) * f_NO3_mgN_per_l, f_NO3_mgN_per_l),
    f_SO4_mg_per_l = ifelse(grepl("DL", f_SO4_mg_per_l_qa), (sqrt(2)/2) * f_SO4_mg_per_l, f_SO4_mg_per_l),
    f_K_mg_l = ifelse(grepl("DL", f_K_mg_l_qa), (sqrt(2)/2) * f_K_mg_l, f_K_mg_l),
    f_Na_mg_l = ifelse(grepl("DL", f_Na_mg_l_qa), (sqrt(2)/2) * f_Na_mg_l, f_Na_mg_l)
  ) %>%
  mutate(across(
    c(f_K_mg_l, f_Na_mg_l), 
    round, 3  # Round all final values to 2 decimal places
  )) %>%
    mutate(across(c(f_PO4_mgP_per_l, TDP_mgP_per_l, UTP_mgP_per_l, f_NH3_mgN_per_l), round, 4)
           ) %>%
  mutate(across(c(Alk_mgCaCO3_per_l, f_Cl_mg_per_l, f_NO3_mgN_per_l, f_SO4_mg_per_l), round, 2))
  
Alaska_DataRelease_2022_2023_Ferrum_DL_transformation <- Alaska_DataRelease_2022_2023_Ferrum_DL_transformation %>%
  mutate(across(c(f_PO4_mgP_per_l, TDP_mgP_per_l, UTP_mgP_per_l), round, 4))
  
  # Code explanation
  
  #mutate(f_Cl_mg_per_l_adjusted = ifelse(
    #grepl("DL", f_Cl_mg_per_l_qa),  # Check if "DL" is present in f_Cl_mg_per_l_qa
    #(sqrt(2)/2) * f_Cl_mg_per_l,    # If TRUE, apply transformation
    #f_Cl_mg_per_l))                   # If FALSE, keep original value
  

#head(Alaska_DataRelease_2022_2023_Ferrum_DL_transformation)

#Check_df <- Alaska_DataRelease_2022_2023_Ferrum_DL_transformation %>%
  #dplyr::select(SamplingEventID, f_Cl_mg_per_l, f_Cl_mg_per_l_adjusted, f_Cl_mg_per_l_qa)

# Save the transformed file as the working dataframe 
# this Working dataframe has values that were below DL replaced with the sqrt2/2 of the DL
write_xlsx(Alaska_DataRelease_2022_2023_Ferrum_DL_transformation, "Alaska_DataRelease_2022_2023_Ferrum_DL_transformation.xlsx")
```

### Bring in the visual description and site classification information

```{r}
# Load data to join
# This file has the VisualDescription, site_classification, Hyd_site_classification, Hyd_Classification, and Site_Grouping columns used for some analyses
Site_info_to_bring_in <- read_excel("C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Master Spreadsheet/Site_info_to_bring_in.xlsx")

# distances downstream and elevation data
site_metrics <- read_excel("C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Master Spreadsheet/site_elevation_and_distances_V2.xlsx", sheet = "USE")

# make everything in this df numeric
site_metrics$Distance_km <- as.numeric(site_metrics$Distance_km)
site_metrics$Elevation_ft <- as.numeric(site_metrics$Elevation_ft)
site_metrics$Watershed_Area <- as.numeric(site_metrics$Watershed_Area)
site_metrics$Relative_MS_Watershed_Area <- as.numeric(site_metrics$Relative_MS_Watershed_Area)

# Make sure SamplingEventID is character in all dataframes
Alaska_DataRelease_2022_2023_Ferrum_DL_transformation <- Alaska_DataRelease_2022_2023_Ferrum_DL_transformation %>%
  mutate(SamplingEventID = as.character(SamplingEventID))

Site_info_to_bring_in <- Site_info_to_bring_in %>%
  mutate(SamplingEventID = as.character(SamplingEventID))

site_metrics <- site_metrics %>%
  mutate(SamplingEventID = as.character(SamplingEventID))

#join dataframes
working_Alaska_DataRelease_2022_2023_Ferrum_joined <- Alaska_DataRelease_2022_2023_Ferrum_DL_transformation %>% 
  left_join(Site_info_to_bring_in, by = "SamplingEventID") %>%
  left_join(site_metrics, by = "SamplingEventID") %>%
  relocate(Prox_Groups, RelAcc_Groups, New_Groups, Distance_km, Elevation_ft, VisualDescription,
                Site_Classification,
                Hyd_Classification, .after = SamplingEventID)

view(working_Alaska_DataRelease_2022_2023_Ferrum_joined)

# Remove sample from the kotzebue water quality lake
working_Alaska_DataRelease_2022_2023_Ferrum_joined <- working_Alaska_DataRelease_2022_2023_Ferrum_joined %>%
  filter(!grepl("kotzebue", SamplingEventID, ignore.case = TRUE))

# Save as an excel file
write_xlsx(working_Alaska_DataRelease_2022_2023_Ferrum_joined, "C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/joined_Alaska_DataRelease_2022_2023_Ferrum_with site information.xlsx")
```

# Particulate Metal Calculation
```{r}
# convert to long format with 
metal_df_long <- working_Alaska_DataRelease_2022_2023_Ferrum_joined %>%
  dplyr::select(
    c(21, 179:271)  # Select columns by position
  ) %>%
  dplyr::select(
    -contains("qa")  # Remove any column that contains "qa"
  ) %>%

  # Step 2: Pivot to long format
  pivot_longer(
    cols = -SamplingEventID,
    names_to = c("prefix", "metal", "unit"),
    names_pattern = "(f|u)_([^_]+)_(mcg_per_l)",
    values_to = "value"
  ) %>%
  
  # Step 3: Pivot wider to get f and u in separate columns
  pivot_wider(
    names_from = prefix,
    values_from = value
  ) %>%
  
  # Step 4: Calculate p_metal = u - f
  mutate(
  p = if_else(
    is.na(f) | is.na(u),
    NA_real_,
    if_else(u - f < 0, 0, u - f)
  )
)

view(metal_df_long)

```

```{r}
# Convert back to wide format with the particulate metal data
metal_df_wide <- metal_df_long %>%
  pivot_longer(
    cols = c(f, u, p),
    names_to = "prefix",
    values_to = "value"
  ) %>%
  mutate(full_name = paste0(prefix, "_", metal, "_", unit)) %>%
  dplyr::select(SamplingEventID, full_name, value) %>%
  pivot_wider(
    names_from = full_name,
    values_from = value
  )

view(metal_df_wide)
```

```{r}
metal_data_swap <- Alaska_DataRelease_2022_2023_Ferrum_DL_transformation %>%
  dplyr::select(-c(171:264))

final_working_Ferrum_Manuscript_df <- metal_data_swap %>%
  left_join(metal_df_wide, by = "SamplingEventID") %>%
  left_join(Site_info_to_bring_in, by = "SamplingEventID") %>%
  left_join(site_elevation_and_distances, by = "SamplingEventID")

final_working_Ferrum_Manuscript_df <- final_working_Ferrum_Manuscript_df %>%
  mutate(    
    New_Grouping = case_when(
    New_Groups == 1 ~ "Upstream",
    New_Groups == 2 ~ "Seep",
    New_Groups == 3 ~ "Impaired Tributary",
    New_Groups == 4 ~ "Unimpaired Tributary",
    New_Groups == 6 ~ "Downstream MS",
    TRUE ~ NA_character_
  ))

view(final_working_Ferrum_Manuscript_df)

# Save as an excel file
write_xlsx(final_working_Ferrum_Manuscript_df, "C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Final Ferrum Manuscript Data Sheet.xlsx")
```

# Join 2022 Salmon River sample data
```{r}
#load data
Salmon_R_2022_SEID <- read_excel("C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Master Spreadsheet/Salmon River 2022_SEID.xlsx")

UAM_metal_data_DL <- read_excel("C:/Users/tevinger/Downloads/20220407 UAM data wide_20250522_DL corrected.xlsx")

SalmonR_2022_df <- Salmon_R_2022_SEID %>%
  left_join(UAM_metal_data_DL, by = "container_id") %>%
  left_join(Site_info_to_bring_in, by = "SamplingEventID") %>%
  left_join(site_elevation_and_distances, by = "SamplingEventID") %>%
  dplyr::select(-matches("206Pb|207Pb|208Pb"))

view(SalmonR_2022_df)

SalmonR_2022_df <- SalmonR_2022_df %>%
  mutate(u_Se_mcg_per_l = as.numeric(u_Se_mcg_per_l))

final_working_Ferrum_Manuscript_df_2 <- final_working_Ferrum_Manuscript_df %>%
  bind_rows(SalmonR_2022_df)

view(final_working_Ferrum_Manuscript_df_2)

# Save as an excel file
write_xlsx(final_working_Ferrum_Manuscript_df_2, "C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Final Ferrum Manuscript Data Sheet_V2.xlsx")

```
