---
title: "Joining Dataframes"
output: html_document
date: "2025-02-03"
---
# Load Data
# Use this if starting from Ferrum_Manuscript_Data 
```{r}
working_Alaska_DataRelease_2022_2023_Ferrum <- read_excel("C:/Users/tayta/OneDrive/Desktop/Lab/Alaska Projects/Master Spreadsheet/working_Alaska_DataRelease_2022_2023_Ferrum.xlsx",
                                                          sheet = "Sheet1")
```

# Use this if need to start from the master spreadsheet
## Load master spreadsheet

```{r}
Alaska_2024_DataRelease_V2.4 <- read_excel("C:/Users/tevinger/Box/Poulin Lab ETOX/Project Folders/Becca Frei/Alaska_ProjectData/Alaska_2024_DataRelease_V2.4_20250528_for Brett to review.xlsx", 
                                           sheet = "Table3_Water")

Alaska_Project_Master_Spreadsheet <- Alaska_2024_DataRelease_V2.4
view(Alaska_Project_Master_Spreadsheet)
```

### Keep only 2022 and 2023 Ferrum project data

```{r}
# Select 2022 and 2023 data into a new sheet in the master spreadsheet to import
Alaska_DataRelease_2022_2023_Ferrum_OG <- Alaska_Project_Master_Spreadsheet %>%
  filter(year(sample_collection_date_mm_dd_yy) %in% c(2022, 2023)) %>% # Filter for 2022 & 2023
  filter(`Project Name` == "Alaska FERRUM" | `Project Name` == "Hydro-Ecology of Arctic Thaw")  # Select only Ferrum Project data

view(Alaska_DataRelease_2022_2023_Ferrum_OG)

# Save the file to modify manually
write_xlsx(Alaska_DataRelease_2022_2023_Ferrum_OG, "C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Alaska_DataRelease_2022_2023_Ferrum_to_modify.xlsx")  # Saves a new Excel file

# Modifications made to Alaska_DataRelease_2022_2023_Ferrum_to_modify 
#I moved the four rows of data from the CCAL Cl, SO4, Na, K, Ca, and Mg to Poulin Lab Cl, SO4, Na, K, Ca, and Mg and deleted those CCAL columns 
#added field measurements for the 2022 samples I have them for 
#deleted columns 265-274 and 277 (UC Davis Becca cation measurements)

# Bring the spreadsheet back in after those changes to use for the DL correction
Alaska_DataRelease_2022_2023_Ferrum <- read_excel("C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Alaska_DataRelease_2022_2023_Ferrum_to_modify.xlsx")
```


### remove "<" character
``` {r}
# Replace all "<" characters with "" across all columns
Alaska_DataRelease_2022_2023_Ferrum_modified <- Alaska_DataRelease_2022_2023_Ferrum %>%
  mutate(across(everything(), ~ str_replace_all(.x, "<", "")))

view(Alaska_DataRelease_2022_2023_Ferrum_modified)
```

## Convert Columns to Numeric
``` {r}
# Define the vector of column indices to convert
columns_to_convert <- c(27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 75, 87, 89, 91, 93, 95, 97, 99, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 142, 144, 146, 148, 150, 152, 154, 156, 158, 160, 162, 164, 166, 168, 170, 172, 174, 176, 178, 180, 182, 184, 186, 188, 190, 192, 194, 196, 198, 200, 202, 204, 206, 208, 210, 212, 214, 216, 218, 220, 222, 224, 226, 228, 230, 232, 234, 236)

Alaska_DataRelease_2022_2023_Ferrum_modified <- Alaska_DataRelease_2022_2023_Ferrum_modified %>%
  mutate(across(all_of(columns_to_convert), as.numeric))  # Convert specified columns to numeric

str(Alaska_DataRelease_2022_2023_Ferrum_modified)
```

## Change duplicate column names
```{r}
colnames(Alaska_DataRelease_2022_2023_Ferrum_modified)[57] <- "CCAL_f_NO3_mgN_per_l" 
colnames(Alaska_DataRelease_2022_2023_Ferrum_modified)[120] <- "f_NO3_mgN_per_l"

colnames(Alaska_DataRelease_2022_2023_Ferrum_modified)[58] <- "CCAL_f_NO3_mgN_per_l_qa" 
colnames(Alaska_DataRelease_2022_2023_Ferrum_modified)[121] <- "f_NO3_mgN_per_l_qa"

Alaska_DataRelease_2022_2023_Ferrum_V1 <- Alaska_DataRelease_2022_2023_Ferrum_modified

# Save the modified file as the version prior to calculations
write_xlsx(Alaska_DataRelease_2022_2023_Ferrum_V1, "C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Alaska_DataRelease_2022_2023_Ferrum_V1.xlsx")  # Saves a new Excel file
```

```{r}
Alaska_DataRelease_2022_2023_Ferrum_V1 <-  read_excel("C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Alaska_DataRelease_2022_2023_Ferrum_V1.xlsx")
```

# Particulate Metal Calculation
```{r}
# convert to long format with 
metal_df_long <- Alaska_DataRelease_2022_2023_Ferrum_V1 %>%
  dplyr::select(
    c(21, 144:237)  # Select metal columns by column number
  ) %>%
  dplyr::select(
    -contains("qa")  # Remove any column that contains "qa"
  ) %>%

  # Step 2: Pivot to long format
  pivot_longer(
    cols = -SamplingEventID,
    names_to = c("prefix", "metal", "unit"),
    names_pattern = "(f|u)_([^_]+)_(mcg_per_l)",
    values_to = "value"
  ) %>%
  
  filter(!is.na(prefix)) %>%
  
  # Step 3: Pivot wider to get f and u in separate columns
  pivot_wider(
    names_from = prefix,
    values_from = value
  ) %>%
  
  # Step 4: Calculate p_metal = u - f
  mutate(
  p = if_else(
    is.na(f) | is.na(u),
    NA_real_,
    if_else(u - f < 0, 0, u - f)
  )
)

view(metal_df_long)

```

```{r}
# Convert back to wide format with the particulate metal data
metal_df_wide <- metal_df_long %>%
  pivot_longer(
    cols = c(f, u, p),
    names_to = "prefix",
    values_to = "value"
  ) %>%
  mutate(full_name = paste0(prefix, "_", metal, "_", unit)) %>%
  dplyr::select(SamplingEventID, full_name, value) %>%
  pivot_wider(
    names_from = full_name,
    values_from = value
  )

view(metal_df_wide)
```

```{r}
# bring particulate metal data into the datasheet
p_metals <- metal_df_wide %>%
  dplyr::select(1, starts_with("p"))

Alaska_DataRelease_2022_2023_Ferrum_V2 <- Alaska_DataRelease_2022_2023_Ferrum_V1 %>%
  left_join(p_metals, by = "SamplingEventID")
```

## P metal QA flag
```{r}
# Make qa columns for the p metal data
# If f or u qa columns have a qa flag, add it to the p qa column

# convert to long format with 
metal_qa_long <- Alaska_DataRelease_2022_2023_Ferrum_V1 %>%
  dplyr::select(
    c(21, 144:237)  # Select metal columns by column number
  ) %>%
  dplyr::select(1,
    contains("qa")  # Remove any column that contains "qa"
  ) %>%

  # Step 2: Pivot to long format
  pivot_longer(
    cols = -SamplingEventID,
    names_to = c("prefix", "metal", "unit"),
    names_pattern = "(f|u)_([^_]+)_(mcg_per_l_qa)",
    values_to = "qa_flag"
  ) %>%
  
  filter(!is.na(prefix)) %>%
  
  # Step 3: Pivot wider to get f and u in separate columns
  pivot_wider(
    names_from = prefix,
    values_from = qa_flag
  ) %>%
  
  # make the -- cells NA
  mutate(
    f = ifelse(f == "--", NA, f)
  ) %>%
  
  # Step 5: add value to qa_flag column for p data
  mutate(
    p = case_when(
      f == "l" ~ NA_character_,
      is.na(f) & is.na(u) ~ NA_character_,
      !is.na(f) & !is.na(u) ~ paste(f, u, sep = ", "),
      !is.na(f) ~ as.character(f),
      !is.na(u) ~ as.character(u)
    )
  )

view(metal_qa_long)

```

```{r}
# Convert back to wide format with the particulate metal data
metal_qa_wide <- metal_qa_long %>%
  pivot_longer(
    cols = c(f, u, p),
    names_to = "prefix",
    values_to = "qa_flag"
  ) %>%
  mutate(full_name = paste0(prefix, "_", metal, "_", unit)) %>%
  dplyr::select(SamplingEventID, full_name, qa_flag) %>%
  pivot_wider(
    names_from = full_name,
    values_from = qa_flag
  )

view(metal_qa_wide)
```

```{r}
# bring particulate metal data qa flags into the datasheet
p_metals_qa <- metal_qa_wide %>%
  dplyr::select(1, starts_with("p"))

Alaska_DataRelease_2022_2023_Ferrum_V2 <- Alaska_DataRelease_2022_2023_Ferrum_V2 %>%
  left_join(p_metals_qa, by = "SamplingEventID")

write_xlsx(Alaska_DataRelease_2022_2023_Ferrum_V2,"C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Alaska_DataRelease_2022_2023_Ferrum_V2.xlsx")
```

## <DL Transformation
####percent of data that is <DL
```{r}
# Calculate the percentage of data that is below DL for each variable
columns_to_check <- c(
  "Alk_mgCaCO3_per_l_qa",
  "f_NH3_mgN_per_l_qa",
  "f_PO4_mgP_per_l_qa",
  "TDP_mgP_per_l_qa",
  "UTP_mgP_per_l_qa",
  "f_Cl_mg_per_l_qa",
  "f_NO3_mgN_per_l_qa",
  "f_SO4_mg_per_l_qa",
  "f_K_mg_l_qa",
  "f_Na_mg_l_qa",
  "f_Ca_mg_l_qa",
  "f_Mg_mg_l_qa",
  "f_SiO2_mg_per_l_qa",
  "f_Al_mcg_per_l_qa", "f_V_mcg_per_l_qa", 
  "f_Cr_mcg_per_l_qa", "f_Mn_mcg_per_l_qa", 
  "f_Fe_mcg_per_l_qa", "f_Co_mcg_per_l_qa", 
  "f_Ni_mcg_per_l_qa", "f_Cu_mcg_per_l_qa", 
  "f_Zn_mcg_per_l_qa", "f_As_mcg_per_l_qa", 
  "f_Se_mcg_per_l_qa", "f_Y_mcg_per_l_qa", 
  "f_Ag_mcg_per_l_qa", "f_Cd_mcg_per_l_qa", 
  "f_Ba_mcg_per_l_qa", "f_La_mcg_per_l_qa", 
  "f_Ce_mcg_per_l_qa", "f_Pr_mcg_per_l_qa", 
  "f_Nd_mcg_per_l_qa", "f_Dy_mcg_per_l_qa", 
  "f_Tl_mcg_per_l_qa", "f_U_mcg_per_l_qa",
  "f_Pb_mcg_per_l_qa",  
  "u_Al_mcg_per_l_qa", "u_V_mcg_per_l_qa", 
  "u_Cr_mcg_per_l_qa", "u_Mn_mcg_per_l_qa", 
  "u_Fe_mcg_per_l_qa", "u_Co_mcg_per_l_qa", 
  "u_Ni_mcg_per_l_qa", "u_Cu_mcg_per_l_qa", 
  "u_Zn_mcg_per_l_qa", "u_As_mcg_per_l_qa", 
  "u_Se_mcg_per_l_qa", "u_Y_mcg_per_l_qa", 
  "u_Ag_mcg_per_l_qa", "u_Cd_mcg_per_l_qa", 
  "u_Ba_mcg_per_l_qa", "u_La_mcg_per_l_qa", 
  "u_Ce_mcg_per_l_qa", "u_Pr_mcg_per_l_qa", 
  "u_Nd_mcg_per_l_qa", "u_Dy_mcg_per_l_qa", 
  "u_Tl_mcg_per_l_qa", "u_U_mcg_per_l_qa", 
  "u_Pb_mcg_per_l_qa"
)

# count the number of cells in each qa column that is <DL to calculate the percent of total data
DL_counts <- sapply(columns_to_check, function(col) {
  sum(grepl("DL", Alaska_DataRelease_2022_2023_Ferrum_modified[[col]], ignore.case = TRUE), na.rm = TRUE)
})

print(DL_counts)

#Convert to dataframe
DL_counts_df <- data.frame(Column = names(DL_counts), DL_Count = DL_counts)

# Add percent_DL column
DL_counts_df$percent_DL <- (DL_counts_df$DL_Count / 135) * 100

#view(DL_counts_df)

# f_V and f_Ag had high censoring but these metals aren't going to be used in any analysis anyways

# Save the percentage data frame
write_xlsx(DL_counts_df, "C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/percent of data below DL.xlsx")
```


####<DL values as sqrt(2)/2 of DL

```{r}
library(dplyr)

# Define your measurement columns and their corresponding QA columns
measure_cols <- c(
  "Alk_mgCaCO3_per_l",
  "f_NH3_mgN_per_l",
  "f_PO4_mgP_per_l",
  "TDP_mgP_per_l",
  "UTP_mgP_per_l",
  "f_Cl_mg_per_l",
  "f_NO3_mgN_per_l",
  "f_SO4_mg_per_l",
  "f_K_mg_l",
  "f_Na_mg_l",
  "f_SiO2_mg_per_l",
  "f_Al_mcg_per_l", 
  "f_V_mcg_per_l", 
  "f_Cr_mcg_per_l", "f_Mn_mcg_per_l", 
  "f_Fe_mcg_per_l", "f_Co_mcg_per_l", 
  "f_Ni_mcg_per_l", "f_Cu_mcg_per_l", 
  "f_Zn_mcg_per_l", "f_As_mcg_per_l", 
  "f_Se_mcg_per_l", "f_Y_mcg_per_l", 
  "f_Ag_mcg_per_l","f_Cd_mcg_per_l", 
  "f_Ba_mcg_per_l", "f_La_mcg_per_l", 
  "f_Ce_mcg_per_l", "f_Pr_mcg_per_l", 
  "f_Nd_mcg_per_l", "f_Dy_mcg_per_l", 
  "f_Tl_mcg_per_l", "f_U_mcg_per_l",
  "f_Pb_mcg_per_l",  
  "u_Al_mcg_per_l", "u_V_mcg_per_l", 
  "u_Cr_mcg_per_l", "u_Mn_mcg_per_l", 
  "u_Fe_mcg_per_l", "u_Co_mcg_per_l", 
  "u_Ni_mcg_per_l", "u_Cu_mcg_per_l", 
  "u_Zn_mcg_per_l", "u_As_mcg_per_l", 
  "u_Se_mcg_per_l", "u_Y_mcg_per_l", 
  "u_Ag_mcg_per_l", "u_Cd_mcg_per_l", 
  "u_Ba_mcg_per_l", "u_La_mcg_per_l", 
  "u_Ce_mcg_per_l", "u_Pr_mcg_per_l", 
  "u_Nd_mcg_per_l", "u_Dy_mcg_per_l", 
  "u_Tl_mcg_per_l", "u_U_mcg_per_l", 
  "u_Pb_mcg_per_l"
  )

# Create the transformed dataframe
Alaska_DataRelease_2022_2023_Ferrum_DL_transformation <- Alaska_DataRelease_2022_2023_Ferrum_V1

# Loop through each column and apply the DL transformation if QA column contains "DL"
for (col in measure_cols) {
  qa_col <- paste0(col, "_qa")
  
  Alaska_DataRelease_2022_2023_Ferrum_DL_transformation[[col]] <- ifelse(
    grepl("DL", Alaska_DataRelease_2022_2023_Ferrum_V1[[qa_col]]),
    (sqrt(2) / 2) * Alaska_DataRelease_2022_2023_Ferrum_V1[[col]],
    Alaska_DataRelease_2022_2023_Ferrum_V1[[col]]
  )
}

# round final values
Alaska_DataRelease_2022_2023_Ferrum_DL_transformation <- Alaska_DataRelease_2022_2023_Ferrum_DL_transformation %>%
    mutate(across(c(f_PO4_mgP_per_l, TDP_mgP_per_l, UTP_mgP_per_l, f_NH3_mgN_per_l, f_Al_mcg_per_l, f_V_mcg_per_l, 
f_Cr_mcg_per_l, f_Mn_mcg_per_l, 
f_Fe_mcg_per_l, f_Co_mcg_per_l, 
f_Ni_mcg_per_l, f_Cu_mcg_per_l, 
f_Zn_mcg_per_l, f_As_mcg_per_l, 
f_Se_mcg_per_l, f_Y_mcg_per_l, 
f_Ag_mcg_per_l, f_Cd_mcg_per_l, 
f_Ba_mcg_per_l, f_La_mcg_per_l, 
f_Ce_mcg_per_l, f_Pr_mcg_per_l, 
f_Nd_mcg_per_l, f_Dy_mcg_per_l, 
f_Tl_mcg_per_l, f_U_mcg_per_l,
f_Pb_mcg_per_l, f_SiO2_mg_per_l, 
u_Al_mcg_per_l, u_V_mcg_per_l, 
u_Cr_mcg_per_l, u_Mn_mcg_per_l, 
u_Fe_mcg_per_l, u_Co_mcg_per_l, 
u_Ni_mcg_per_l, u_Cu_mcg_per_l, 
u_Zn_mcg_per_l, u_As_mcg_per_l, 
u_Se_mcg_per_l, u_Y_mcg_per_l, 
u_Ag_mcg_per_l, u_Cd_mcg_per_l, 
u_Ba_mcg_per_l, u_La_mcg_per_l, 
u_Ce_mcg_per_l, u_Pr_mcg_per_l, 
u_Nd_mcg_per_l, u_Dy_mcg_per_l, 
u_Tl_mcg_per_l, u_U_mcg_per_l, 
u_Pb_mcg_per_l
), round, 3)
           ) %>%
  mutate(across(c(f_K_mg_l, f_Na_mg_l, f_Ca_mg_l, f_Mg_mg_l, Alk_mgCaCO3_per_l, f_Cl_mg_per_l, f_NO3_mgN_per_l, f_SO4_mg_per_l), round, 2))
  

view(Alaska_DataRelease_2022_2023_Ferrum_DL_transformation)

Alaska_DataRelease_2022_2023_Ferrum_V3 <-  Alaska_DataRelease_2022_2023_Ferrum_DL_transformation

# Save the modified file to check
write_xlsx(Alaska_DataRelease_2022_2023_Ferrum_V3, "C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Alaska_DataRelease_2022_2023_Ferrum_V3.xlsx")  

```

```{r}
#This is the non loop version of the DL correction calculation that I started with

Alaska_DataRelease_2022_2023_Ferrum_DL_transformation <- Alaska_DataRelease_2022_2023_Ferrum %>%
 mutate(
    Alk_mgCaCO3_per_l = ifelse(grepl("DL", Alk_mgCaCO3_per_l_qa), (sqrt(2)/2) * Alk_mgCaCO3_per_l, Alk_mgCaCO3_per_l),
    f_NH3_mgN_per_l = ifelse(grepl("DL", f_NH3_mgN_per_l_qa), (sqrt(2)/2) * f_NH3_mgN_per_l, f_NH3_mgN_per_l),
    f_PO4_mgP_per_l = ifelse(grepl("DL", f_PO4_mgP_per_l_qa), (sqrt(2)/2) * f_PO4_mgP_per_l, f_PO4_mgP_per_l),
    TDP_mgP_per_l = ifelse(grepl("DL", TDP_mgP_per_l_qa), (sqrt(2)/2) * TDP_mgP_per_l, TDP_mgP_per_l),
    UTP_mgP_per_l = ifelse(grepl("DL", UTP_mgP_per_l_qa), (sqrt(2)/2) * UTP_mgP_per_l, UTP_mgP_per_l),
    f_Cl_mg_per_l = ifelse(grepl("DL", f_Cl_mg_per_l_qa), (sqrt(2)/2) * f_Cl_mg_per_l, f_Cl_mg_per_l),
    f_NO3_mg_per_l = ifelse(grepl("DL", f_NO3_mgN_per_l_qa), (sqrt(2)/2) * f_NO3_mgN_per_l, f_NO3_mgN_per_l),
    f_SO4_mg_per_l = ifelse(grepl("DL", f_SO4_mg_per_l_qa), (sqrt(2)/2) * f_SO4_mg_per_l, f_SO4_mg_per_l),
    f_K_mg_l = ifelse(grepl("DL", f_K_mg_l_qa), (sqrt(2)/2) * f_K_mg_l, f_K_mg_l),
    f_Na_mg_l = ifelse(grepl("DL", f_Na_mg_l_qa), (sqrt(2)/2) * f_Na_mg_l, f_Na_mg_l)
  ) %>%
  mutate(across(
    c(f_K_mg_l, f_Na_mg_l), 
    round, 3  # Round all final values to 2 decimal places
  )) %>%
    mutate(across(c(f_PO4_mgP_per_l, TDP_mgP_per_l, UTP_mgP_per_l, f_NH3_mgN_per_l), round, 4)
           ) %>%
  mutate(across(c(Alk_mgCaCO3_per_l, f_Cl_mg_per_l, f_NO3_mgN_per_l, f_SO4_mg_per_l), round, 2))
  
Alaska_DataRelease_2022_2023_Ferrum_DL_transformation <- Alaska_DataRelease_2022_2023_Ferrum_DL_transformation %>%
  mutate(across(c(f_PO4_mgP_per_l, TDP_mgP_per_l, UTP_mgP_per_l), round, 4))
  
  # Code explanation
  
  #mutate(f_Cl_mg_per_l_adjusted = ifelse(
    #grepl("DL", f_Cl_mg_per_l_qa),  # Check if "DL" is present in f_Cl_mg_per_l_qa
    #(sqrt(2)/2) * f_Cl_mg_per_l,    # If TRUE, apply transformation
    #f_Cl_mg_per_l))                   # If FALSE, keep original value
  

#head(Alaska_DataRelease_2022_2023_Ferrum_DL_transformation)

#Check_df <- Alaska_DataRelease_2022_2023_Ferrum_DL_transformation %>%
  #dplyr::select(SamplingEventID, f_Cl_mg_per_l, f_Cl_mg_per_l_adjusted, f_Cl_mg_per_l_qa)

# Save the transformed file as the working dataframe 
# this Working dataframe has values that were below DL replaced with the sqrt2/2 of the DL
write_xlsx(Alaska_DataRelease_2022_2023_Ferrum_DL_transformation, "Alaska_DataRelease_2022_2023_Ferrum_DL_transformation.xlsx")
```

```{r}
Alaska_DataRelease_2022_2023_Ferrum_V3 <-  read_excel("C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Alaska_DataRelease_2022_2023_Ferrum_V3.xlsx")
```

# Particulate Metal Calculation
```{r}
# convert to long format with 
metal_df_long <- Alaska_DataRelease_2022_2023_Ferrum_V3 %>%
  dplyr::select(
    c(21, 144:237)  # Select metal columns by column number
  ) %>%
  dplyr::select(
    -contains("qa")  # Remove any column that contains "qa"
  ) %>%

  # Step 2: Pivot to long format
  pivot_longer(
    cols = -SamplingEventID,
    names_to = c("prefix", "metal", "unit"),
    names_pattern = "(f|u)_([^_]+)_(mcg_per_l)",
    values_to = "value"
  ) %>%
  
  filter(!is.na(prefix)) %>%
  
  # Step 3: Pivot wider to get f and u in separate columns
  pivot_wider(
    names_from = prefix,
    values_from = value
  ) %>%
  
  # Step 4: Calculate p_metal = u - f
  mutate(
  p = if_else(
    is.na(f) | is.na(u),
    NA_real_,
    if_else(u - f < 0, 0, u - f)
  )
)

view(metal_df_long)

```

```{r}
# Convert back to wide format with the particulate metal data
metal_df_wide <- metal_df_long %>%
  pivot_longer(
    cols = c(f, u, p),
    names_to = "prefix",
    values_to = "value"
  ) %>%
  mutate(full_name = paste0(prefix, "_", metal, "_", unit)) %>%
  dplyr::select(SamplingEventID, full_name, value) %>%
  pivot_wider(
    names_from = full_name,
    values_from = value
  )

view(metal_df_wide)
```

```{r}
# bring particulate metal data into the datasheet
p_metals <- metal_df_wide %>%
  dplyr::select(1, starts_with("p"))

Alaska_DataRelease_2022_2023_Ferrum_V4 <- Alaska_DataRelease_2022_2023_Ferrum_V3 %>%
  left_join(p_metals, by = "SamplingEventID")
```

## P metal QA flag
```{r}
# Make qa columns for the p metal data
# If f or u qa columns have a qa flag, add it to the p qa column

# convert to long format with 
metal_qa_long <- Alaska_DataRelease_2022_2023_Ferrum_V3 %>%
  dplyr::select(
    c(21, 144:237)  # Select metal columns by column number
  ) %>%
  dplyr::select(1,
    contains("qa")  # Remove any column that contains "qa"
  ) %>%

  # Step 2: Pivot to long format
  pivot_longer(
    cols = -SamplingEventID,
    names_to = c("prefix", "metal", "unit"),
    names_pattern = "(f|u)_([^_]+)_(mcg_per_l_qa)",
    values_to = "qa_flag"
  ) %>%
  
  filter(!is.na(prefix)) %>%
  
  # Step 3: Pivot wider to get f and u in separate columns
  pivot_wider(
    names_from = prefix,
    values_from = qa_flag
  ) %>%
  
  # make the -- cells NA
  mutate(
    f = ifelse(f == "--", NA, f)
  ) %>%
  
  # Step 5: add value to qa_flag column for p data
  mutate(
    p = case_when(
      f == "l" ~ NA_character_,
      is.na(f) & is.na(u) ~ NA_character_,
      !is.na(f) & !is.na(u) ~ paste(f, u, sep = ", "),
      !is.na(f) ~ as.character(f),
      !is.na(u) ~ as.character(u)
    )
  )

view(metal_qa_long)

```

```{r}
# Convert back to wide format with the particulate metal data
metal_qa_wide <- metal_qa_long %>%
  pivot_longer(
    cols = c(f, u, p),
    names_to = "prefix",
    values_to = "qa_flag"
  ) %>%
  mutate(full_name = paste0(prefix, "_", metal, "_", unit)) %>%
  dplyr::select(SamplingEventID, full_name, qa_flag) %>%
  pivot_wider(
    names_from = full_name,
    values_from = qa_flag
  )

view(metal_qa_wide)
```

```{r}
# bring particulate metal data qa flags into the datasheet
p_metals_qa <- metal_qa_wide %>%
  dplyr::select(1, starts_with("p"))

Alaska_DataRelease_2022_2023_Ferrum_V4 <- Alaska_DataRelease_2022_2023_Ferrum_V4 %>%
  left_join(p_metals_qa, by = "SamplingEventID")

write_xlsx(Alaska_DataRelease_2022_2023_Ferrum_V4,"C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Alaska_DataRelease_2022_2023_Ferrum_V4.xlsx")
```


### Bring in the visual description and site classification information

```{r}
# Load data to join
# This file has the VisualDescription, site_classification, Hyd_site_classification, Hyd_Classification, and Site_Grouping columns used for some analyses
Site_info_to_bring_in <- read_excel("C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Master Spreadsheet/Site_info_to_bring_in.xlsx")

# distances downstream and elevation data
site_metrics <- read_excel("C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Master Spreadsheet/site_elevation_and_distances_V2.xlsx", sheet = "USE")

# make everything in this df numeric
site_metrics$Distance_km <- as.numeric(site_metrics$Distance_km)
site_metrics$Elevation_ft <- as.numeric(site_metrics$Elevation_ft)
site_metrics$Watershed_Area <- as.numeric(site_metrics$Watershed_Area)
site_metrics$Relative_MS_Watershed_Area <- as.numeric(site_metrics$Relative_MS_Watershed_Area)

# Make sure SamplingEventID is character in all dataframes
Alaska_DataRelease_2022_2023_Ferrum_V4 <- Alaska_DataRelease_2022_2023_Ferrum_V4 %>%
  mutate(SamplingEventID = as.character(SamplingEventID))

Site_info_to_bring_in <- Site_info_to_bring_in %>%
  mutate(SamplingEventID = as.character(SamplingEventID))

site_metrics <- site_metrics %>%
  mutate(SamplingEventID = as.character(SamplingEventID))

#join dataframes
Alaska_DataRelease_2022_2023_Ferrum_V5 <- Alaska_DataRelease_2022_2023_Ferrum_V4 %>% 
  left_join(Site_info_to_bring_in, by = "SamplingEventID") %>%
  left_join(site_metrics, by = "SamplingEventID") %>%
  relocate(SamplingEventID, .after = FieldNotesFile) %>%
  relocate(Prox_Groups, RelAcc_Groups, New_Groups, Distance_km, Elevation_ft, VisualDescription,
                Site_Classification,
                Hyd_Classification, .after = SamplingEventID)

Alaska_DataRelease_2022_2023_Ferrum_V5 <- Alaska_DataRelease_2022_2023_Ferrum_V5 %>%
  mutate(    
    New_Grouping = case_when(
    New_Groups == 1 ~ "Upstream",
    New_Groups == 2 ~ "Seep",
    New_Groups == 3 ~ "Impaired Tributary",
    New_Groups == 4 ~ "Unimpaired Tributary",
    New_Groups == 6 ~ "Downstream MS",
    TRUE ~ NA_character_
  ))

Alaska_DataRelease_2022_2023_Ferrum_V5 <- Alaska_DataRelease_2022_2023_Ferrum_V5 %>%
  relocate(New_Grouping, .after = New_Groups) 

Alaska_DataRelease_2022_2023_Ferrum_V5$New_Groups <- as.numeric(Alaska_DataRelease_2022_2023_Ferrum_V5$New_Groups)

view(Alaska_DataRelease_2022_2023_Ferrum_V5)

# Remove sample from the kotzebue water quality lake
Alaska_DataRelease_2022_2023_Ferrum_V5 <- Alaska_DataRelease_2022_2023_Ferrum_V5 %>%
  filter(!grepl("kotzebue", SamplingEventID, ignore.case = TRUE))

# Save as an excel file
write_xlsx(Alaska_DataRelease_2022_2023_Ferrum_V5, "C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Alaska_DataRelease_2022_2023_Ferrum_V5.xlsx")
```


# Join 2022 Salmon River sample data
```{r}
#load data
Salmon_R_2022_SEID <- read_excel("C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Master Spreadsheet/Salmon River 2022_SEID.xlsx")

UAM_2022_metal_data_DL <- read_excel("C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Master Spreadsheet/2022 UAM/20220407 UAM data wide_20250522_DL corrected.xlsx")

SalmonR_2022_df <- Salmon_R_2022_SEID %>%
  left_join(UAM_2022_metal_data_DL, by = "container_id") %>%
  left_join(Site_info_to_bring_in, by = "SamplingEventID") %>%
  left_join(site_metrics, by = "SamplingEventID") %>%
  dplyr::select(-matches("206Pb|207Pb|208Pb"))

colnames(SalmonR_2022_df)[11] <- "u_Pb_mcg_per_l" 
colnames(SalmonR_2022_df)[12] <- "u_Pb_mcg_per_l_qa"

view(SalmonR_2022_df)

# convert columns to numeric
cols_to_num <- c(3,4,5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 50, 51)

SalmonR_2022_df <- SalmonR_2022_df %>%
  mutate(across(all_of(cols_to_num), as.numeric))

# convert columns to numeric in V5
V5_num <- c(27,28)
Alaska_DataRelease_2022_2023_Ferrum_V5 <- Alaska_DataRelease_2022_2023_Ferrum_V5 %>%
  mutate(across(all_of(V5_num), as.numeric))

Alaska_DataRelease_2022_2023_Ferrum_V6 <- bind_rows(Alaska_DataRelease_2022_2023_Ferrum_V5, SalmonR_2022_df)

view(Alaska_DataRelease_2022_2023_Ferrum_V6)

# Save as an excel file
write_xlsx(Alaska_DataRelease_2022_2023_Ferrum_V6, "C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Alaska_DataRelease_2022_2023_Ferrum_V6.xlsx")

```

#Final data sheet modifications
```{r}
# Add a column that extracts the year and a column for month 
Alaska_DataRelease_2022_2023_Ferrum_V7 <- Alaska_DataRelease_2022_2023_Ferrum_V6 %>%
  mutate(
    sample_collection_year = year(as.Date(sample_collection_date_mm_dd_yy)),
    sample_collection_month = month(as.Date(sample_collection_date_mm_dd_yy), label = TRUE, abbr = FALSE)
  ) %>%
  mutate(
    sample_collection_season = case_when(
      sample_collection_month %in% c("May", "June") ~ "early",
      sample_collection_month == "July" ~ "middle",
      sample_collection_month %in% c("August", "September") ~ "late",
      TRUE ~ NA_character_
    )
  ) %>%
  relocate(sample_collection_year, sample_collection_month, sample_collection_season, .after = SamplingEventID)

view(Alaska_DataRelease_2022_2023_Ferrum_V7)

write_xlsx(Alaska_DataRelease_2022_2023_Ferrum_V7, "C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Ferrum Manuscript Datasheets/Alaska_DataRelease_2022_2023_Ferrum_V7.xlsx")

#Manually added year, month and season for the Salmon 2022 sites in excel and then reload to R

Alaska_DataRelease_2022_2023_Ferrum_V7 <- read_excel("C:/Users/tevinger/OneDrive - University of California, Davis/Lab/Alaska Projects/Ferrum Manuscript Datasheets/Alaska_DataRelease_2022_2023_Ferrum_V7.xlsx")
```
